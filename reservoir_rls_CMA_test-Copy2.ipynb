{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reservoir_rls import *\n",
    "from lorenz63 import *\n",
    "from sklearn import preprocessing\n",
    "from scipy.stats import sem\n",
    "import cma\n",
    "from scipy.stats import kstest, norm, shapiro\n",
    "from multiprocessing import Pool\n",
    "from min_func import *\n",
    "from tqdm import tqdm\n",
    "from matplotlib.patches import Ellipse\n",
    "import matplotlib.transforms as transforms\n",
    "\n",
    "\n",
    "\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style(theme='monokai', context='notebook', ticks=True, grid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.05210027118992914\n",
      "18.92542301780254\n",
      "-19.022413088306337\n"
     ]
    }
   ],
   "source": [
    "data_length = 200000\n",
    "step = 0.05\n",
    "r_t = lambda x: r_t_const(x)\n",
    "dxdt = lambda x,t,r_t: dxdt_lorenz(x,t,r_t)\n",
    "data = getLorenzData(data_length, r_t, dxdt, sample_tau = step)\n",
    "\n",
    "sync_length = 200\n",
    "train_length = 800\n",
    "pred_length = 500\n",
    "\n",
    "# scaler = preprocessing.StandardScaler().fit(data)\n",
    "# scaled_data = scaler.transform(data)\n",
    "scaled_data = np.copy(data)\n",
    "scaled_data = np.ascontiguousarray(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 210\n",
    "num_tests = 100\n",
    "res_seed = 1\n",
    "base_res = reservoir(3,num_nodes,input_weight = 1, spectral_radius = 1, seed = res_seed)\n",
    "mask = ['input_weight', 'regularization']\n",
    "x0 = np.array([5, 5])\n",
    "min_func = lambda x: vt_min_function_norm(scaled_data, x, mask, base_res.Win, base_res.A, \\\n",
    "     num_tests = num_tests,  num_nodes = num_nodes, pred_length = pred_length, train_length = train_length)\n",
    "sigma = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = cma.CMAOptions()\n",
    "opts.set('popsize',6*x0.size)\n",
    "opts.set('bounds', [0,10])\n",
    "opts.set('seed', 5)\n",
    "opts.set('verb_filenameprefix','cmaes_norm_res%d_redo\\\\' % res_seed)\n",
    "results = cma.fmin(min_func, x0, sigma, options = opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 2500/2500 [2:02:14<00:00,  2.93s/it]\n"
     ]
    }
   ],
   "source": [
    "weights = np.linspace(0,10,50)\n",
    "forgets = np.linspace(0,10,50)\n",
    "func_vals = np.zeros((weights.size, forgets.size))\n",
    "\n",
    "with tqdm(total = weights.size * forgets.size) as pbar:\n",
    "    for i in range(weights.size):\n",
    "        for j in range(forgets.size):\n",
    "            func_vals[i,j] = min_func(np.array([weights[i], forgets[j]]))\n",
    "            # print('Weight: %f, Log Reg: %f, Fval: %f'%(0.2*(weights[i]-5),-forgets[j]-3.0,func_vals[i,j]))\n",
    "            np.savetxt('norm_func_vals.csv', func_vals, delimiter = ',')\n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.linspace(0,10,50)\n",
    "regs = np.linspace(0,10,50)\n",
    "W, R = np.meshgrid(weights, regs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_ellipse(mean_x, mean_y, cov, ax, n_std=1.0, facecolor='none', **kwargs):\n",
    "    \"\"\"\n",
    "    Create a plot of the covariance confidence ellipse of *x* and *y*.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x, y : array-like, shape (n, )\n",
    "        Input data.\n",
    "\n",
    "    ax : matplotlib.axes.Axes\n",
    "        The axes object to draw the ellipse into.\n",
    "\n",
    "    n_std : float\n",
    "        The number of standard deviations to determine the ellipse's radiuses.\n",
    "\n",
    "    **kwargs\n",
    "        Forwarded to `~matplotlib.patches.Ellipse`\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.patches.Ellipse\n",
    "    \"\"\"\n",
    "    \n",
    "    pearson = cov[0, 1]/np.sqrt(cov[0, 0] * cov[1, 1])\n",
    "    # Using a special case to obtain the eigenvalues of this\n",
    "    # two-dimensionl dataset.\n",
    "    ell_radius_x = np.sqrt(1 + pearson)\n",
    "    ell_radius_y = np.sqrt(1 - pearson)\n",
    "    ellipse = Ellipse((0, 0), width=ell_radius_x * 2, height=ell_radius_y * 2,\n",
    "                      facecolor=facecolor, **kwargs)\n",
    "\n",
    "    # Calculating the stdandard deviation of x from\n",
    "    # the squareroot of the variance and multiplying\n",
    "    # with the given number of standard deviations.\n",
    "    scale_x = np.sqrt(cov[0, 0]) * n_std\n",
    "    # mean_x = np.mean(x)\n",
    "\n",
    "    # calculating the stdandard deviation of y ...\n",
    "    scale_y = np.sqrt(cov[1, 1]) * n_std\n",
    "    # mean_y = np.mean(y)\n",
    "\n",
    "    transf = transforms.Affine2D() \\\n",
    "        .rotate_deg(45) \\\n",
    "        .scale(scale_x, scale_y) \\\n",
    "        .translate(mean_x, mean_y)\n",
    "\n",
    "    ellipse.set_transform(transf + ax.transData)\n",
    "    return ax.add_patch(ellipse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_data = np.load('cmaes_norm_res1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 6))\n",
    "ticks = np.linspace(0,10,6)\n",
    "xlabels = 0.25*ticks\n",
    "ylabels = -ticks-2.0\n",
    "\n",
    "ax = plt.subplot(1,2,1)\n",
    "func_vals = np.loadtxt('norm_func_vals.csv', delimiter = ',')\n",
    "plt.pcolor(W, R, -func_vals.T)\n",
    "plt.colorbar()\n",
    "# ax = plt.subplot(1,2,2)\n",
    "np.random.seed(5)\n",
    "x = np.random.randn(10)\n",
    "y = np.random.randn(10)\n",
    "cov = np.cov(x,y)\n",
    "x_mean = 5\n",
    "y_mean = 5\n",
    "confidence_ellipse(x_mean,y_mean,cov,ax,edgecolor = 'red', linewidth = 2)\n",
    "ax.scatter(x_mean, y_mean, c = 'red')\n",
    "ax.set_xlim(0,10)\n",
    "ax.set_ylim(0,10)\n",
    "plt.xticks(ticks, xlabels)\n",
    "plt.yticks(ticks, ylabels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func_vals = np.loadtxt('norm_func_vals.csv', delimiter = ',')\n",
    "plt.pcolor(W, R, -func_vals.T)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = reservoir(3,210,forget = 1, input_weight = 0.25*0.05735187596920699, regularization = 10**(-9.310114193664688), seed = 3)\n",
    "num_tests = 5000\n",
    "pred_length = 500\n",
    "train_length = 400\n",
    "sync_length = 200\n",
    "valid_times_norm = cross_validation_performance_resync(scaled_data,res2,num_tests,sync_length, \\\n",
    "   train_length, pred_length,train_method = 'Normal', progress = True)\n",
    "print(np.median(valid_times_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_times_RLS = cross_validation_performance(scaled_data,res1,num_tests,sync_length, \\\n",
    "   train_length, pred_length,train_method = 'RLS')\n",
    "print(np.median(valid_times_RLS))\n",
    "valid_times_norm = cross_validation_performance(scaled_data,res2,num_tests,sync_length, \\\n",
    "   train_length, pred_length,train_method = 'Normal')\n",
    "print(np.median(valid_times_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = reservoir(3,300,forget = 0.985, input_weight = 0.01, regularization = 1e-8, \\\n",
    "     t_regularization = 5e-5, delta = 1e6, t_weighted = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_times_norm_array = np.loadtxt('Lorenz63Data/valid_times_norm_tweight_forget%f_reg%e_treg%e.csv' \\\n",
    "#     %(res1.forget, res1.regularization, res1.t_regularization), delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0.05\n",
    "base_data_length = 25000\n",
    "data_length = int(base_data_length * step/(0.01))\n",
    "r_t = lambda x: r_t_cosine(x)\n",
    "dxdt = lambda x,t,r_t: dxdt_lorenz(x,t,r_t)\n",
    "valid_times_norm_array = np.array([])\n",
    "\n",
    "sync_length = 1000\n",
    "num_tests = 300\n",
    "train_length = 800\n",
    "pred_length = 200\n",
    "completed_seeds = valid_times_norm_array.shape[0]\n",
    "\n",
    "# scaler = preprocessing.StandardScaler().fit(data)\n",
    "# scaled_data = scaler.transform(data)\n",
    "from tqdm import tqdm\n",
    "with tqdm(total = num_tests) as pbar:\n",
    "    for seed in range(num_tests):\n",
    "        data = getLorenzData(data_length, r_t, dxdt, sample_tau = step, seed = seed)\n",
    "        scaled_data = np.ascontiguousarray(data)\n",
    "        valid_times_norm = cross_validation_performance_versust(scaled_data,res1,sync_length, \\\n",
    "               train_length, pred_length,pred_gap_length = 100, train_method = 'Normal', progress = False)\n",
    "        if valid_times_norm_array.size == 0:\n",
    "            valid_times_norm_array = np.copy(valid_times_norm)\n",
    "        else:\n",
    "            valid_times_norm_array = np.vstack((valid_times_norm_array,valid_times_norm))\n",
    "        np.savetxt('Lorenz63Data/valid_times_norm_tweight_forget%f_reg%e_treg%e.csv' %(res1.forget, res1.regularization, res1.t_regularization), \\\n",
    "            valid_times_norm_array, delimiter = ',')\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('Lorenz63Data/valid_times_norm_tweight_forget%f_reg%e_treg%e.csv' %(res1.forget, res1.regularization, res1.t_regularization), \\\n",
    "    valid_times_norm_array, delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.mean(valid_times_norm_array*0.05,axis = 0))\n",
    "plt.ylim(0,5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = reservoir(3,300,forget = 0.985, input_weight = 0.01, LM_regularization = 1e-10, \\\n",
    "     t_regularization = 0, delta = 1e6, t_weighted = False, RLS_reg_type = 'LM')\n",
    "step = 0.05\n",
    "base_data_length = 5000\n",
    "data_length = int(base_data_length * step/(0.01))\n",
    "r_t = lambda x: r_t_cosine(x)\n",
    "dxdt = lambda x,t,r_t: dxdt_lorenz(x,t,r_t)\n",
    "valid_times_norm_array = np.array([])\n",
    "\n",
    "sync_length = 500\n",
    "num_tests = 100\n",
    "train_length = 2000\n",
    "pred_length = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = getLorenzData(data_length, r_t, dxdt, sample_tau = step, seed = 1)\n",
    "new_data = np.ascontiguousarray(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1.trainWoutRLS(scaled_data[2800:3800],200)\n",
    "res1.valid_time(scaled_data[3800:4200],plot = True, error_bound = 3.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_times_norm = cross_validation_performance_separated(scaled_data,res1,sync_length, \\\n",
    "               train_length, pred_length, train_method = 'RLS', progress = False)\n",
    "print(np.median(valid_times_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = preprocessing.StandardScaler().fit(data)\n",
    "# scaled_data = scaler.transform(data)\n",
    "from tqdm import tqdm\n",
    "with tqdm(total = num_tests) as pbar:\n",
    "    for seed in range(num_tests):\n",
    "        data = getLorenzData(data_length, r_t, dxdt, sample_tau = step, seed = seed)\n",
    "        scaled_data = np.ascontiguousarray(data)\n",
    "        valid_times_norm = cross_validation_performance_versust(scaled_data,res1,sync_length, \\\n",
    "               train_length, pred_length,pred_gap_length = 100, train_method = 'RLS', progress = False)\n",
    "        if valid_times_norm_array.size == 0:\n",
    "            valid_times_norm_array = np.copy(valid_times_norm)\n",
    "        else:\n",
    "            valid_times_norm_array = np.vstack((valid_times_norm_array,valid_times_norm))\n",
    "        np.savetxt('Lorenz63Data/valid_times_rls_tweight_forget%f_reg%e_treg%e.csv' %(res1.forget, \\\n",
    "            res1.regularization, res1.t_regularization), valid_times_norm_array, delimiter = ',')\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.mean(valid_times_norm_array*0.05,axis = 0))\n",
    "plt.ylim(0,5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1,2],[3,4]])\n",
    "np.mean(x,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
