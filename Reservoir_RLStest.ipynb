{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sparse\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.sparse import linalg\n",
    "from scipy.linalg import solve, pinv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dxdt_lorenz(x,time,r_t, sigma = 10., beta = 8/3, rho = 28.):\n",
    "    return np.array([sigma*(- x[0] + x[1]),\\\n",
    "                     r_t(time)*rho*x[0] - x[1] - x[0]*x[2],\\\n",
    "                     x[0]*x[1]-beta*x[2]])\n",
    "    \n",
    "def rk4(x, time, tau, r_t, dxdt):\n",
    "    k1 = dxdt(x, time, r_t)\n",
    "    k2 = dxdt(x + k1/2*tau, time + tau/2, r_t)\n",
    "    k3 = dxdt(x + k2/2*tau, time + tau/2, r_t)\n",
    "    k4 = dxdt(x + tau*k3, time + tau, r_t)\n",
    "    \n",
    "    xnext = x + 1/6*tau*(k1+2*k2+2*k3+k4)\n",
    "    return xnext\n",
    "\n",
    "def getLorenzData(data_length, r_t, dxdt_lorenz,transient_length = 1000, tau = 0.1):\n",
    "    x = np.random.rand(3)\n",
    "    time = -transient_length*tau\n",
    "    for i in range(0,transient_length):\n",
    "        x = rk4(x,time,tau,r_t,dxdt_lorenz)\n",
    "        time += tau\n",
    "    \n",
    "    data = np.zeros((3,data_length))\n",
    "    data[:,0] = x\n",
    "    for i in range(0,data_length-1):\n",
    "        data[:,i+1] = rk4(data[:,i],time,tau,r_t,dxdt_lorenz)\n",
    "        time += tau\n",
    "        \n",
    "    return data\n",
    "\n",
    "def r_t_cosine(time, period = 500, max_height = 48/28):\n",
    "    r = 1 + (max_height-1.)/2 - (max_height-1)/2*np.cos(2*np.pi/period*time)\n",
    "    return r\n",
    "\n",
    "def r_t_const(time, value = 1):\n",
    "    # Function for constant rho value\n",
    "    r = value\n",
    "    return r\n",
    "\n",
    "def advanceReservoir(win,A_mat,x,u,leakage):\n",
    "    x_next = leakage*x + (1-leakage)*np.tanh(A_mat.dot(x) + np.matmul(win,u))\n",
    "    return x_next\n",
    "\n",
    "def getPrediction(win, A_mat, wout, x, predict_length, leakage):\n",
    "    prediction = np.zeros((wout.shape[0],predict_length))\n",
    "    aug_x = np.copy(x)\n",
    "    aug_x[::2] = np.power(x[::2],2)\n",
    "    prediction[:,0] = np.matmul(wout,aug_x)\n",
    "    \n",
    "    for pred_idx in range(0,predict_length - 1):\n",
    "        x = advanceReservoir(win, A_mat, x, prediction[:,pred_idx], leakage)\n",
    "        aug_x = np.copy(x)\n",
    "        aug_x[::2] = np.power(x[::2],2)\n",
    "        prediction[:,pred_idx + 1] = np.matmul(wout,aug_x)\n",
    "        \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.     0.9975 0.995  0.9925 0.99   0.9875 0.985  0.9825 0.98  ]\n",
      "0 0 1e-06\n",
      "0 0 5e-07\n",
      "0 0 1e-07\n",
      "0 0 5e-08\n",
      "0 0 1e-08\n",
      "0 1 1e-06\n",
      "0 1 5e-07\n",
      "0 1 1e-07\n",
      "0 1 5e-08\n",
      "0 1 1e-08\n",
      "0 2 1e-06\n",
      "0 2 5e-07\n",
      "0 2 1e-07\n",
      "0 2 5e-08\n",
      "0 2 1e-08\n",
      "0 3 1e-06\n",
      "0 3 5e-07\n",
      "0 3 1e-07\n",
      "0 3 5e-08\n",
      "0 3 1e-08\n",
      "0 4 1e-06\n",
      "0 4 5e-07\n",
      "0 4 1e-07\n",
      "0 4 5e-08\n",
      "0 4 1e-08\n",
      "0 5 1e-06\n",
      "0 5 5e-07\n",
      "0 5 1e-07\n",
      "0 5 5e-08\n",
      "0 5 1e-08\n",
      "0 6 1e-06\n",
      "0 6 5e-07\n",
      "0 6 1e-07\n",
      "0 6 5e-08\n",
      "0 6 1e-08\n",
      "0 7 1e-06\n",
      "0 7 5e-07\n",
      "0 7 1e-07\n",
      "0 7 5e-08\n",
      "0 7 1e-08\n",
      "0 8 1e-06\n",
      "0 8 5e-07\n",
      "0 8 1e-07\n",
      "0 8 5e-08\n",
      "0 8 1e-08\n",
      "1 0 1e-06\n",
      "1 0 5e-07\n",
      "1 0 1e-07\n",
      "1 0 5e-08\n",
      "1 0 1e-08\n",
      "1 1 1e-06\n",
      "1 1 5e-07\n",
      "1 1 1e-07\n",
      "1 1 5e-08\n",
      "1 1 1e-08\n",
      "1 2 1e-06\n",
      "1 2 5e-07\n",
      "1 2 1e-07\n",
      "1 2 5e-08\n",
      "1 2 1e-08\n",
      "1 3 1e-06\n",
      "1 3 5e-07\n",
      "1 3 1e-07\n",
      "1 3 5e-08\n",
      "1 3 1e-08\n",
      "1 4 1e-06\n",
      "1 4 5e-07\n",
      "1 4 1e-07\n",
      "1 4 5e-08\n",
      "1 4 1e-08\n",
      "1 5 1e-06\n",
      "1 5 5e-07\n",
      "1 5 1e-07\n",
      "1 5 5e-08\n",
      "1 5 1e-08\n",
      "1 6 1e-06\n",
      "1 6 5e-07\n",
      "1 6 1e-07\n",
      "1 6 5e-08\n",
      "1 6 1e-08\n",
      "1 7 1e-06\n",
      "1 7 5e-07\n",
      "1 7 1e-07\n",
      "1 7 5e-08\n",
      "1 7 1e-08\n",
      "1 8 1e-06\n",
      "1 8 5e-07\n",
      "1 8 1e-07\n",
      "1 8 5e-08\n",
      "1 8 1e-08\n",
      "2 0 1e-06\n",
      "2 0 5e-07\n",
      "2 0 1e-07\n",
      "2 0 5e-08\n",
      "2 0 1e-08\n",
      "2 1 1e-06\n",
      "2 1 5e-07\n",
      "2 1 1e-07\n",
      "2 1 5e-08\n",
      "2 1 1e-08\n",
      "2 2 1e-06\n",
      "2 2 5e-07\n",
      "2 2 1e-07\n",
      "2 2 5e-08\n",
      "2 2 1e-08\n",
      "2 3 1e-06\n",
      "2 3 5e-07\n",
      "2 3 1e-07\n",
      "2 3 5e-08\n",
      "2 3 1e-08\n",
      "2 4 1e-06\n",
      "2 4 5e-07\n",
      "2 4 1e-07\n",
      "2 4 5e-08\n",
      "2 4 1e-08\n",
      "2 5 1e-06\n",
      "2 5 5e-07\n",
      "2 5 1e-07\n",
      "2 5 5e-08\n",
      "2 5 1e-08\n",
      "2 6 1e-06\n",
      "2 6 5e-07\n",
      "2 6 1e-07\n",
      "2 6 5e-08\n",
      "2 6 1e-08\n",
      "2 7 1e-06\n",
      "2 7 5e-07\n",
      "2 7 1e-07\n",
      "2 7 5e-08\n",
      "2 7 1e-08\n",
      "2 8 1e-06\n",
      "2 8 5e-07\n",
      "2 8 1e-07\n",
      "2 8 5e-08\n",
      "2 8 1e-08\n",
      "3 0 1e-06\n",
      "3 0 5e-07\n",
      "3 0 1e-07\n",
      "3 0 5e-08\n",
      "3 0 1e-08\n",
      "3 1 1e-06\n",
      "3 1 5e-07\n",
      "3 1 1e-07\n",
      "3 1 5e-08\n",
      "3 1 1e-08\n",
      "3 2 1e-06\n",
      "3 2 5e-07\n",
      "3 2 1e-07\n",
      "3 2 5e-08\n",
      "3 2 1e-08\n",
      "3 3 1e-06\n",
      "3 3 5e-07\n",
      "3 3 1e-07\n",
      "3 3 5e-08\n",
      "3 3 1e-08\n",
      "3 4 1e-06\n",
      "3 4 5e-07\n",
      "3 4 1e-07\n",
      "3 4 5e-08\n",
      "3 4 1e-08\n",
      "3 5 1e-06\n",
      "3 5 5e-07\n",
      "3 5 1e-07\n",
      "3 5 5e-08\n",
      "3 5 1e-08\n",
      "3 6 1e-06\n",
      "3 6 5e-07\n",
      "3 6 1e-07\n",
      "3 6 5e-08\n",
      "3 6 1e-08\n",
      "3 7 1e-06\n",
      "3 7 5e-07\n",
      "3 7 1e-07\n",
      "3 7 5e-08\n",
      "3 7 1e-08\n",
      "3 8 1e-06\n",
      "3 8 5e-07\n",
      "3 8 1e-07\n",
      "3 8 5e-08\n",
      "3 8 1e-08\n",
      "4 0 1e-06\n",
      "4 0 5e-07\n",
      "4 0 1e-07\n",
      "4 0 5e-08\n",
      "4 0 1e-08\n",
      "4 1 1e-06\n",
      "4 1 5e-07\n",
      "4 1 1e-07\n",
      "4 1 5e-08\n",
      "4 1 1e-08\n",
      "4 2 1e-06\n",
      "4 2 5e-07\n",
      "4 2 1e-07\n",
      "4 2 5e-08\n",
      "4 2 1e-08\n",
      "4 3 1e-06\n",
      "4 3 5e-07\n",
      "4 3 1e-07\n",
      "4 3 5e-08\n",
      "4 3 1e-08\n",
      "4 4 1e-06\n",
      "4 4 5e-07\n",
      "4 4 1e-07\n",
      "4 4 5e-08\n",
      "4 4 1e-08\n",
      "4 5 1e-06\n",
      "4 5 5e-07\n",
      "4 5 1e-07\n",
      "4 5 5e-08\n",
      "4 5 1e-08\n",
      "4 6 1e-06\n",
      "4 6 5e-07\n",
      "4 6 1e-07\n",
      "4 6 5e-08\n",
      "4 6 1e-08\n",
      "4 7 1e-06\n",
      "4 7 5e-07\n",
      "4 7 1e-07\n",
      "4 7 5e-08\n",
      "4 7 1e-08\n",
      "4 8 1e-06\n",
      "4 8 5e-07\n",
      "4 8 1e-07\n",
      "4 8 5e-08\n",
      "4 8 1e-08\n",
      "5 0 1e-06\n",
      "5 0 5e-07\n",
      "5 0 1e-07\n",
      "5 0 5e-08\n",
      "5 0 1e-08\n",
      "5 1 1e-06\n",
      "5 1 5e-07\n",
      "5 1 1e-07\n",
      "5 1 5e-08\n",
      "5 1 1e-08\n",
      "5 2 1e-06\n",
      "5 2 5e-07\n",
      "5 2 1e-07\n",
      "5 2 5e-08\n",
      "5 2 1e-08\n",
      "5 3 1e-06\n",
      "5 3 5e-07\n",
      "5 3 1e-07\n",
      "5 3 5e-08\n",
      "5 3 1e-08\n",
      "5 4 1e-06\n",
      "5 4 5e-07\n",
      "5 4 1e-07\n",
      "5 4 5e-08\n",
      "5 4 1e-08\n",
      "5 5 1e-06\n",
      "5 5 5e-07\n",
      "5 5 1e-07\n",
      "5 5 5e-08\n",
      "5 5 1e-08\n",
      "5 6 1e-06\n",
      "5 6 5e-07\n",
      "5 6 1e-07\n",
      "5 6 5e-08\n",
      "5 6 1e-08\n",
      "5 7 1e-06\n",
      "5 7 5e-07\n",
      "5 7 1e-07\n",
      "5 7 5e-08\n",
      "5 7 1e-08\n",
      "5 8 1e-06\n",
      "5 8 5e-07\n",
      "5 8 1e-07\n",
      "5 8 5e-08\n",
      "5 8 1e-08\n",
      "6 0 1e-06\n",
      "6 0 5e-07\n",
      "6 0 1e-07\n",
      "6 0 5e-08\n",
      "6 0 1e-08\n",
      "6 1 1e-06\n",
      "6 1 5e-07\n",
      "6 1 1e-07\n",
      "6 1 5e-08\n",
      "6 1 1e-08\n",
      "6 2 1e-06\n",
      "6 2 5e-07\n",
      "6 2 1e-07\n",
      "6 2 5e-08\n",
      "6 2 1e-08\n",
      "6 3 1e-06\n",
      "6 3 5e-07\n",
      "6 3 1e-07\n",
      "6 3 5e-08\n",
      "6 3 1e-08\n",
      "6 4 1e-06\n",
      "6 4 5e-07\n",
      "6 4 1e-07\n",
      "6 4 5e-08\n",
      "6 4 1e-08\n",
      "6 5 1e-06\n",
      "6 5 5e-07\n",
      "6 5 1e-07\n",
      "6 5 5e-08\n",
      "6 5 1e-08\n",
      "6 6 1e-06\n",
      "6 6 5e-07\n",
      "6 6 1e-07\n",
      "6 6 5e-08\n",
      "6 6 1e-08\n",
      "6 7 1e-06\n",
      "6 7 5e-07\n",
      "6 7 1e-07\n",
      "6 7 5e-08\n",
      "6 7 1e-08\n",
      "6 8 1e-06\n",
      "6 8 5e-07\n",
      "6 8 1e-07\n",
      "6 8 5e-08\n",
      "6 8 1e-08\n",
      "7 0 1e-06\n",
      "7 0 5e-07\n",
      "7 0 1e-07\n",
      "7 0 5e-08\n",
      "7 0 1e-08\n",
      "7 1 1e-06\n",
      "7 1 5e-07\n",
      "7 1 1e-07\n",
      "7 1 5e-08\n",
      "7 1 1e-08\n",
      "7 2 1e-06\n",
      "7 2 5e-07\n",
      "7 2 1e-07\n",
      "7 2 5e-08\n",
      "7 2 1e-08\n",
      "7 3 1e-06\n",
      "7 3 5e-07\n",
      "7 3 1e-07\n",
      "7 3 5e-08\n",
      "7 3 1e-08\n",
      "7 4 1e-06\n",
      "7 4 5e-07\n",
      "7 4 1e-07\n",
      "7 4 5e-08\n",
      "7 4 1e-08\n",
      "7 5 1e-06\n",
      "7 5 5e-07\n",
      "7 5 1e-07\n",
      "7 5 5e-08\n",
      "7 5 1e-08\n",
      "7 6 1e-06\n",
      "7 6 5e-07\n",
      "7 6 1e-07\n",
      "7 6 5e-08\n",
      "7 6 1e-08\n",
      "7 7 1e-06\n",
      "7 7 5e-07\n",
      "7 7 1e-07\n",
      "7 7 5e-08\n",
      "7 7 1e-08\n",
      "7 8 1e-06\n",
      "7 8 5e-07\n",
      "7 8 1e-07\n",
      "7 8 5e-08\n",
      "7 8 1e-08\n",
      "8 0 1e-06\n",
      "8 0 5e-07\n",
      "8 0 1e-07\n",
      "8 0 5e-08\n",
      "8 0 1e-08\n",
      "8 1 1e-06\n",
      "8 1 5e-07\n",
      "8 1 1e-07\n",
      "8 1 5e-08\n",
      "8 1 1e-08\n",
      "8 2 1e-06\n",
      "8 2 5e-07\n",
      "8 2 1e-07\n",
      "8 2 5e-08\n",
      "8 2 1e-08\n",
      "8 3 1e-06\n",
      "8 3 5e-07\n",
      "8 3 1e-07\n",
      "8 3 5e-08\n",
      "8 3 1e-08\n",
      "8 4 1e-06\n",
      "8 4 5e-07\n",
      "8 4 1e-07\n",
      "8 4 5e-08\n",
      "8 4 1e-08\n",
      "8 5 1e-06\n",
      "8 5 5e-07\n",
      "8 5 1e-07\n",
      "8 5 5e-08\n",
      "8 5 1e-08\n",
      "8 6 1e-06\n",
      "8 6 5e-07\n",
      "8 6 1e-07\n",
      "8 6 5e-08\n",
      "8 6 1e-08\n",
      "8 7 1e-06\n",
      "8 7 5e-07\n",
      "8 7 1e-07\n",
      "8 7 5e-08\n",
      "8 7 1e-08\n",
      "8 8 1e-06\n",
      "8 8 5e-07\n",
      "8 8 1e-07\n",
      "8 8 5e-08\n",
      "8 8 1e-08\n",
      "9 0 1e-06\n",
      "9 0 5e-07\n",
      "9 0 1e-07\n",
      "9 0 5e-08\n",
      "9 0 1e-08\n",
      "9 1 1e-06\n",
      "9 1 5e-07\n",
      "9 1 1e-07\n",
      "9 1 5e-08\n",
      "9 1 1e-08\n",
      "9 2 1e-06\n",
      "9 2 5e-07\n",
      "9 2 1e-07\n",
      "9 2 5e-08\n",
      "9 2 1e-08\n",
      "9 3 1e-06\n",
      "9 3 5e-07\n",
      "9 3 1e-07\n",
      "9 3 5e-08\n",
      "9 3 1e-08\n",
      "9 4 1e-06\n",
      "9 4 5e-07\n",
      "9 4 1e-07\n",
      "9 4 5e-08\n",
      "9 4 1e-08\n",
      "9 5 1e-06\n",
      "9 5 5e-07\n",
      "9 5 1e-07\n",
      "9 5 5e-08\n",
      "9 5 1e-08\n",
      "9 6 1e-06\n",
      "9 6 5e-07\n",
      "9 6 1e-07\n",
      "9 6 5e-08\n",
      "9 6 1e-08\n",
      "9 7 1e-06\n",
      "9 7 5e-07\n",
      "9 7 1e-07\n",
      "9 7 5e-08\n",
      "9 7 1e-08\n",
      "9 8 1e-06\n",
      "9 8 5e-07\n",
      "9 8 1e-07\n",
      "9 8 5e-08\n",
      "9 8 1e-08\n",
      "10 0 1e-06\n",
      "10 0 5e-07\n",
      "10 0 1e-07\n",
      "10 0 5e-08\n",
      "10 0 1e-08\n",
      "10 1 1e-06\n",
      "10 1 5e-07\n",
      "10 1 1e-07\n",
      "10 1 5e-08\n",
      "10 1 1e-08\n",
      "10 2 1e-06\n",
      "10 2 5e-07\n",
      "10 2 1e-07\n",
      "10 2 5e-08\n",
      "10 2 1e-08\n",
      "10 3 1e-06\n",
      "10 3 5e-07\n",
      "10 3 1e-07\n",
      "10 3 5e-08\n",
      "10 3 1e-08\n",
      "10 4 1e-06\n",
      "10 4 5e-07\n",
      "10 4 1e-07\n",
      "10 4 5e-08\n",
      "10 4 1e-08\n",
      "10 5 1e-06\n",
      "10 5 5e-07\n",
      "10 5 1e-07\n",
      "10 5 5e-08\n",
      "10 5 1e-08\n",
      "10 6 1e-06\n",
      "10 6 5e-07\n",
      "10 6 1e-07\n",
      "10 6 5e-08\n",
      "10 6 1e-08\n",
      "10 7 1e-06\n",
      "10 7 5e-07\n",
      "10 7 1e-07\n",
      "10 7 5e-08\n",
      "10 7 1e-08\n",
      "10 8 1e-06\n",
      "10 8 5e-07\n",
      "10 8 1e-07\n",
      "10 8 5e-08\n",
      "10 8 1e-08\n",
      "11 0 1e-06\n",
      "11 0 5e-07\n",
      "11 0 1e-07\n",
      "11 0 5e-08\n",
      "11 0 1e-08\n",
      "11 1 1e-06\n",
      "11 1 5e-07\n",
      "11 1 1e-07\n",
      "11 1 5e-08\n",
      "11 1 1e-08\n",
      "11 2 1e-06\n",
      "11 2 5e-07\n",
      "11 2 1e-07\n",
      "11 2 5e-08\n",
      "11 2 1e-08\n",
      "11 3 1e-06\n",
      "11 3 5e-07\n",
      "11 3 1e-07\n",
      "11 3 5e-08\n",
      "11 3 1e-08\n",
      "11 4 1e-06\n",
      "11 4 5e-07\n",
      "11 4 1e-07\n",
      "11 4 5e-08\n",
      "11 4 1e-08\n",
      "11 5 1e-06\n",
      "11 5 5e-07\n",
      "11 5 1e-07\n",
      "11 5 5e-08\n",
      "11 5 1e-08\n",
      "11 6 1e-06\n",
      "11 6 5e-07\n",
      "11 6 1e-07\n",
      "11 6 5e-08\n",
      "11 6 1e-08\n",
      "11 7 1e-06\n",
      "11 7 5e-07\n",
      "11 7 1e-07\n",
      "11 7 5e-08\n",
      "11 7 1e-08\n",
      "11 8 1e-06\n",
      "11 8 5e-07\n",
      "11 8 1e-07\n",
      "11 8 5e-08\n",
      "11 8 1e-08\n",
      "12 0 1e-06\n",
      "12 0 5e-07\n",
      "12 0 1e-07\n",
      "12 0 5e-08\n",
      "12 0 1e-08\n",
      "12 1 1e-06\n",
      "12 1 5e-07\n",
      "12 1 1e-07\n",
      "12 1 5e-08\n",
      "12 1 1e-08\n",
      "12 2 1e-06\n",
      "12 2 5e-07\n",
      "12 2 1e-07\n",
      "12 2 5e-08\n",
      "12 2 1e-08\n",
      "12 3 1e-06\n",
      "12 3 5e-07\n",
      "12 3 1e-07\n",
      "12 3 5e-08\n",
      "12 3 1e-08\n",
      "12 4 1e-06\n",
      "12 4 5e-07\n",
      "12 4 1e-07\n",
      "12 4 5e-08\n",
      "12 4 1e-08\n",
      "12 5 1e-06\n",
      "12 5 5e-07\n",
      "12 5 1e-07\n",
      "12 5 5e-08\n",
      "12 5 1e-08\n",
      "12 6 1e-06\n",
      "12 6 5e-07\n",
      "12 6 1e-07\n",
      "12 6 5e-08\n",
      "12 6 1e-08\n",
      "12 7 1e-06\n",
      "12 7 5e-07\n",
      "12 7 1e-07\n",
      "12 7 5e-08\n",
      "12 7 1e-08\n",
      "12 8 1e-06\n",
      "12 8 5e-07\n",
      "12 8 1e-07\n",
      "12 8 5e-08\n",
      "12 8 1e-08\n",
      "13 0 1e-06\n",
      "13 0 5e-07\n",
      "13 0 1e-07\n",
      "13 0 5e-08\n",
      "13 0 1e-08\n"
     ]
    }
   ],
   "source": [
    "input_weight = 1e-2\n",
    "spectral_radius = 0.9\n",
    "regularization = 1e-5\n",
    "average_degree = 3\n",
    "leakage = 0\n",
    "forgets = np.array([1,0.9975,0.995,0.9925,0.99,0.9875,0.985,0.9825,0.98])\n",
    "inv_forgets = 1/forgets\n",
    "print(forgets)\n",
    "data_seed = 30\n",
    "cumulative = False\n",
    "w_LM_reg = True\n",
    "approx_LM_reg = True\n",
    "LM_regs = np.array([1e-6, 5e-7,1e-7,5e-8,1e-8])\n",
    "\n",
    "step = 0.05\n",
    "transient_length = int(50/step)\n",
    "data_length = int(3000/step)\n",
    "train_length = int(200/step)\n",
    "start_length = int(50/step)\n",
    "predict_length = int(20/step)\n",
    "predict_gap_length = int(5/step)\n",
    "num_predictions = 100\n",
    "num_trials = 30\n",
    "num_forgets = forgets.shape[0]\n",
    "approx_num_nodes = 300\n",
    "\n",
    "np.random.seed(data_seed)\n",
    "train_input_sequence = getLorenzData(data_length,r_t_cosine,dxdt_lorenz,tau = 0.05)\n",
    "\n",
    "input_size = train_input_sequence.shape[0]\n",
    "num_nodes = int(np.ceil(approx_num_nodes/input_size)*input_size);\n",
    "\n",
    "A_mat = sparse.random(num_nodes,num_nodes, density = average_degree/num_nodes)\n",
    "eg = linalg.eigs(A_mat, k = 1, return_eigenvectors=False)\n",
    "A_mat = spectral_radius/np.abs(eg[0])*A_mat\n",
    "\n",
    "q = int(np.floor(num_nodes/(input_size)))\n",
    "win = np.zeros((num_nodes,input_size))\n",
    "for i in range(input_size):\n",
    "    np.random.seed(i)\n",
    "    ip = (-1 + 2*np.random.randn(q));\n",
    "    win[i*q:(i+1)*q,i] = input_weight*ip;\n",
    "\n",
    "predictions = np.zeros((input_size,predict_length,num_predictions,num_trials,num_forgets))\n",
    "truths = np.zeros((input_size,predict_length,num_predictions,num_trials,num_forgets))\n",
    "errors = np.zeros((predict_length,num_predictions,num_trials,num_forgets))\n",
    "valid_times = np.zeros((num_predictions,num_trials,num_forgets))\n",
    "wouts = np.zeros((input_size,num_nodes,num_predictions,num_trials,num_forgets))\n",
    "times = np.zeros(num_predictions)\n",
    "\n",
    "predictions_norm = np.zeros((input_size,predict_length,num_predictions,num_trials,num_forgets))\n",
    "errors_norm = np.zeros((predict_length,num_predictions,num_trials,num_forgets))\n",
    "valid_times_norm = np.zeros((num_predictions,num_trials,num_forgets))\n",
    "wouts_norm = np.zeros((input_size,num_nodes,num_predictions,num_trials,num_forgets))\n",
    "for data_seed in range(num_trials):\n",
    "    np.random.seed(data_seed)\n",
    "    train_input_sequence = getLorenzData(data_length,r_t_cosine,dxdt_lorenz,tau = 0.05)\n",
    "    for k in range(num_forgets):\n",
    "        for LM_reg in LM_regs:\n",
    "            valid_time = np.zeros(num_predictions)\n",
    "            times = np.zeros(num_predictions)\n",
    "\n",
    "            x = np.zeros(num_nodes)\n",
    "            states = np.zeros((num_nodes, start_length))\n",
    "\n",
    "            for t in range(transient_length):\n",
    "                x = advanceReservoir(win,A_mat,x,train_input_sequence[:,t],leakage)\n",
    "\n",
    "            states[:,0] = x;\n",
    "\n",
    "            for t in range(start_length-1):\n",
    "                states[:,t+1] = advanceReservoir(win,A_mat,states[:,t],\\\n",
    "                        train_input_sequence[:,t+transient_length],leakage)\n",
    "\n",
    "            x = states[:,-1]\n",
    "\n",
    "            aug_states = np.copy(states)\n",
    "            aug_states[::2,:] = np.power(states[::2,:],2)\n",
    "            idenmat = regularization*sparse.identity(num_nodes)\n",
    "            s_mat = np.diag(np.power(forgets[k],np.arange(start_length)[::-1]))\n",
    "            data_trstates = np.matmul(np.matmul(train_input_sequence[:,transient_length:transient_length+start_length],\\\n",
    "                                                s_mat),\\\n",
    "                                      np.transpose(aug_states))\n",
    "            states_trstates = np.matmul(np.matmul(aug_states,s_mat),np.transpose(aug_states))\n",
    "            states_trstates_inv = pinv(states_trstates + idenmat)\n",
    "            wout = np.matmul(data_trstates,states_trstates_inv)\n",
    "\n",
    "            wout_norm = np.copy(wout)\n",
    "            x_norm = np.copy(x)\n",
    "\n",
    "            error_cutoff = 1;\n",
    "            if w_LM_reg:\n",
    "                LM_idenmat = sparse.identity(num_nodes)\n",
    "            for pred in range(num_predictions):\n",
    "                prediction = getPrediction(win,A_mat,wout,x,predict_length,leakage)\n",
    "                start_pred_idx = transient_length + start_length + pred*predict_gap_length - 1\n",
    "                times[pred] = start_pred_idx*step\n",
    "                truth = train_input_sequence[:,start_pred_idx :start_pred_idx + predict_length]\n",
    "                error = np.linalg.norm(prediction - truth, axis = 0)/np.sqrt(np.mean(truth**2))\n",
    "\n",
    "                for i in range(predict_length):\n",
    "                    if error[i] > error_cutoff:\n",
    "                        break\n",
    "                    else:\n",
    "                        valid_times[pred] += 1\n",
    "\n",
    "                for i in range(predict_gap_length):\n",
    "                    x = advanceReservoir(win,A_mat,x,train_input_sequence[:,start_pred_idx + i],leakage)\n",
    "                    aug_x = np.copy(x)\n",
    "                    aug_x[::2] = np.power(x[::2],2)\n",
    "                    data_trstates = forgets[k]*data_trstates + \\\n",
    "                        np.outer(train_input_sequence[:,start_pred_idx + i + 1],aug_x)\n",
    "\n",
    "                    states_trstates_inv = inv_forgets[k]*(states_trstates_inv - 1.0/\\\n",
    "                            (1+inv_forgets[k]*np.dot(np.dot(aug_x,states_trstates_inv),aug_x))*\\\n",
    "                            np.outer(np.dot(states_trstates_inv,aug_x),np.dot(aug_x,states_trstates_inv))\\\n",
    "                            *inv_forgets[k])\n",
    "                    if w_LM_reg:\n",
    "                        if approx_LM_reg:\n",
    "                            states_trstates_inv = states_trstates_inv - \\\n",
    "                                LM_reg*np.matmul(states_trstates_inv,states_trstates_inv)\n",
    "                        else:\n",
    "                            states_trstates_inv = np.transpose(solve(np.transpose(LM_reg*states_trstates_inv + \\\n",
    "                                LM_idenmat),np.transpose(states_trstates_inv)))\n",
    "\n",
    "\n",
    "\n",
    "                wout = np.matmul(data_trstates,states_trstates_inv)\n",
    "                # np.savetxt('Lorenz63Data/lorenz_prediction_lam%f_reg%f_seed%d_pred%d.csv' % (forgets[k],LM_reg,data_seed,pred),prediction,delimiter = ',')\n",
    "                # np.savetxt('Lorenz63Data/lorenz_error_lam%f_reg%f_seed%d_pred%d.csv' % (forgets[k],LM_reg,data_seed,pred),error,delimiter = ',')\n",
    "                # if k == 0 and LM_reg == LM_regs[0]:\n",
    "                    # np.savetxt('Lorenz63Data/lorenz_truth_seed%d_pred%d.csv' % (data_seed,pred),truth,delimiter = ',')\n",
    "            print(data_seed, k, LM_reg)\n",
    "            np.savetxt('Lorenz63Data/lorenz_valid_times_lam%f_reg%e_seed%d.csv' % (forgets[k],LM_reg,data_seed),valid_time,delimiter = ',')\n",
    "    \n",
    "    \"\"\"\n",
    "        # print(k, data_seed)\n",
    "        # print(valid_times)\n",
    "\n",
    "        if cumulative:\n",
    "            for pred in range(num_predictions):\n",
    "                wouts_norm[:,:,pred,data_seed,k] = wout_norm\n",
    "                predictions_norm[:,:,pred,data_seed,k] = getPrediction(win,A_mat,wout_norm,x_norm,predict_length,leakage)\n",
    "                start_pred_idx = transient_length + start_length + pred*predict_gap_length - 1\n",
    "                errors_norm[:,pred,data_seed,k] = np.linalg.norm(predictions_norm[:,:,pred,data_seed,k] - \\\n",
    "                                                               truths[:,:,pred,data_seed,k], axis = 0)/\\\n",
    "                                                np.sqrt(np.mean(truths[:,:,pred,data_seed,k]**2))\n",
    "\n",
    "                for i in range(predict_length):\n",
    "                    if errors_norm[i,pred,data_seed,k] > error_cutoff:\n",
    "                        break\n",
    "                    else:\n",
    "                        valid_times_norm[pred,data_seed,k] += 1\n",
    "\n",
    "                new_states = np.zeros((num_nodes,predict_gap_length))\n",
    "                for i in range(predict_gap_length):\n",
    "                    x_norm = advanceReservoir(win,A_mat,x_norm,train_input_sequence[:,start_pred_idx + i],leakage)\n",
    "                    new_states[:,i] = x_norm\n",
    "\n",
    "                new_aug_states = np.copy(new_states)\n",
    "                new_aug_states[::2,:] = np.power(new_states[::2,:],2)\n",
    "                aug_states = np.concatenate((aug_states,new_aug_states),axis = 1)\n",
    "                s_mat = np.diag(np.power(forgets[k],np.arange(aug_states.shape[1])[::-1]))\n",
    "                data_trstates = np.matmul(np.matmul(train_input_sequence[:,\\\n",
    "                                                                         transient_length:start_pred_idx + predict_gap_length + 1],\\\n",
    "                                                s_mat),\\\n",
    "                                      np.transpose(aug_states))\n",
    "                states_trstates = np.matmul(np.matmul(aug_states,s_mat),np.transpose(aug_states))\n",
    "\n",
    "                wout_norm = np.transpose(solve(np.transpose(states_trstates + idenmat),np.transpose(data_trstates)))\n",
    "\n",
    "\n",
    "            # print(valid_times_norm)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wouts_abs = np.sqrt(np.mean((wouts - wouts_norm)**2,axis = (0,1)))\n",
    "plt.plot(wouts_abs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itr = 50\n",
    "run = 15\n",
    "fg  = 8\n",
    "times_all = step*(transient_length + start_length + np.arange(num_predictions)*predict_gap_length)\n",
    "plt.plot(times_all,r_t_cosine(times))\n",
    "plt.plot(times[itr],r_t_cosine(times[itr]),'r.')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('r(t)')\n",
    "plt.savefig('r_t_cosine_itr%d_run%d_forget%d.pdf' % (itr,run,fg))\n",
    "plt.show()\n",
    "plt.plot(np.arange(predict_length)*step,truths[0,:,itr,run,fg],label = 'Truth')\n",
    "plt.plot(np.arange(predict_length)*step,predictions[0,:,itr,run,fg],label = 'Reservoir w/ RLS')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('x(t)')\n",
    "tlfg = step*np.log(1/2)/np.log(forgets[fg])\n",
    "plt.title('$t_\\lambda = %f$' % tlfg)\n",
    "plt.legend()\n",
    "plt.savefig('x_t_truth_vs_pred_itr%d_run%d_forget%d_wapproxLMreg.pdf' % (itr,run,fg))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx1 = 5\n",
    "tl1 = step*np.log(1/2)/np.log(forgets[idx1])\n",
    "idx2 = 8\n",
    "tl2 = step*np.log(1/2)/np.log(forgets[idx2])\n",
    "plt.errorbar(times,np.mean(valid_times[:,:,0],axis = 1)*step,step*np.std(valid_times[:,:,0],axis = 1),label = '$t_\\lambda = \\infty$')\n",
    "plt.errorbar(times,np.mean(valid_times[:,:,idx1],axis = 1)*step,step*np.std(valid_times[:,:,idx1],axis = 1),label = '$t_\\lambda = %f$' % tl1)\n",
    "plt.errorbar(times,np.mean(valid_times[:,:,idx2],axis = 1)*step,step*np.std(valid_times[:,:,idx2],axis = 1),label = '$t_\\lambda = %f$' % tl2)\n",
    "plt.legend()\n",
    "plt.xlabel('Prediction Start Time')\n",
    "plt.ylabel('Valid Time')\n",
    "plt.title('300 Reservoir Nodes, $\\mu = 10^{-6}$')\n",
    "plt.savefig('valid_time_vs_start_time_wapproxLMreg.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(predictions[0,:,80,5,6])\n",
    "plt.plot(truths[0,:,80,5,6])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
