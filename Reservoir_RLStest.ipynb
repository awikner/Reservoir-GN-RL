{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sparse\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.sparse import linalg\n",
    "from scipy.linalg import solve, pinv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dxdt_lorenz(x,time,r_t, sigma = 10., beta = 8/3, rho = 28.):\n",
    "    return np.array([sigma*(- x[0] + x[1]),\\\n",
    "                     r_t(time)*rho*x[0] - x[1] - x[0]*x[2],\\\n",
    "                     x[0]*x[1]-beta*x[2]])\n",
    "    \n",
    "def rk4(x, time, tau, r_t, dxdt):\n",
    "    k1 = dxdt(x, time, r_t)\n",
    "    k2 = dxdt(x + k1/2*tau, time + tau/2, r_t)\n",
    "    k3 = dxdt(x + k2/2*tau, time + tau/2, r_t)\n",
    "    k4 = dxdt(x + tau*k3, time + tau, r_t)\n",
    "    \n",
    "    xnext = x + 1/6*tau*(k1+2*k2+2*k3+k4)\n",
    "    return xnext\n",
    "\n",
    "def getLorenzData(data_length, r_t, dxdt_lorenz,transient_length = 1000, tau = 0.1):\n",
    "    x = np.random.rand(3)\n",
    "    time = -transient_length*tau\n",
    "    for i in range(0,transient_length):\n",
    "        x = rk4(x,time,tau,r_t,dxdt_lorenz)\n",
    "        time += tau\n",
    "    \n",
    "    data = np.zeros((3,data_length))\n",
    "    data[:,0] = x\n",
    "    for i in range(0,data_length-1):\n",
    "        data[:,i+1] = rk4(data[:,i],time,tau,r_t,dxdt_lorenz)\n",
    "        time += tau\n",
    "        \n",
    "    return data\n",
    "\n",
    "def r_t_cosine(time, period = 5000, max_height = 48/28):\n",
    "    r = 1 + (max_height-1.)/2 - (max_height-1)/2*np.cos(2*np.pi/period*time)\n",
    "    return r\n",
    "\n",
    "def r_t_const(time, value = 1):\n",
    "    # Function for constant rho value\n",
    "    r = value\n",
    "    return r\n",
    "\n",
    "def advanceReservoir(win,A_mat,x,u,leakage):\n",
    "    x_next = leakage*x + (1-leakage)*np.tanh(A_mat.dot(x) + np.matmul(win,u))\n",
    "    return x_next\n",
    "\n",
    "def getPrediction(win, A_mat, wout, x, predict_length, leakage):\n",
    "    prediction = np.zeros((wout.shape[0],predict_length))\n",
    "    aug_x = np.copy(x)\n",
    "    aug_x[::2] = np.power(x[::2],2)\n",
    "    prediction[:,0] = np.matmul(wout,aug_x)\n",
    "    \n",
    "    for pred_idx in range(0,predict_length - 1):\n",
    "        x = advanceReservoir(win, A_mat, x, prediction[:,pred_idx], leakage)\n",
    "        aug_x = np.copy(x)\n",
    "        aug_x[::2] = np.power(x[::2],2)\n",
    "        prediction[:,pred_idx + 1] = np.matmul(wout,aug_x)\n",
    "        \n",
    "    return prediction\n",
    "\n",
    "def CountFrequency(my_list): \n",
    "  \n",
    "    # Creating an empty dictionary  \n",
    "    freq = {} \n",
    "    for item in my_list: \n",
    "        if (item in freq): \n",
    "            freq[item] += 1\n",
    "        else: \n",
    "            freq[item] = 1\n",
    "        \n",
    "    return freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.995  0.9925 0.99   0.9875 0.985  0.9825 0.98  ]\n"
     ]
    }
   ],
   "source": [
    "input_weight = 1e-2\n",
    "spectral_radius = 0.9\n",
    "regularization = 1e-5\n",
    "average_degree = 3\n",
    "leakage = 0\n",
    "forgets = np.array([0.995,0.9925,0.99,0.9875,0.985,0.9825,0.98])\n",
    "# forgets = np.array([0.9825])\n",
    "inv_forgets = 1/forgets\n",
    "print(forgets)\n",
    "data_seed = 30\n",
    "cumulative = False\n",
    "w_LM_reg = True\n",
    "approx_LM_reg = True\n",
    "LM_regs = np.array([1e-8])\n",
    "\n",
    "step = 0.05\n",
    "transient_length = int(50/step)\n",
    "data_length = int(3000/step)\n",
    "train_length = int(200/step)\n",
    "start_length = int(50/step)\n",
    "predict_length = int(20/step)\n",
    "predict_gap_length = int(5/step)\n",
    "num_predictions = 100\n",
    "num_trials = 50\n",
    "num_forgets = forgets.shape[0]\n",
    "approx_num_nodes = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 1e-08\n",
      "0 1 1e-08\n",
      "0 2 1e-08\n",
      "0 3 1e-08\n",
      "0 4 1e-08\n",
      "0 5 1e-08\n",
      "0 6 1e-08\n",
      "1 0 1e-08\n",
      "1 1 1e-08\n",
      "1 2 1e-08\n",
      "1 3 1e-08\n",
      "1 4 1e-08\n",
      "1 5 1e-08\n",
      "1 6 1e-08\n",
      "2 0 1e-08\n",
      "2 1 1e-08\n",
      "2 2 1e-08\n",
      "2 3 1e-08\n",
      "2 4 1e-08\n",
      "2 5 1e-08\n",
      "2 6 1e-08\n",
      "3 0 1e-08\n",
      "3 1 1e-08\n",
      "3 2 1e-08\n",
      "3 3 1e-08\n",
      "3 4 1e-08\n",
      "3 5 1e-08\n",
      "3 6 1e-08\n",
      "4 0 1e-08\n",
      "4 1 1e-08\n",
      "4 2 1e-08\n",
      "4 3 1e-08\n",
      "4 4 1e-08\n",
      "4 5 1e-08\n",
      "4 6 1e-08\n",
      "5 0 1e-08\n",
      "5 1 1e-08\n",
      "5 2 1e-08\n",
      "5 3 1e-08\n",
      "5 4 1e-08\n",
      "5 5 1e-08\n",
      "5 6 1e-08\n",
      "6 0 1e-08\n",
      "6 1 1e-08\n",
      "6 2 1e-08\n",
      "6 3 1e-08\n",
      "6 4 1e-08\n",
      "6 5 1e-08\n",
      "6 6 1e-08\n",
      "7 0 1e-08\n",
      "7 1 1e-08\n",
      "7 2 1e-08\n",
      "7 3 1e-08\n",
      "7 4 1e-08\n",
      "7 5 1e-08\n",
      "7 6 1e-08\n",
      "8 0 1e-08\n",
      "8 1 1e-08\n",
      "8 2 1e-08\n",
      "8 3 1e-08\n",
      "8 4 1e-08\n",
      "8 5 1e-08\n",
      "8 6 1e-08\n",
      "9 0 1e-08\n",
      "9 1 1e-08\n",
      "9 2 1e-08\n",
      "9 3 1e-08\n",
      "9 4 1e-08\n",
      "9 5 1e-08\n",
      "9 6 1e-08\n",
      "10 0 1e-08\n",
      "10 1 1e-08\n",
      "10 2 1e-08\n",
      "10 3 1e-08\n",
      "10 4 1e-08\n",
      "10 5 1e-08\n",
      "10 6 1e-08\n",
      "11 0 1e-08\n",
      "11 1 1e-08\n",
      "11 2 1e-08\n",
      "11 3 1e-08\n",
      "11 4 1e-08\n",
      "11 5 1e-08\n",
      "11 6 1e-08\n",
      "12 0 1e-08\n",
      "12 1 1e-08\n",
      "12 2 1e-08\n",
      "12 3 1e-08\n",
      "12 4 1e-08\n",
      "12 5 1e-08\n",
      "12 6 1e-08\n",
      "13 0 1e-08\n",
      "13 1 1e-08\n",
      "13 2 1e-08\n",
      "13 3 1e-08\n",
      "13 4 1e-08\n",
      "13 5 1e-08\n",
      "13 6 1e-08\n",
      "14 0 1e-08\n",
      "14 1 1e-08\n",
      "14 2 1e-08\n",
      "14 3 1e-08\n",
      "14 4 1e-08\n",
      "14 5 1e-08\n",
      "14 6 1e-08\n",
      "15 0 1e-08\n",
      "15 1 1e-08\n",
      "15 2 1e-08\n",
      "15 3 1e-08\n",
      "15 4 1e-08\n",
      "15 5 1e-08\n",
      "15 6 1e-08\n",
      "16 0 1e-08\n",
      "16 1 1e-08\n",
      "16 2 1e-08\n",
      "16 3 1e-08\n",
      "16 4 1e-08\n",
      "16 5 1e-08\n",
      "16 6 1e-08\n",
      "17 0 1e-08\n",
      "17 1 1e-08\n",
      "17 2 1e-08\n",
      "17 3 1e-08\n",
      "17 4 1e-08\n",
      "17 5 1e-08\n",
      "17 6 1e-08\n",
      "18 0 1e-08\n",
      "18 1 1e-08\n",
      "18 2 1e-08\n",
      "18 3 1e-08\n",
      "18 4 1e-08\n",
      "18 5 1e-08\n",
      "18 6 1e-08\n",
      "19 0 1e-08\n",
      "19 1 1e-08\n",
      "19 2 1e-08\n",
      "19 3 1e-08\n",
      "19 4 1e-08\n",
      "19 5 1e-08\n",
      "19 6 1e-08\n",
      "20 0 1e-08\n",
      "20 1 1e-08\n",
      "20 2 1e-08\n",
      "20 3 1e-08\n",
      "20 4 1e-08\n",
      "20 5 1e-08\n",
      "20 6 1e-08\n",
      "21 0 1e-08\n",
      "21 1 1e-08\n",
      "21 2 1e-08\n",
      "21 3 1e-08\n",
      "21 4 1e-08\n",
      "21 5 1e-08\n",
      "21 6 1e-08\n",
      "22 0 1e-08\n",
      "22 1 1e-08\n",
      "22 2 1e-08\n",
      "22 3 1e-08\n",
      "22 4 1e-08\n",
      "22 5 1e-08\n",
      "22 6 1e-08\n",
      "23 0 1e-08\n",
      "23 1 1e-08\n",
      "23 2 1e-08\n",
      "23 3 1e-08\n",
      "23 4 1e-08\n",
      "23 5 1e-08\n",
      "23 6 1e-08\n",
      "24 0 1e-08\n",
      "24 1 1e-08\n",
      "24 2 1e-08\n",
      "24 3 1e-08\n",
      "24 4 1e-08\n",
      "24 5 1e-08\n",
      "24 6 1e-08\n",
      "25 0 1e-08\n",
      "25 1 1e-08\n",
      "25 2 1e-08\n",
      "25 3 1e-08\n",
      "25 4 1e-08\n",
      "25 5 1e-08\n",
      "25 6 1e-08\n",
      "26 0 1e-08\n",
      "26 1 1e-08\n",
      "26 2 1e-08\n",
      "26 3 1e-08\n",
      "26 4 1e-08\n",
      "26 5 1e-08\n",
      "26 6 1e-08\n",
      "27 0 1e-08\n",
      "27 1 1e-08\n",
      "27 2 1e-08\n",
      "27 3 1e-08\n",
      "27 4 1e-08\n",
      "27 5 1e-08\n",
      "27 6 1e-08\n",
      "28 0 1e-08\n",
      "28 1 1e-08\n",
      "28 2 1e-08\n",
      "28 3 1e-08\n",
      "28 4 1e-08\n",
      "28 5 1e-08\n",
      "28 6 1e-08\n",
      "29 0 1e-08\n",
      "29 1 1e-08\n",
      "29 2 1e-08\n",
      "29 3 1e-08\n",
      "29 4 1e-08\n",
      "29 5 1e-08\n",
      "29 6 1e-08\n",
      "30 0 1e-08\n",
      "30 1 1e-08\n",
      "30 2 1e-08\n",
      "30 3 1e-08\n",
      "30 4 1e-08\n",
      "30 5 1e-08\n",
      "30 6 1e-08\n",
      "31 0 1e-08\n",
      "31 1 1e-08\n",
      "31 2 1e-08\n",
      "31 3 1e-08\n",
      "31 4 1e-08\n",
      "31 5 1e-08\n",
      "31 6 1e-08\n",
      "32 0 1e-08\n",
      "32 1 1e-08\n",
      "32 2 1e-08\n",
      "32 3 1e-08\n",
      "32 4 1e-08\n",
      "32 5 1e-08\n",
      "32 6 1e-08\n",
      "33 0 1e-08\n",
      "33 1 1e-08\n",
      "33 2 1e-08\n",
      "33 3 1e-08\n",
      "33 4 1e-08\n",
      "33 5 1e-08\n",
      "33 6 1e-08\n",
      "34 0 1e-08\n",
      "34 1 1e-08\n",
      "34 2 1e-08\n",
      "34 3 1e-08\n",
      "34 4 1e-08\n",
      "34 5 1e-08\n",
      "34 6 1e-08\n",
      "35 0 1e-08\n",
      "35 1 1e-08\n",
      "35 2 1e-08\n",
      "35 3 1e-08\n",
      "35 4 1e-08\n",
      "35 5 1e-08\n",
      "35 6 1e-08\n",
      "36 0 1e-08\n",
      "36 1 1e-08\n",
      "36 2 1e-08\n",
      "36 3 1e-08\n",
      "36 4 1e-08\n",
      "36 5 1e-08\n",
      "36 6 1e-08\n",
      "37 0 1e-08\n",
      "37 1 1e-08\n",
      "37 2 1e-08\n",
      "37 3 1e-08\n",
      "37 4 1e-08\n",
      "37 5 1e-08\n",
      "37 6 1e-08\n",
      "38 0 1e-08\n",
      "38 1 1e-08\n",
      "38 2 1e-08\n",
      "38 3 1e-08\n",
      "38 4 1e-08\n",
      "38 5 1e-08\n",
      "38 6 1e-08\n",
      "39 0 1e-08\n",
      "39 1 1e-08\n",
      "39 2 1e-08\n",
      "39 3 1e-08\n",
      "39 4 1e-08\n",
      "39 5 1e-08\n",
      "39 6 1e-08\n",
      "40 0 1e-08\n",
      "40 1 1e-08\n",
      "40 2 1e-08\n",
      "40 3 1e-08\n",
      "40 4 1e-08\n",
      "40 5 1e-08\n",
      "40 6 1e-08\n",
      "41 0 1e-08\n",
      "41 1 1e-08\n",
      "41 2 1e-08\n",
      "41 3 1e-08\n",
      "41 4 1e-08\n",
      "41 5 1e-08\n",
      "41 6 1e-08\n",
      "42 0 1e-08\n",
      "42 1 1e-08\n",
      "42 2 1e-08\n",
      "42 3 1e-08\n",
      "42 4 1e-08\n",
      "42 5 1e-08\n",
      "42 6 1e-08\n",
      "43 0 1e-08\n",
      "43 1 1e-08\n",
      "43 2 1e-08\n",
      "43 3 1e-08\n",
      "43 4 1e-08\n",
      "43 5 1e-08\n",
      "43 6 1e-08\n",
      "44 0 1e-08\n",
      "44 1 1e-08\n",
      "44 2 1e-08\n",
      "44 3 1e-08\n",
      "44 4 1e-08\n",
      "44 5 1e-08\n",
      "44 6 1e-08\n",
      "45 0 1e-08\n",
      "45 1 1e-08\n",
      "45 2 1e-08\n",
      "45 3 1e-08\n",
      "45 4 1e-08\n",
      "45 5 1e-08\n",
      "45 6 1e-08\n",
      "46 0 1e-08\n",
      "46 1 1e-08\n",
      "46 2 1e-08\n",
      "46 3 1e-08\n",
      "46 4 1e-08\n",
      "46 5 1e-08\n",
      "46 6 1e-08\n",
      "47 0 1e-08\n",
      "47 1 1e-08\n",
      "47 2 1e-08\n",
      "47 3 1e-08\n",
      "47 4 1e-08\n",
      "47 5 1e-08\n",
      "47 6 1e-08\n",
      "48 0 1e-08\n",
      "48 1 1e-08\n",
      "48 2 1e-08\n",
      "48 3 1e-08\n",
      "48 4 1e-08\n",
      "48 5 1e-08\n",
      "48 6 1e-08\n",
      "49 0 1e-08\n",
      "49 1 1e-08\n",
      "49 2 1e-08\n",
      "49 3 1e-08\n",
      "49 4 1e-08\n",
      "49 5 1e-08\n",
      "49 6 1e-08\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(data_seed)\n",
    "train_input_sequence = getLorenzData(data_length,r_t_cosine,dxdt_lorenz,tau = 0.05)\n",
    "\n",
    "input_size = train_input_sequence.shape[0]\n",
    "num_nodes = int(np.ceil(approx_num_nodes/input_size)*input_size);\n",
    "\n",
    "A_mat = sparse.random(num_nodes,num_nodes, density = average_degree/num_nodes)\n",
    "eg = linalg.eigs(A_mat, k = 1, return_eigenvectors=False)\n",
    "A_mat = spectral_radius/np.abs(eg[0])*A_mat\n",
    "\n",
    "q = int(np.floor(num_nodes/(input_size)))\n",
    "win = np.zeros((num_nodes,input_size))\n",
    "for i in range(input_size):\n",
    "    np.random.seed(i)\n",
    "    ip = (-1 + 2*np.random.randn(q));\n",
    "    win[i*q:(i+1)*q,i] = input_weight*ip;\n",
    "\n",
    "predictions = np.zeros((input_size,predict_length,num_predictions,num_trials,num_forgets))\n",
    "truths = np.zeros((input_size,predict_length,num_predictions,num_trials,num_forgets))\n",
    "errors = np.zeros((predict_length,num_predictions,num_trials,num_forgets))\n",
    "valid_times = np.zeros((num_predictions,num_trials,num_forgets))\n",
    "wouts = np.zeros((input_size,num_nodes,num_predictions,num_trials,num_forgets))\n",
    "times = np.zeros(num_predictions)\n",
    "\n",
    "predictions_norm = np.zeros((input_size,predict_length,num_predictions,num_trials,num_forgets))\n",
    "errors_norm = np.zeros((predict_length,num_predictions,num_trials,num_forgets))\n",
    "valid_times_norm = np.zeros((num_predictions,num_trials,num_forgets))\n",
    "wouts_norm = np.zeros((input_size,num_nodes,num_predictions,num_trials,num_forgets))\n",
    "\n",
    "plot_itr = 50;\n",
    "for data_seed in range(num_trials):\n",
    "    np.random.seed(data_seed)\n",
    "    train_input_sequence = getLorenzData(data_length,r_t_cosine,dxdt_lorenz,tau = 0.05)\n",
    "    for k in range(num_forgets):\n",
    "        for LM_reg in LM_regs:\n",
    "            valid_time = np.zeros(num_predictions)\n",
    "            times = np.zeros(num_predictions)\n",
    "\n",
    "            x = np.zeros(num_nodes)\n",
    "            states = np.zeros((num_nodes, start_length))\n",
    "\n",
    "            for t in range(transient_length):\n",
    "                x = advanceReservoir(win,A_mat,x,train_input_sequence[:,t],leakage)\n",
    "\n",
    "            states[:,0] = x;\n",
    "\n",
    "            for t in range(start_length-1):\n",
    "                states[:,t+1] = advanceReservoir(win,A_mat,states[:,t],\\\n",
    "                        train_input_sequence[:,t+transient_length],leakage)\n",
    "\n",
    "            x = states[:,-1]\n",
    "\n",
    "            aug_states = np.copy(states)\n",
    "            aug_states[::2,:] = np.power(states[::2,:],2)\n",
    "            idenmat = regularization*sparse.identity(num_nodes)\n",
    "            s_mat = np.diag(np.power(forgets[k],np.arange(start_length)[::-1]))\n",
    "            data_trstates = np.matmul(np.matmul(train_input_sequence[:,transient_length:transient_length+start_length],\\\n",
    "                                                s_mat),\\\n",
    "                                      np.transpose(aug_states))\n",
    "            states_trstates = np.matmul(np.matmul(aug_states,s_mat),np.transpose(aug_states))\n",
    "            states_trstates_inv = pinv(states_trstates + idenmat)\n",
    "            wout = np.matmul(data_trstates,states_trstates_inv)\n",
    "\n",
    "            wout_norm = np.copy(wout)\n",
    "            x_norm = np.copy(x)\n",
    "\n",
    "            error_cutoff = 1;\n",
    "            if w_LM_reg:\n",
    "                LM_idenmat = sparse.identity(num_nodes)\n",
    "            for pred in range(num_predictions):\n",
    "                prediction = getPrediction(win,A_mat,wout,x,predict_length,leakage)\n",
    "                    \n",
    "                start_pred_idx = transient_length + start_length + pred*predict_gap_length - 1\n",
    "                times[pred] = start_pred_idx*step\n",
    "                truth = train_input_sequence[:,start_pred_idx :start_pred_idx + predict_length]\n",
    "                # plt.plot(np.arange(predict_length)*step,truth[0,:],label = 'Truth')\n",
    "                # plt.plot(np.arange(predict_length)*step,prediction[0,:],label = 'Reservoir w/ RLS')\n",
    "                # plt.xlabel('Time')\n",
    "                # plt.ylabel('x(t)')\n",
    "                # tlfg = step*np.log(1/2)/np.log(forgets[k])\n",
    "                # plt.title('$t_\\lambda = %f$' % tlfg)\n",
    "                # plt.legend()\n",
    "                # plt.show()\n",
    "                error = np.linalg.norm(prediction - truth, axis = 0)/np.sqrt(np.mean(truth**2))\n",
    "\n",
    "                for i in range(predict_length):\n",
    "                    if error[i] > error_cutoff:\n",
    "                        break\n",
    "                    else:\n",
    "                        valid_time[pred] += 1\n",
    "\n",
    "                for i in range(predict_gap_length):\n",
    "                    x = advanceReservoir(win,A_mat,x,train_input_sequence[:,start_pred_idx + i],leakage)\n",
    "                    aug_x = np.copy(x)\n",
    "                    aug_x[::2] = np.power(x[::2],2)\n",
    "                    data_trstates = forgets[k]*data_trstates + \\\n",
    "                        np.outer(train_input_sequence[:,start_pred_idx + i + 1],aug_x)\n",
    "\n",
    "                    states_trstates_inv = inv_forgets[k]*(states_trstates_inv - 1.0/\\\n",
    "                            (1+inv_forgets[k]*np.dot(np.dot(aug_x,states_trstates_inv),aug_x))*\\\n",
    "                            np.outer(np.dot(states_trstates_inv,aug_x),np.dot(aug_x,states_trstates_inv))\\\n",
    "                            *inv_forgets[k])\n",
    "                    if w_LM_reg:\n",
    "                        if approx_LM_reg:\n",
    "                            states_trstates_inv = states_trstates_inv - \\\n",
    "                                LM_reg*np.matmul(states_trstates_inv,states_trstates_inv)\n",
    "                        else:\n",
    "                            states_trstates_inv = np.transpose(solve(np.transpose(LM_reg*states_trstates_inv + \\\n",
    "                                LM_idenmat),np.transpose(states_trstates_inv)))\n",
    "\n",
    "\n",
    "\n",
    "                wout = np.matmul(data_trstates,states_trstates_inv)\n",
    "                # np.savetxt('Lorenz63Data/lorenz_prediction_lam%f_reg%f_seed%d_pred%d.csv' % (forgets[k],LM_reg,data_seed,pred),prediction,delimiter = ',')\n",
    "                # np.savetxt('Lorenz63Data/lorenz_error_lam%f_reg%f_seed%d_pred%d.csv' % (forgets[k],LM_reg,data_seed,pred),error,delimiter = ',')\n",
    "                # if k == 0 and LM_reg == LM_regs[0]:\n",
    "                    # np.savetxt('Lorenz63Data/lorenz_truth_seed%d_pred%d.csv' % (data_seed,pred),truth,delimiter = ',')\n",
    "            print(data_seed, k, LM_reg)\n",
    "            np.savetxt('Lorenz63Data/lorenz_valid_times_period5000_lam%f_reg%e_seed%d.csv' % (forgets[k],LM_reg,data_seed),valid_time,delimiter = ',')\n",
    "    \n",
    "    \"\"\"\n",
    "        # print(k, data_seed)\n",
    "        # print(valid_times)\n",
    "\n",
    "        if cumulative:\n",
    "            for pred in range(num_predictions):\n",
    "                wouts_norm[:,:,pred,data_seed,k] = wout_norm\n",
    "                predictions_norm[:,:,pred,data_seed,k] = getPrediction(win,A_mat,wout_norm,x_norm,predict_length,leakage)\n",
    "                start_pred_idx = transient_length + start_length + pred*predict_gap_length - 1\n",
    "                errors_norm[:,pred,data_seed,k] = np.linalg.norm(predictions_norm[:,:,pred,data_seed,k] - \\\n",
    "                                                               truths[:,:,pred,data_seed,k], axis = 0)/\\\n",
    "                                                np.sqrt(np.mean(truths[:,:,pred,data_seed,k]**2))\n",
    "\n",
    "                for i in range(predict_length):\n",
    "                    if errors_norm[i,pred,data_seed,k] > error_cutoff:\n",
    "                        break\n",
    "                    else:\n",
    "                        valid_times_norm[pred,data_seed,k] += 1\n",
    "\n",
    "                new_states = np.zeros((num_nodes,predict_gap_length))\n",
    "                for i in range(predict_gap_length):\n",
    "                    x_norm = advanceReservoir(win,A_mat,x_norm,train_input_sequence[:,start_pred_idx + i],leakage)\n",
    "                    new_states[:,i] = x_norm\n",
    "\n",
    "                new_aug_states = np.copy(new_states)\n",
    "                new_aug_states[::2,:] = np.power(new_states[::2,:],2)\n",
    "                aug_states = np.concatenate((aug_states,new_aug_states),axis = 1)\n",
    "                s_mat = np.diag(np.power(forgets[k],np.arange(aug_states.shape[1])[::-1]))\n",
    "                data_trstates = np.matmul(np.matmul(train_input_sequence[:,\\\n",
    "                                                                         transient_length:start_pred_idx + predict_gap_length + 1],\\\n",
    "                                                s_mat),\\\n",
    "                                      np.transpose(aug_states))\n",
    "                states_trstates = np.matmul(np.matmul(aug_states,s_mat),np.transpose(aug_states))\n",
    "\n",
    "                wout_norm = np.transpose(solve(np.transpose(states_trstates + idenmat),np.transpose(data_trstates)))\n",
    "\n",
    "\n",
    "            # print(valid_times_norm)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_valid_times = np.zeros((3,num_predictions))\n",
    "max_avg_valid_times = np.zeros(num_predictions)\n",
    "for k in range(num_forgets):\n",
    "    for LM_reg in LM_regs:\n",
    "        new_avg_valid_times = np.zeros(num_predictions)\n",
    "        for data_seed in range(num_trials):\n",
    "            new_avg_valid_times = new_avg_valid_times + np.loadtxt('Lorenz63Data/lorenz_valid_times_period5000_lam%f_reg%e_seed%d.csv' % (forgets[k],LM_reg,data_seed),delimiter = ',')\n",
    "        new_avg_valid_times = new_avg_valid_times/num_trials\n",
    "        max_avg_valid_times = np.maximum(max_avg_valid_times,new_avg_valid_times)\n",
    "        for pred in range(num_predictions):\n",
    "            if max_avg_valid_times[pred] == new_avg_valid_times[pred]:\n",
    "                best_valid_times[0,pred] = data_seed\n",
    "                best_valid_times[1,pred] = forgets[k]\n",
    "                best_valid_times[2,pred] = LM_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.995: 12, 0.99: 21, 0.9875: 27, 0.9925: 16, 0.985: 17, 0.9825: 6, 0.98: 1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(best_valid_times)\n",
    "CountFrequency(best_valid_times[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wouts_abs = np.sqrt(np.mean((wouts - wouts_norm)**2,axis = (0,1)))\n",
    "plt.plot(wouts_abs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itr = 50\n",
    "run = 15\n",
    "fg  = 8\n",
    "times_all = step*(transient_length + start_length + np.arange(num_predictions)*predict_gap_length)\n",
    "plt.plot(times_all,r_t_cosine(times))\n",
    "plt.plot(times[itr],r_t_cosine(times[itr]),'r.')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('r(t)')\n",
    "plt.savefig('r_t_cosine_itr%d_run%d_forget%d.pdf' % (itr,run,fg))\n",
    "plt.show()\n",
    "plt.plot(np.arange(predict_length)*step,truths[0,:,itr,run,fg],label = 'Truth')\n",
    "plt.plot(np.arange(predict_length)*step,predictions[0,:,itr,run,fg],label = 'Reservoir w/ RLS')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('x(t)')\n",
    "tlfg = step*np.log(1/2)/np.log(forgets[fg])\n",
    "plt.title('$t_\\lambda = %f$' % tlfg)\n",
    "plt.legend()\n",
    "plt.savefig('x_t_truth_vs_pred_itr%d_run%d_forget%d_wapproxLMreg.pdf' % (itr,run,fg))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx1 = 5\n",
    "tl1 = step*np.log(1/2)/np.log(forgets[idx1])\n",
    "idx2 = 8\n",
    "tl2 = step*np.log(1/2)/np.log(forgets[idx2])\n",
    "plt.errorbar(times,np.mean(valid_times[:,:,0],axis = 1)*step,step*np.std(valid_times[:,:,0],axis = 1),label = '$t_\\lambda = \\infty$')\n",
    "plt.errorbar(times,np.mean(valid_times[:,:,idx1],axis = 1)*step,step*np.std(valid_times[:,:,idx1],axis = 1),label = '$t_\\lambda = %f$' % tl1)\n",
    "plt.errorbar(times,np.mean(valid_times[:,:,idx2],axis = 1)*step,step*np.std(valid_times[:,:,idx2],axis = 1),label = '$t_\\lambda = %f$' % tl2)\n",
    "plt.legend()\n",
    "plt.xlabel('Prediction Start Time')\n",
    "plt.ylabel('Valid Time')\n",
    "plt.title('300 Reservoir Nodes, $\\mu = 10^{-6}$')\n",
    "plt.savefig('valid_time_vs_start_time_wapproxLMreg.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(predictions[0,:,80,5,6])\n",
    "plt.plot(truths[0,:,80,5,6])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
