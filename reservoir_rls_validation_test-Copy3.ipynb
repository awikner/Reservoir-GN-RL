{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reservoir_rls import *\n",
    "from lorenz63 import *\n",
    "from sklearn import preprocessing\n",
    "from scipy.stats import sem\n",
    "import cma\n",
    "from scipy.stats import kstest, norm, shapiro\n",
    "from multiprocessing import Pool\n",
    "from min_func import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style(theme='monokai', context='notebook', ticks=True, grid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 100/100 [00:53<00:00,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140000, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "step = 0.05\n",
    "start_time = 125\n",
    "sync_length = 200\n",
    "num_tests = 500\n",
    "train_length = 800\n",
    "pred_length = 400\n",
    "base_data_length = int(start_time/step)\n",
    "data_length = int(base_data_length * step/(0.01))+pred_length\n",
    "r_t = lambda x: r_t_cosine(x)\n",
    "dxdt = lambda x,t,r_t: dxdt_lorenz(x,t,r_t)\n",
    "\n",
    "num_tests = 100\n",
    "with tqdm(total = num_tests) as pbar:\n",
    "    for seed in range(num_tests):\n",
    "        data = getLorenzData(data_length, r_t, dxdt, sample_tau = step, seed = seed)\n",
    "        if seed == 0:\n",
    "            optim_data = data[-sync_length - train_length - pred_length:]\n",
    "        else:\n",
    "            optim_data = np.vstack((optim_data, data[-sync_length - train_length - pred_length:]))\n",
    "        pbar.update(1)\n",
    "print(optim_data.shape)\n",
    "\n",
    "# scaler = preprocessing.StandardScaler().fit(data)\n",
    "# scaled_data = scaler.transform(data)\n",
    "scaled_data = np.copy(optim_data)\n",
    "scaled_data = np.ascontiguousarray(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 210\n",
    "res_seed = 1\n",
    "base_res = reservoir(3,num_nodes,input_weight = 1, spectral_radius = 1, seed = res_seed)\n",
    "mask = ['input_weight','regularization','forget']\n",
    "x0 = np.array([5, 6, 2])\n",
    "min_func = lambda x: vt_min_function_norm(scaled_data, x, mask, base_res.Win, base_res.A, \\\n",
    "     num_tests = num_tests,  num_nodes = num_nodes, pred_length = pred_length, train_length = train_length,\n",
    "     separated = True)\n",
    "sigma = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9_w,18)-aCMA-ES (mu_w=5.4,w_1=30%) in dimension 3 (seed=5, Tue Dec 15 15:38:13 2020)\n",
      "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      "    1     18 -3.500000000000000e+01 1.0e+00 8.63e-01  6e-01  8e-01 0:44.3\n",
      "    2     36 -3.500000000000000e+01 1.4e+00 8.30e-01  5e-01  9e-01 1:28.6\n",
      "    3     54 -3.500000000000000e+01 2.0e+00 6.59e-01  3e-01  8e-01 2:13.3\n",
      "    4     72 -4.300000000000000e+01 3.1e+00 7.08e-01  3e-01  8e-01 2:57.1\n",
      "    5     90 -4.300000000000000e+01 3.3e+00 7.83e-01  3e-01  8e-01 3:41.1\n",
      "    6    108 -4.450000000000000e+01 3.6e+00 9.62e-01  2e-01  1e+00 4:26.9\n",
      "    7    126 -3.600000000000000e+01 5.4e+00 1.27e+00  3e-01  2e+00 5:20.9\n",
      "    8    144 -3.400000000000000e+01 6.9e+00 1.48e+00  3e-01  2e+00 6:15.6\n",
      "    9    162 -3.600000000000000e+01 8.7e+00 1.31e+00  2e-01  1e+00 7:10.3\n",
      "   10    180 -4.500000000000000e+01 8.1e+00 1.37e+00  2e-01  2e+00 8:03.8\n",
      "   11    198 -4.350000000000000e+01 1.0e+01 1.06e+00  1e-01  1e+00 8:57.1\n",
      "   12    216 -4.000000000000000e+01 9.5e+00 1.09e+00  2e-01  1e+00 9:50.1\n",
      "   13    234 -4.300000000000000e+01 1.2e+01 9.03e-01  1e-01  1e+00 10:43.6\n",
      "   14    252 -4.350000000000000e+01 1.1e+01 8.53e-01  1e-01  9e-01 11:27.4\n",
      "   15    270 -4.500000000000000e+01 1.1e+01 1.01e+00  1e-01  1e+00 12:11.6\n",
      "   16    288 -3.900000000000000e+01 1.3e+01 1.19e+00  2e-01  1e+00 12:55.7\n",
      "   17    306 -3.750000000000000e+01 1.6e+01 1.17e+00  2e-01  1e+00 13:38.6\n",
      "   18    324 -3.950000000000000e+01 2.0e+01 1.08e+00  1e-01  1e+00 14:22.5\n",
      "   19    342 -3.950000000000000e+01 1.7e+01 9.21e-01  1e-01  9e-01 15:05.1\n",
      "   20    360 -4.100000000000000e+01 1.9e+01 9.79e-01  1e-01  1e+00 15:48.6\n",
      "   21    378 -4.100000000000000e+01 1.9e+01 8.81e-01  1e-01  8e-01 16:32.7\n",
      "   22    396 -4.100000000000000e+01 1.6e+01 6.89e-01  7e-02  5e-01 17:16.9\n",
      "   23    414 -4.100000000000000e+01 1.5e+01 7.68e-01  6e-02  6e-01 18:00.5\n",
      "   24    432 -4.200000000000000e+01 1.5e+01 7.21e-01  4e-02  6e-01 18:45.0\n",
      "   25    450 -4.500000000000000e+01 1.8e+01 6.84e-01  3e-02  5e-01 19:29.3\n",
      "   26    468 -4.750000000000000e+01 2.0e+01 8.46e-01  3e-02  7e-01 20:13.6\n",
      "   27    486 -4.650000000000000e+01 2.8e+01 1.07e+00  3e-02  1e+00 21:06.8\n",
      "   28    504 -4.700000000000000e+01 4.8e+01 1.17e+00  2e-02  1e+00 22:01.8\n",
      "   29    522 -4.600000000000000e+01 5.9e+01 1.63e+00  3e-02  2e+00 22:46.8\n",
      "   30    540 -4.400000000000000e+01 8.7e+01 1.47e+00  2e-02  2e+00 23:31.1\n",
      "   31    558 -4.450000000000000e+01 1.0e+02 1.20e+00  1e-02  1e+00 24:20.9\n",
      "   32    576 -4.850000000000000e+01 1.4e+02 1.77e+00  2e-02  2e+00 25:14.0\n",
      "   33    594 -4.800000000000000e+01 1.4e+02 2.05e+00  1e-02  2e+00 26:10.7\n",
      "   34    612 -4.600000000000000e+01 1.6e+02 1.98e+00  1e-02  2e+00 27:02.3\n",
      "   35    630 -4.750000000000000e+01 1.8e+02 1.73e+00  7e-03  2e+00 27:47.3\n",
      "   36    648 -4.700000000000000e+01 2.4e+02 1.39e+00  5e-03  1e+00 28:32.3\n",
      "   37    666 -4.550000000000000e+01 2.6e+02 1.25e+00  4e-03  1e+00 29:16.7\n",
      "   38    684 -4.650000000000000e+01 2.6e+02 1.57e+00  6e-03  1e+00 30:01.3\n",
      "   39    702 -4.900000000000000e+01 2.5e+02 1.52e+00  5e-03  9e-01 30:46.1\n",
      "   40    720 -4.750000000000000e+01 2.7e+02 1.28e+00  3e-03  8e-01 31:30.7\n",
      "   41    738 -4.700000000000000e+01 3.4e+02 1.16e+00  3e-03  7e-01 32:15.9\n",
      "   42    756 -4.850000000000000e+01 3.4e+02 9.49e-01  2e-03  5e-01 33:00.2\n",
      "   43    774 -4.750000000000000e+01 3.5e+02 9.95e-01  2e-03  6e-01 33:44.4\n",
      "   44    792 -4.750000000000000e+01 4.4e+02 8.27e-01  2e-03  5e-01 34:29.5\n",
      "   45    810 -4.800000000000000e+01 4.7e+02 7.81e-01  1e-03  5e-01 35:14.6\n",
      "   46    828 -5.000000000000000e+01 5.5e+02 8.61e-01  1e-03  6e-01 36:11.4\n",
      "   47    846 -4.850000000000000e+01 7.1e+02 1.04e+00  2e-03  7e-01 37:07.4\n",
      "   48    864 -4.850000000000000e+01 5.9e+02 1.03e+00  1e-03  6e-01 37:55.3\n",
      "   50    900 -5.050000000000000e+01 6.6e+02 9.33e-01  9e-04  5e-01 39:25.7\n",
      "   52    936 -5.000000000000000e+01 8.8e+02 7.49e-01  6e-04  4e-01 40:55.2\n",
      "   54    972 -5.000000000000000e+01 8.4e+02 5.20e-01  3e-04  2e-01 42:24.4\n",
      "   56   1008 -5.100000000000000e+01 7.2e+02 6.59e-01  5e-04  2e-01 43:53.1\n",
      "   58   1044 -5.050000000000000e+01 5.6e+02 4.92e-01  3e-04  1e-01 45:22.7\n",
      "   60   1080 -5.150000000000000e+01 5.5e+02 6.94e-01  3e-04  1e-01 46:53.3\n",
      "   62   1116 -5.150000000000000e+01 4.9e+02 5.10e-01  2e-04  7e-02 48:23.7\n",
      "   64   1152 -5.100000000000000e+01 4.1e+02 5.30e-01  2e-04  9e-02 49:53.7\n",
      "   66   1188 -5.150000000000000e+01 5.3e+02 4.67e-01  1e-04  6e-02 51:23.6\n",
      "   68   1224 -5.150000000000000e+01 5.3e+02 3.52e-01  8e-05  4e-02 52:54.6\n",
      "   70   1260 -5.150000000000000e+01 5.2e+02 3.35e-01  6e-05  4e-02 54:25.1\n",
      "   72   1296 -5.150000000000000e+01 7.1e+02 2.83e-01  5e-05  3e-02 56:04.2\n",
      "   74   1332 -5.150000000000000e+01 5.3e+02 2.01e-01  5e-05  2e-02 57:54.2\n",
      "   75   1350 -5.150000000000000e+01 4.8e+02 2.08e-01  5e-05  2e-02 58:49.2\n",
      "termination on tolflatfitness=1 (Tue Dec 15 16:37:05 2020)\n",
      "final/bestever f-value = -5.150000e+01 -5.150000e+01\n",
      "incumbent solution: [4.921887034992285, 9.543144610857526, 0.9456974892987713]\n",
      "std deviation: [5.196789932632487e-05, 0.020258124329534683, 0.0029292355956568312]\n"
     ]
    }
   ],
   "source": [
    "opts = cma.CMAOptions()\n",
    "opts.set('popsize',6*x0.size)\n",
    "opts.set('bounds', [0,10])\n",
    "opts.set('seed', 5)\n",
    "opts.set('verb_filenameprefix','cmaes_norm_cos_wforget_starttime%d_res%d\\\\' % (start_time,res_seed))\n",
    "results = cma.fmin(min_func, x0, sigma, options = opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_weight = 5.066848935533839\n",
    "regs = np.linspace(2,8,25)\n",
    "forgets = np.linspace(0,5,25)\n",
    "func_vals = np.zeros((regs.size, forgets.size))\n",
    "\n",
    "with tqdm(total = regs.size * forgets.size) as pbar:\n",
    "    for i in range(regs.size):\n",
    "        for j in range(forgets.size):\n",
    "            func_vals[i,j] = min_func(np.array([input_weight, regs[i], forgets[j]]))\n",
    "            np.savetxt('rls_func_vals_weight%f.csv'%input_weight, func_vals, delimiter = ',')\n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pcolor(regs, forgets, -func_vals.T)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Ellipse\n",
    "import matplotlib.transforms as transforms\n",
    "def confidence_ellipse(mean_x, mean_y, cov, ax, n_std=1.0, facecolor='none', **kwargs):\n",
    "    \"\"\"\n",
    "    Create a plot of the covariance confidence ellipse of *x* and *y*.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x, y : array-like, shape (n, )\n",
    "        Input data.\n",
    "\n",
    "    ax : matplotlib.axes.Axes\n",
    "        The axes object to draw the ellipse into.\n",
    "\n",
    "    n_std : float\n",
    "        The number of standard deviations to determine the ellipse's radiuses.\n",
    "\n",
    "    **kwargs\n",
    "        Forwarded to `~matplotlib.patches.Ellipse`\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.patches.Ellipse\n",
    "    \"\"\"\n",
    "    \n",
    "    pearson = cov[0, 1]/np.sqrt(cov[0, 0] * cov[1, 1])\n",
    "    # Using a special case to obtain the eigenvalues of this\n",
    "    # two-dimensionl dataset.\n",
    "    ell_radius_x = np.sqrt(1 + pearson)\n",
    "    ell_radius_y = np.sqrt(1 - pearson)\n",
    "    ellipse = Ellipse((0, 0), width=ell_radius_x * 2, height=ell_radius_y * 2,\n",
    "                      facecolor=facecolor, **kwargs)\n",
    "\n",
    "    # Calculating the stdandard deviation of x from\n",
    "    # the squareroot of the variance and multiplying\n",
    "    # with the given number of standard deviations.\n",
    "    scale_x = np.sqrt(cov[0, 0]) * n_std\n",
    "    # mean_x = np.mean(x)\n",
    "\n",
    "    # calculating the stdandard deviation of y ...\n",
    "    scale_y = np.sqrt(cov[1, 1]) * n_std\n",
    "    # mean_y = np.mean(y)\n",
    "\n",
    "    transf = transforms.Affine2D() \\\n",
    "        .rotate_deg(45) \\\n",
    "        .scale(scale_x, scale_y) \\\n",
    "        .translate(mean_x, mean_y)\n",
    "\n",
    "    ellipse.set_transform(transf + ax.transData)\n",
    "    print(ellipse)\n",
    "    return ax.add_patch(ellipse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.animation import FuncAnimation\n",
    "import pandas as pd\n",
    "step = 0.05\n",
    "test_weight = 5.066848935533839\n",
    "\n",
    "covmats = np.loadtxt('cmaes_rls_const_weight_starttime125_res1/covmats.txt', delimiter = ',')\n",
    "mean_data = np.loadtxt('cmaes_rls_const_weight_starttime125_res1/phenomean.txt', delimiter = ',')[2:]\n",
    "num_frames = 92\n",
    "func_vals = np.loadtxt('rls_func_vals_weight%f.csv'%test_weight, delimiter = ',')*step\n",
    "mean_func = pd.read_csv('cmaes_rls_const_weight_starttime125_res1/fit.dat', sep = ' ', header = None, skiprows = [0]).to_numpy()[:,5]*step\n",
    "plt.plot(np.max(np.abs(covmats), axis = 1))\n",
    "plt.xlim(0,num_frames)\n",
    "plt.show()\n",
    "\n",
    "weights = np.linspace(2,8,25)\n",
    "regs = np.linspace(0,5,25)\n",
    "W, R = np.meshgrid(weights, regs)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "def init_base(ax,W,R,func_vals):\n",
    "    ax.clear()\n",
    "    plt.pcolor(W, R, -func_vals.T)\n",
    "    plt.colorbar()\n",
    "    ax.set_xlim(2,8)\n",
    "    ax.set_ylim(0,5)\n",
    "    xticks = np.linspace(2,8,7)\n",
    "    yticks = np.linspace(0,5,6)\n",
    "    xlabels = ['%.0f'%i for i in -xticks-3.0]\n",
    "    ylabels = ['%.1f'%i for i in -0.5*yticks - 1.0]\n",
    "    plt.xticks(xticks, xlabels)\n",
    "    plt.yticks(yticks, ylabels)\n",
    "    plt.xlabel('log$_{10}$(Regularization)')\n",
    "    plt.ylabel('log$_{10}$(1 - Forgetting)')\n",
    "\n",
    "def animate(i,ax,mean_data,covmats,W, R, func_vals, test_weight):\n",
    "    ax.clear()\n",
    "    plt.pcolor(W, R, -func_vals.T)\n",
    "    confidence_ellipse(mean_data[i,0],mean_data[i,1],covmats[i,:].reshape(2,2),ax,edgecolor = 'red', linewidth = 2)\n",
    "    ax.scatter(mean_data[i,0],mean_data[i,1],c = 'red')\n",
    "    ax.set_xlim(2,8)\n",
    "    ax.set_ylim(0,5)\n",
    "    xticks = np.linspace(2,8,7)\n",
    "    yticks = np.linspace(0,5,6)\n",
    "    xlabels = ['%.0f'%i for i in -xticks-3.0]\n",
    "    ylabels = ['%.1f'%i for i in -0.5*yticks - 1.0]\n",
    "    plt.xticks(xticks, xlabels)\n",
    "    plt.yticks(yticks, ylabels)\n",
    "    plt.xlabel('log$_{10}$(Regularization)')\n",
    "    plt.ylabel('log$_{10}$(1 - Forgetting)')\n",
    "    plt.title('Color Input Weight: %.3f, Mean Input Weight: %.3f' % ((test_weight-5)*0.2, (test_weight-5)*0.2))\n",
    "    \n",
    "update = lambda i: animate(i,ax,mean_data,covmats,W,R,func_vals,test_weight)\n",
    "init = lambda : init_base(ax,W,R,func_vals)\n",
    "\n",
    "ani = FuncAnimation(fig, update, frames = num_frames, init_func = init, blit = False)\n",
    "\n",
    "ani.save('test_rls_cweight.gif')\n",
    "fig.show()\n",
    "\n",
    "fig2 = plt.figure()\n",
    "\n",
    "ax2 = fig2.add_subplot(1,1,1)\n",
    "line, = ax2.plot([],[],lw = 2, color = 'red')\n",
    "\n",
    "def init2(ax2, line, num_frames):\n",
    "    ax2.set_xlim(0,num_frames)\n",
    "    ax2.set_ylim(0,2.25)\n",
    "    ax2.set_xlabel('CMA-ES Generation')\n",
    "    ax2.set_ylabel('Median Valid Time')\n",
    "    ax2.grid()\n",
    "    line.set_data([],[])\n",
    "    return line,\n",
    "\n",
    "def animate2(i, line, mean_func):\n",
    "    line.set_data(np.arange(i+1),np.append(np.array([0]),-mean_func[:i]))\n",
    "    return line,\n",
    "    \n",
    "\n",
    "init_fun = lambda : init2(ax2, line, num_frames)    \n",
    "update2 = lambda i: animate2(i,line, mean_func)\n",
    "\n",
    "ani2 = FuncAnimation(fig2, update2, frames = num_frames, init_func = init_fun, blit = True)\n",
    "\n",
    "ani2.save('test2_rls_cweight.gif')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = reservoir(3,210,forget = 1, input_weight = 0.25*0.05735187596920699, regularization = 10**(-9.310114193664688), seed = 3)\n",
    "num_tests = 5000\n",
    "pred_length = 500\n",
    "train_length = 400\n",
    "sync_length = 200\n",
    "valid_times_norm = cross_validation_performance_resync(scaled_data,res2,num_tests,sync_length, \\\n",
    "   train_length, pred_length,train_method = 'Normal', progress = True)\n",
    "print(np.median(valid_times_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = reservoir(3,200,forget = 0.995, input_weight = 0.01, LM_regularization = 1e-10, delta = 1e6)\n",
    "res2 = reservoir(3,200,forget = 1, input_weight = 0.01, regularization = 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_length = 100000\n",
    "step = 0.05\n",
    "r_t = lambda x: r_t_const(x)\n",
    "dxdt = lambda x,t,r_t: dxdt_lorenz(x,t,r_t)\n",
    "data = getLorenzData(data_length, r_t, dxdt, sample_tau = step)\n",
    "\n",
    "sync_length = 200\n",
    "num_tests = 500\n",
    "train_length = 800\n",
    "pred_length = 500\n",
    "\n",
    "# scaler = preprocessing.StandardScaler().fit(data)\n",
    "# scaled_data = scaler.transform(data)\n",
    "scaled_data = np.copy(data)\n",
    "scaled_data = np.ascontiguousarray(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_times_RLS = cross_validation_performance(scaled_data,res1,num_tests,sync_length, \\\n",
    "   train_length, pred_length,train_method = 'RLS')\n",
    "print(np.median(valid_times_RLS))\n",
    "valid_times_norm = cross_validation_performance(scaled_data,res2,num_tests,sync_length, \\\n",
    "   train_length, pred_length,train_method = 'Normal')\n",
    "print(np.median(valid_times_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = reservoir(3,300,forget = 0.985, input_weight = 0.01, regularization = 1e-8, \\\n",
    "     t_regularization = 5e-5, delta = 1e6, t_weighted = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_times_norm_array = np.loadtxt('Lorenz63Data/valid_times_norm_tweight_forget%f_reg%e_treg%e.csv' \\\n",
    "#     %(res1.forget, res1.regularization, res1.t_regularization), delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0.05\n",
    "base_data_length = 25000\n",
    "data_length = int(base_data_length * step/(0.01))\n",
    "r_t = lambda x: r_t_cosine(x)\n",
    "dxdt = lambda x,t,r_t: dxdt_lorenz(x,t,r_t)\n",
    "valid_times_norm_array = np.array([])\n",
    "\n",
    "sync_length = 1000\n",
    "num_tests = 300\n",
    "train_length = 800\n",
    "pred_length = 200\n",
    "completed_seeds = valid_times_norm_array.shape[0]\n",
    "\n",
    "# scaler = preprocessing.StandardScaler().fit(data)\n",
    "# scaled_data = scaler.transform(data)\n",
    "from tqdm import tqdm\n",
    "with tqdm(total = num_tests) as pbar:\n",
    "    for seed in range(num_tests):\n",
    "        data = getLorenzData(data_length, r_t, dxdt, sample_tau = step, seed = seed)\n",
    "        scaled_data = np.ascontiguousarray(data)\n",
    "        valid_times_norm = cross_validation_performance_versust(scaled_data,res1,sync_length, \\\n",
    "               train_length, pred_length,pred_gap_length = 100, train_method = 'Normal', progress = False)\n",
    "        if valid_times_norm_array.size == 0:\n",
    "            valid_times_norm_array = np.copy(valid_times_norm)\n",
    "        else:\n",
    "            valid_times_norm_array = np.vstack((valid_times_norm_array,valid_times_norm))\n",
    "        np.savetxt('Lorenz63Data/valid_times_norm_tweight_forget%f_reg%e_treg%e.csv' %(res1.forget, res1.regularization, res1.t_regularization), \\\n",
    "            valid_times_norm_array, delimiter = ',')\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('Lorenz63Data/valid_times_norm_tweight_forget%f_reg%e_treg%e.csv' %(res1.forget, res1.regularization, res1.t_regularization), \\\n",
    "    valid_times_norm_array, delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.mean(valid_times_norm_array*0.05,axis = 0))\n",
    "plt.ylim(0,5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = reservoir(3,300,forget = 0.985, input_weight = 0.01, LM_regularization = 1e-10, \\\n",
    "     t_regularization = 0, delta = 1e6, t_weighted = False, RLS_reg_type = 'LM')\n",
    "step = 0.05\n",
    "base_data_length = 5000\n",
    "data_length = int(base_data_length * step/(0.01))\n",
    "r_t = lambda x: r_t_cosine(x)\n",
    "dxdt = lambda x,t,r_t: dxdt_lorenz(x,t,r_t)\n",
    "valid_times_norm_array = np.array([])\n",
    "\n",
    "sync_length = 500\n",
    "num_tests = 100\n",
    "train_length = 2000\n",
    "pred_length = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = getLorenzData(data_length, r_t, dxdt, sample_tau = step, seed = 1)\n",
    "new_data = np.ascontiguousarray(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1.trainWoutRLS(scaled_data[2800:3800],200)\n",
    "res1.valid_time(scaled_data[3800:4200],plot = True, error_bound = 3.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_times_norm = cross_validation_performance_separated(scaled_data,res1,sync_length, \\\n",
    "               train_length, pred_length, train_method = 'RLS', progress = False)\n",
    "print(np.median(valid_times_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = preprocessing.StandardScaler().fit(data)\n",
    "# scaled_data = scaler.transform(data)\n",
    "from tqdm import tqdm\n",
    "with tqdm(total = num_tests) as pbar:\n",
    "    for seed in range(num_tests):\n",
    "        data = getLorenzData(data_length, r_t, dxdt, sample_tau = step, seed = seed)\n",
    "        scaled_data = np.ascontiguousarray(data)\n",
    "        valid_times_norm = cross_validation_performance_versust(scaled_data,res1,sync_length, \\\n",
    "               train_length, pred_length,pred_gap_length = 100, train_method = 'RLS', progress = False)\n",
    "        if valid_times_norm_array.size == 0:\n",
    "            valid_times_norm_array = np.copy(valid_times_norm)\n",
    "        else:\n",
    "            valid_times_norm_array = np.vstack((valid_times_norm_array,valid_times_norm))\n",
    "        np.savetxt('Lorenz63Data/valid_times_rls_tweight_forget%f_reg%e_treg%e.csv' %(res1.forget, \\\n",
    "            res1.regularization, res1.t_regularization), valid_times_norm_array, delimiter = ',')\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.mean(valid_times_norm_array*0.05,axis = 0))\n",
    "plt.ylim(0,5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1,2],[3,4]])\n",
    "np.mean(x,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
