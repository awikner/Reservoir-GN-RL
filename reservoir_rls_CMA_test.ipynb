{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reservoir_rls import *\n",
    "from lorenz63 import *\n",
    "from sklearn import preprocessing\n",
    "from scipy.stats import sem\n",
    "import cma\n",
    "from scipy.stats import kstest, norm, shapiro\n",
    "from multiprocessing import Pool\n",
    "from min_func import *\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# from jupyterthemes import jtplot\n",
    "# jtplot.style(theme='monokai', context='notebook', ticks=True, grid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.05210027118992914\n",
      "18.92542301780254\n",
      "-19.022413088306337\n"
     ]
    }
   ],
   "source": [
    "data_length = 200000\n",
    "step = 0.05\n",
    "r_t = lambda x: r_t_const(x)\n",
    "dxdt = lambda x,t,r_t: dxdt_lorenz(x,t,r_t)\n",
    "data = getLorenzData(data_length, r_t, dxdt, sample_tau = step)\n",
    "\n",
    "sync_length = 200\n",
    "train_length = 800\n",
    "pred_length = 500\n",
    "\n",
    "# scaler = preprocessing.StandardScaler().fit(data)\n",
    "# scaled_data = scaler.transform(data)\n",
    "scaled_data = np.copy(data)\n",
    "scaled_data = np.ascontiguousarray(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 210\n",
    "num_tests = 100\n",
    "res_seed = 1\n",
    "base_res = reservoir(3,num_nodes,input_weight = 1, spectral_radius = 1, seed = res_seed)\n",
    "mask = ['input_weight', 'regularization']\n",
    "x0 = np.array([5, 5])\n",
    "min_func = lambda x: vt_min_function_norm(scaled_data, x, mask, base_res.Win, base_res.A, \\\n",
    "     num_tests = num_tests,  num_nodes = num_nodes, pred_length = pred_length, train_length = train_length)\n",
    "sigma = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AdaptSigma': 'True  # or False or any CMAAdaptSigmaBase class e.g. CMAAdaptSigmaTPA, CMAAdaptSigmaCSA', 'CMA_active': 'True  # negative update, conducted after the original update', 'CMA_cmean': '1  # learning rate for the mean value', 'CMA_const_trace': 'False  # normalize trace, 1, True, \"arithm\", \"geom\", \"aeig\", \"geig\" are valid', 'CMA_diagonal': '0*100*N/popsize**0.5  # nb of iterations with diagonal covariance matrix, True for always', 'CMA_eigenmethod': 'np.linalg.eigh  # or cma.utilities.math.eig or pygsl.eigen.eigenvectors', 'CMA_elitist': 'False  #v or \"initial\" or True, elitism likely impairs global search performance', 'CMA_injections_threshold_keep_len': '1  #v keep length if Mahalanobis length is below the given relative threshold', 'CMA_mirrors': 'popsize < 6  # values <0.5 are interpreted as fraction, values >1 as numbers (rounded), otherwise about 0.16 is used', 'CMA_mirrormethod': '2  # 0=unconditional, 1=selective, 2=selective with delay', 'CMA_mu': 'None  # parents selection parameter, default is popsize // 2', 'CMA_on': '1  # multiplier for all covariance matrix updates', 'CMA_sampler': 'None  # a class or instance that implements the interface of `cma.interfaces.StatisticalModelSamplerWithZeroMeanBaseClass`', 'CMA_sampler_options': '{}  # options passed to `CMA_sampler` class init as keyword arguments', 'CMA_rankmu': '1.0  # multiplier for rank-mu update learning rate of covariance matrix', 'CMA_rankone': '1.0  # multiplier for rank-one update learning rate of covariance matrix', 'CMA_recombination_weights': 'None  # a list, see class RecombinationWeights, overwrites CMA_mu and popsize options', 'CMA_dampsvec_fac': 'np.Inf  # tentative and subject to changes, 0.5 would be a \"default\" damping for sigma vector update', 'CMA_dampsvec_fade': '0.1  # tentative fading out parameter for sigma vector update', 'CMA_teststds': 'None  # factors for non-isotropic initial distr. of C, mainly for test purpose, see CMA_stds for production', 'CMA_stds': 'None  # multipliers for sigma0 in each coordinate, not represented in C, makes scaling_of_variables obsolete', 'CSA_dampfac': '1  #v positive multiplier for step-size damping, 0.3 is close to optimal on the sphere', 'CSA_damp_mueff_exponent': '0.5  # zero would mean no dependency of damping on mueff, useful with CSA_disregard_length option', 'CSA_disregard_length': 'False  #v True is untested, also changes respective parameters', 'CSA_clip_length_value': 'None  #v poorly tested, [0, 0] means const length N**0.5, [-1, 1] allows a variation of +- N/(N+2), etc.', 'CSA_squared': 'False  #v use squared length for sigma-adaptation ', 'BoundaryHandler': 'BoundTransform  # or BoundPenalty, unused when ``bounds in (None, [None, None])``', 'bounds': '[None, None]  # lower (=bounds[0]) and upper domain boundaries, each a scalar or a list/vector', 'conditioncov_alleviate': '[1e8, 1e12]  # when to alleviate the condition in the coordinates and in main axes', 'eval_final_mean': 'True  # evaluate the final mean, which is a favorite return candidate', 'fixed_variables': 'None  # dictionary with index-value pairs like {0:1.1, 2:0.1} that are not optimized', 'ftarget': '-inf  #v target function value, minimization', 'integer_variables': '[]  # index list, invokes basic integer handling: prevent std dev to become too small in the given variables', 'is_feasible': 'is_feasible  #v a function that computes feasibility, by default lambda x, f: f not in (None, np.NaN)', 'maxfevals': 'inf  #v maximum number of function evaluations', 'maxiter': '100 + 150 * (N+3)**2 // popsize**0.5  #v maximum number of iterations', 'mean_shift_line_samples': 'False #v sample two new solutions colinear to previous mean shift', 'mindx': '0  #v minimal std in any arbitrary direction, cave interference with tol*', 'minstd': '0  #v minimal std (scalar or vector) in any coordinate direction, cave interference with tol*', 'maxstd': 'inf  #v maximal std in any coordinate direction', 'pc_line_samples': 'False #v one line sample along the evolution path pc', 'popsize': '4+int(3*np.log(N))  # population size, AKA lambda, number of new solution per iteration', 'randn': 'np.random.randn  #v randn(lam, N) must return an np.array of shape (lam, N), see also cma.utilities.math.randhss', 'scaling_of_variables': 'None  # deprecated, rather use fitness_transformations.ScaleCoordinates instead (or possibly CMA_stds).\\n            Scale for each variable in that effective_sigma0 = sigma0*scaling. Internally the variables are divided by\\n            scaling_of_variables and sigma is unchanged, default is `np.ones(N)`', 'seed': 'time  # random number seed for `numpy.random`; `None` and `0` equate to `time`, `np.nan` means \"do nothing\", see also option \"randn\"', 'signals_filename': 'cma_signals.in  # read versatile options from this file (use `None` or `\"\"` for no file) which contains a single options dict, e.g. ``{\"timeout\": 0}`` to stop, string-values are evaluated, e.g. \"np.inf\" is valid', 'termination_callback': '[]  #v a function or list of functions returning True for termination, called in `stop` with `self` as argument, could be abused for side effects', 'timeout': 'inf  #v stop if timeout seconds are exceeded, the string \"2.5 * 60**2\" evaluates to 2 hours and 30 minutes', 'tolconditioncov': '1e14  #v stop if the condition of the covariance matrix is above `tolconditioncov`', 'tolfacupx': '1e3  #v termination when step-size increases by tolfacupx (diverges). That is, the initial step-size was chosen far too small and better solutions were found far away from the initial solution x0', 'tolupsigma': '1e20  #v sigma/sigma0 > tolupsigma * max(eivenvals(C)**0.5) indicates \"creeping behavior\" with usually minor improvements', 'tolflatfitness': '1  #v iterations tolerated with flat fitness before termination', 'tolfun': '1e-11  #v termination criterion: tolerance in function value, quite useful', 'tolfunhist': '1e-12  #v termination criterion: tolerance in function value history', 'tolfunrel': '0  #v termination criterion: relative tolerance in function value: Delta f current < tolfunrel * (median0 - median_min)', 'tolstagnation': 'int(100 + 100 * N**1.5 / popsize)  #v termination if no improvement over tolstagnation iterations', 'tolx': '1e-11  #v termination criterion: tolerance in x-changes', 'transformation': 'None  # depreciated, use cma.fitness_transformations.FitnessTransformation instead.\\n            [t0, t1] are two mappings, t0 transforms solutions from CMA-representation to f-representation (tf_pheno),\\n            t1 is the (optional) back transformation, see class GenoPheno', 'typical_x': 'None  # used with scaling_of_variables', 'updatecovwait': 'None  #v number of iterations without distribution update, name is subject to future changes', 'verbose': '3  #v verbosity e.g. of initial/final message, -1 is very quiet, -9 maximally quiet, may not be fully implemented', 'verb_append': '0  # initial evaluation counter, if append, do not overwrite output files', 'verb_disp': '100  #v verbosity: display console output every verb_disp iteration', 'verb_filenameprefix': 'outcmaes\\\\  # output path and filenames prefix', 'verb_log': '1  #v verbosity: write data to files every verb_log iteration, writing can be time critical on fast to evaluate functions', 'verb_log_expensive': 'N * (N <= 50)  # allow to execute eigendecomposition for logging every verb_log_expensive iteration, 0 or False for never', 'verb_plot': '0  #v in fmin(): plot() is called every verb_plot iteration', 'verb_time': 'True  #v output timings on console', 'vv': '{}  #? versatile set or dictionary for hacking purposes, value found in self.opts[\"vv\"]'}\n"
     ]
    }
   ],
   "source": [
    "print(cma.CMAOptions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4_w,8)-aCMA-ES (mu_w=2.6,w_1=52%) in dimension 2 (seed=5, Fri Nov 27 13:26:10 2020)\n",
      "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      "    1      8 -1.395000000000000e+02 1.0e+00 1.91e+00  1e+00  2e+00 0:28.4\n",
      "    2     16 -1.740000000000000e+02 1.6e+00 2.04e+00  1e+00  3e+00 0:57.9\n",
      "    3     24 -1.765000000000000e+02 2.4e+00 2.30e+00  9e-01  3e+00 1:27.1\n",
      "    4     32 -1.345000000000000e+02 3.7e+00 2.49e+00  7e-01  4e+00 1:56.6\n",
      "    5     40 -1.555000000000000e+02 5.7e+00 2.84e+00  6e-01  5e+00 2:26.9\n",
      "    6     48 -1.390000000000000e+02 9.1e+00 2.69e+00  5e-01  5e+00 2:56.4\n",
      "    7     56 -1.285000000000000e+02 1.1e+01 2.25e+00  3e-01  4e+00 3:26.3\n",
      "    8     64 -1.330000000000000e+02 1.4e+01 1.82e+00  2e-01  3e+00 3:56.8\n",
      "    9     72 -1.420000000000000e+02 1.5e+01 1.49e+00  2e-01  2e+00 4:27.4\n",
      "   10     80 -1.665000000000000e+02 1.5e+01 1.19e+00  1e-01  1e+00 4:58.3\n",
      "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      "   11     88 -1.575000000000000e+02 1.2e+01 9.88e-01  9e-02  1e+00 5:29.2\n",
      "   12     96 -1.680000000000000e+02 1.2e+01 8.48e-01  7e-02  9e-01 6:00.6\n",
      "   13    104 -1.745000000000000e+02 1.3e+01 9.42e-01  8e-02  1e+00 6:30.8\n",
      "   14    112 -1.790000000000000e+02 1.3e+01 8.83e-01  7e-02  9e-01 7:01.8\n",
      "   15    120 -1.720000000000000e+02 1.2e+01 7.69e-01  6e-02  7e-01 7:32.6\n",
      "   16    128 -1.815000000000000e+02 1.0e+01 6.63e-01  5e-02  5e-01 8:03.3\n",
      "   17    136 -1.785000000000000e+02 9.8e+00 5.71e-01  4e-02  4e-01 8:34.9\n",
      "   18    144 -1.820000000000000e+02 1.0e+01 7.98e-01  6e-02  7e-01 9:05.6\n",
      "   19    152 -1.730000000000000e+02 1.2e+01 6.38e-01  4e-02  5e-01 9:38.0\n",
      "   20    160 -1.810000000000000e+02 1.5e+01 5.61e-01  3e-02  4e-01 10:09.2\n",
      "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      "   21    168 -1.800000000000000e+02 1.7e+01 5.17e-01  2e-02  4e-01 10:40.9\n",
      "   22    176 -1.800000000000000e+02 2.1e+01 4.79e-01  1e-02  4e-01 11:13.4\n",
      "   23    184 -1.795000000000000e+02 2.7e+01 4.70e-01  1e-02  4e-01 11:46.4\n",
      "   24    192 -1.810000000000000e+02 3.4e+01 3.81e-01  7e-03  3e-01 12:19.0\n",
      "   25    200 -1.785000000000000e+02 4.2e+01 3.05e-01  5e-03  2e-01 12:52.0\n",
      "   26    208 -1.795000000000000e+02 3.8e+01 2.54e-01  4e-03  1e-01 13:24.8\n",
      "   27    216 -1.800000000000000e+02 3.3e+01 2.96e-01  5e-03  2e-01 13:57.9\n",
      "   28    224 -1.800000000000000e+02 3.3e+01 2.21e-01  3e-03  1e-01 14:30.5\n",
      "   29    232 -1.800000000000000e+02 3.3e+01 1.79e-01  3e-03  8e-02 15:03.0\n",
      "   30    240 -1.800000000000000e+02 3.1e+01 1.50e-01  2e-03  6e-02 15:36.8\n",
      "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      "   31    248 -1.805000000000000e+02 2.8e+01 1.38e-01  2e-03  5e-02 16:09.7\n",
      "   32    256 -1.800000000000000e+02 3.0e+01 1.17e-01  1e-03  4e-02 16:43.1\n",
      "   33    264 -1.800000000000000e+02 3.6e+01 9.89e-02  1e-03  3e-02 17:15.9\n",
      "   34    272 -1.800000000000000e+02 3.2e+01 9.94e-02  1e-03  3e-02 17:47.8\n",
      "   35    280 -1.800000000000000e+02 2.8e+01 9.11e-02  9e-04  2e-02 18:20.0\n",
      "   36    288 -1.800000000000000e+02 2.8e+01 7.89e-02  7e-04  2e-02 18:52.3\n",
      "   37    296 -1.805000000000000e+02 3.1e+01 7.00e-02  5e-04  2e-02 19:25.8\n",
      "   38    304 -1.805000000000000e+02 4.4e+01 6.52e-02  4e-04  2e-02 19:59.2\n",
      "   39    312 -1.805000000000000e+02 4.5e+01 6.05e-02  4e-04  1e-02 20:32.3\n",
      "   40    320 -1.800000000000000e+02 3.8e+01 5.30e-02  3e-04  1e-02 21:04.8\n",
      "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      "   41    328 -1.800000000000000e+02 3.3e+01 5.36e-02  4e-04  1e-02 21:37.1\n",
      "termination on tolflatfitness=1 (Fri Nov 27 13:47:51 2020)\n",
      "final/bestever f-value = -1.800000e+02 -1.820000e+02\n",
      "incumbent solution: [5.089349222243458, 7.047908623146654]\n",
      "std deviation: [0.0003726287564601972, 0.009768290083111008]\n"
     ]
    }
   ],
   "source": [
    "opts = cma.CMAOptions()\n",
    "opts.set('popsize',4*x0.size)\n",
    "opts.set('bounds', [0,10])\n",
    "opts.set('verb_disp', 1)\n",
    "opts.set('seed', 5)\n",
    "opts.set('verb_filenameprefix','cmaes_norm_res%d\\\\' % res_seed)\n",
    "# constraints = lambda x: [x[1] - 10, -x[1]]\n",
    "results = cma.fmin(min_func, x0, sigma,options = opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_reg = 8.5\n",
    "weights = np.linspace(4,6,20)\n",
    "forgets = np.linspace(1,4,20)\n",
    "func_vals = np.zeros((weights.size, forgets.size))\n",
    "\n",
    "with tqdm(total = weights.size * forgets.size) as pbar:\n",
    "    for i in range(weights.size):\n",
    "        for j in range(forgets.size):\n",
    "            func_vals[i,j] = min_func(np.array([weights[i], test_reg, forgets[j]]))\n",
    "            np.savetxt('rls_func_vals_reg%e.csv'%test_reg, func_vals, delimiter = ',')\n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res2 = reservoir(3,210,forget = 1, input_weight = 0.25*0.05735187596920699, regularization = 10**(-9.310114193664688), seed = 3)\n",
    "num_tests = 5000\n",
    "pred_length = 500\n",
    "train_length = 400\n",
    "sync_length = 200\n",
    "valid_times_norm = cross_validation_performance_resync(scaled_data,res2,num_tests,sync_length, \\\n",
    "   train_length, pred_length,train_method = 'Normal', progress = True)\n",
    "print(np.median(valid_times_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_times_RLS = cross_validation_performance(scaled_data,res1,num_tests,sync_length, \\\n",
    "   train_length, pred_length,train_method = 'RLS')\n",
    "print(np.median(valid_times_RLS))\n",
    "valid_times_norm = cross_validation_performance(scaled_data,res2,num_tests,sync_length, \\\n",
    "   train_length, pred_length,train_method = 'Normal')\n",
    "print(np.median(valid_times_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = reservoir(3,300,forget = 0.985, input_weight = 0.01, regularization = 1e-8, \\\n",
    "     t_regularization = 5e-5, delta = 1e6, t_weighted = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valid_times_norm_array = np.loadtxt('Lorenz63Data/valid_times_norm_tweight_forget%f_reg%e_treg%e.csv' \\\n",
    "#     %(res1.forget, res1.regularization, res1.t_regularization), delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0.05\n",
    "base_data_length = 25000\n",
    "data_length = int(base_data_length * step/(0.01))\n",
    "r_t = lambda x: r_t_cosine(x)\n",
    "dxdt = lambda x,t,r_t: dxdt_lorenz(x,t,r_t)\n",
    "valid_times_norm_array = np.array([])\n",
    "\n",
    "sync_length = 1000\n",
    "num_tests = 300\n",
    "train_length = 800\n",
    "pred_length = 200\n",
    "completed_seeds = valid_times_norm_array.shape[0]\n",
    "\n",
    "# scaler = preprocessing.StandardScaler().fit(data)\n",
    "# scaled_data = scaler.transform(data)\n",
    "from tqdm import tqdm\n",
    "with tqdm(total = num_tests) as pbar:\n",
    "    for seed in range(num_tests):\n",
    "        data = getLorenzData(data_length, r_t, dxdt, sample_tau = step, seed = seed)\n",
    "        scaled_data = np.ascontiguousarray(data)\n",
    "        valid_times_norm = cross_validation_performance_versust(scaled_data,res1,sync_length, \\\n",
    "               train_length, pred_length,pred_gap_length = 100, train_method = 'Normal', progress = False)\n",
    "        if valid_times_norm_array.size == 0:\n",
    "            valid_times_norm_array = np.copy(valid_times_norm)\n",
    "        else:\n",
    "            valid_times_norm_array = np.vstack((valid_times_norm_array,valid_times_norm))\n",
    "        np.savetxt('Lorenz63Data/valid_times_norm_tweight_forget%f_reg%e_treg%e.csv' %(res1.forget, res1.regularization, res1.t_regularization), \\\n",
    "            valid_times_norm_array, delimiter = ',')\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('Lorenz63Data/valid_times_norm_tweight_forget%f_reg%e_treg%e.csv' %(res1.forget, res1.regularization, res1.t_regularization), \\\n",
    "    valid_times_norm_array, delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.mean(valid_times_norm_array*0.05,axis = 0))\n",
    "plt.ylim(0,5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1 = reservoir(3,300,forget = 0.985, input_weight = 0.01, LM_regularization = 1e-10, \\\n",
    "     t_regularization = 0, delta = 1e6, t_weighted = False, RLS_reg_type = 'LM')\n",
    "step = 0.05\n",
    "base_data_length = 5000\n",
    "data_length = int(base_data_length * step/(0.01))\n",
    "r_t = lambda x: r_t_cosine(x)\n",
    "dxdt = lambda x,t,r_t: dxdt_lorenz(x,t,r_t)\n",
    "valid_times_norm_array = np.array([])\n",
    "\n",
    "sync_length = 500\n",
    "num_tests = 100\n",
    "train_length = 2000\n",
    "pred_length = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = getLorenzData(data_length, r_t, dxdt, sample_tau = step, seed = 1)\n",
    "new_data = np.ascontiguousarray(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res1.trainWoutRLS(scaled_data[2800:3800],200)\n",
    "res1.valid_time(scaled_data[3800:4200],plot = True, error_bound = 3.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_times_norm = cross_validation_performance_separated(scaled_data,res1,sync_length, \\\n",
    "               train_length, pred_length, train_method = 'RLS', progress = False)\n",
    "print(np.median(valid_times_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = preprocessing.StandardScaler().fit(data)\n",
    "# scaled_data = scaler.transform(data)\n",
    "from tqdm import tqdm\n",
    "with tqdm(total = num_tests) as pbar:\n",
    "    for seed in range(num_tests):\n",
    "        data = getLorenzData(data_length, r_t, dxdt, sample_tau = step, seed = seed)\n",
    "        scaled_data = np.ascontiguousarray(data)\n",
    "        valid_times_norm = cross_validation_performance_versust(scaled_data,res1,sync_length, \\\n",
    "               train_length, pred_length,pred_gap_length = 100, train_method = 'RLS', progress = False)\n",
    "        if valid_times_norm_array.size == 0:\n",
    "            valid_times_norm_array = np.copy(valid_times_norm)\n",
    "        else:\n",
    "            valid_times_norm_array = np.vstack((valid_times_norm_array,valid_times_norm))\n",
    "        np.savetxt('Lorenz63Data/valid_times_rls_tweight_forget%f_reg%e_treg%e.csv' %(res1.forget, \\\n",
    "            res1.regularization, res1.t_regularization), valid_times_norm_array, delimiter = ',')\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.mean(valid_times_norm_array*0.05,axis = 0))\n",
    "plt.ylim(0,5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1,2],[3,4]])\n",
    "np.mean(x,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
