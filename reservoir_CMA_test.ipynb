{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cma\n",
    "from reservoir_rls import *\n",
    "from lorenz63 import *\n",
    "from sklearn import preprocessing\n",
    "from scipy.stats import sem\n",
    "import cma\n",
    "from scipy.stats import kstest, norm, shapiro\n",
    "from multiprocessing import Pool\n",
    "from min_func import *\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style(theme='monokai', context='notebook', ticks=True, grid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.05210027118992914\n",
      "18.92542301780254\n",
      "-19.022413088306337\n"
     ]
    }
   ],
   "source": [
    "data_length = 200000\n",
    "step = 0.05\n",
    "r_t = lambda x: r_t_const(x)\n",
    "dxdt = lambda x,t,r_t: dxdt_lorenz(x,t,r_t)\n",
    "data = getLorenzData(data_length, r_t, dxdt, sample_tau = step) # Generate data with a constant rho value\n",
    "\n",
    "# Set lengths for each train and validation data set\n",
    "sync_length = 200\n",
    "train_length = 800\n",
    "pred_length = 500\n",
    "\n",
    "scaled_data = np.copy(data)\n",
    "scaled_data = np.ascontiguousarray(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 210\n",
    "num_tests = 100\n",
    "res_seed = 1\n",
    "base_res = reservoir(3,num_nodes,input_weight = 1, spectral_radius = 1, seed = res_seed) #Generate a reservoir\n",
    "mask = ['input_weight', 'regularization']\n",
    "x0 = np.array([5, 5])\n",
    "# Set the minimization function. This function takes num_tests training\n",
    "# and validation data sets and trains the reservoir to predict each validation set\n",
    "# after being trained on the corresponding training set. The negative median valid\n",
    "# time is returned to be minimized.\n",
    "min_func = lambda x: vt_min_function_norm(scaled_data, x, mask, base_res.Win, base_res.A, \\\n",
    "     num_tests = num_tests,  num_nodes = num_nodes, pred_length = pred_length, train_length = train_length)\n",
    "sigma = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = cma.CMAOptions()\n",
    "opts.set('popsize',6*x0.size) # Set number of samples per generation\n",
    "\"\"\"\n",
    "Set bounds on parameters. IMPORTANT: The mean returned by cma-es is\n",
    "the mean BEFORE the boundary function is applied, so the mean may not\n",
    "lie in the domain set by bounds. To obtain the true sample mean requires \n",
    "downloading the cma-es package from github and editing one of the \n",
    "functions. Ask me if you need to do this.\n",
    "\"\"\"\n",
    "opts.set('bounds', [0,10]) \n",
    "opts.set('seed', 5) # Seed for the initial samples\n",
    "\"\"\"\n",
    "File where results are saved. IMPORTANT: Full covariance matrix is \n",
    "NOT saved, nor are the exact samples. If these need to be saved, one\n",
    "will also have to download from github and make some edits. Again,\n",
    "ask me.\n",
    "\"\"\"\n",
    "opts.set('verb_filenameprefix','cmaes_norm_res%d\\\\' % res_seed)\n",
    "results = cma.fmin(min_func, x0, sigma, options = opts) # Run the algorithm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
