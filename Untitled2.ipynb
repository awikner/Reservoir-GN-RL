{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Jun  3 12:57:49 2020\n",
    "\n",
    "@author: josephharvey\n",
    "\"\"\"\n",
    "from datetime import datetime\n",
    "from lorenzrungekutta import *\n",
    "import numpy as np\n",
    "#from sklearn.linear_model import Ridge\n",
    "from scipy import sparse\n",
    "from scipy.linalg import solve\n",
    "from scipy.optimize import minimize\n",
    "from scipy.sparse.linalg import eigs\n",
    "from scipy.stats import wasserstein_distance\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reservoir:\n",
    "    def __init__(self, rk, rsvr_size = 300, spectral_radius = 0.6, input_weight = 1):\n",
    "        self.rsvr_size = rsvr_size\n",
    "        \n",
    "        #get spectral radius < 1\n",
    "        #gets row density = 0.03333\n",
    "        unnormalized_W = (np.random.rand(rsvr_size,rsvr_size)*2 - 1)\n",
    "        for i in range(unnormalized_W[:,0].size):\n",
    "            for j in range(unnormalized_W[0].size):\n",
    "                if np.random.rand(1) > 10/rsvr_size:\n",
    "                    unnormalized_W[i][j] = 0\n",
    "    \n",
    "        max_eig = eigs(unnormalized_W, k = 1, return_eigenvectors = False, maxiter = 10**5)\n",
    "        \n",
    "        self.W = sparse.csr_matrix(spectral_radius/np.abs(max_eig)*unnormalized_W)\n",
    "        \n",
    "        const_conn = int(rsvr_size*0.15)\n",
    "        Win = np.zeros((rsvr_size, 4))\n",
    "        Win[:const_conn, 0] = (np.random.rand(Win[:const_conn, 0].size)*2 - 1)*input_weight\n",
    "        Win[const_conn: const_conn + int((rsvr_size-const_conn)/3), 1] = (np.random.rand(Win[const_conn: const_conn + int((rsvr_size-const_conn)/3), 1].size)*2 - 1)*input_weight\n",
    "        Win[const_conn + int((rsvr_size-const_conn)/3):const_conn + 2*int((rsvr_size-const_conn)/3), 2] = (np.random.rand(Win[const_conn + int((rsvr_size-const_conn)/3):const_conn + 2*int((rsvr_size-const_conn)/3), 2].size)*2 - 1)*input_weight\n",
    "        Win[const_conn + 2*int((rsvr_size-const_conn)/3):, 3] = (np.random.rand(Win[const_conn + 2*int((rsvr_size-const_conn)/3):, 3].size)*2 - 1)*input_weight\n",
    "        \n",
    "        self.Win = sparse.csr_matrix(Win)\n",
    "        self.X = (np.random.rand(rsvr_size, rk.train_length+2)*2 - 1)\n",
    "        self.Wout = np.array([])\n",
    "\n",
    "        self.data_trstates = 0\n",
    "        self.states_trstates = 0\n",
    "        \n",
    "class RungeKutta:\n",
    "    def __init__(self, x0 = 2,y0 = 2,z0 = 23, h = 0.01, T = 300, ttsplit = 5000, noise_scaling = 0):\n",
    "        u_arr = rungekutta(x0,y0,z0,h,T)[:, ::10] \n",
    "        self.train_length = ttsplit\n",
    "        \n",
    "        u_arr[0] = (u_arr[0] - 0)/7.929788629895004\n",
    "        u_arr[1] = (u_arr[1] - 0)/8.9932616136662\n",
    "        u_arr[2] = (u_arr[2] - 23.596294463016896)/8.575917849311919\n",
    "        \n",
    "        self.u_arr_train = u_arr[:, :ttsplit+1] \n",
    "        #size 5001\n",
    "        \n",
    "        #noisy training array\n",
    "        #switch to gaussian \n",
    "        noise = np.random.randn(self.u_arr_train[:,0].size, self.u_arr_train[0,:].size)*noise_scaling \n",
    "        self.u_arr_train_noise = self.u_arr_train + noise\n",
    "        \n",
    "        #plt.plot(self.u_arr_train_noise[0, :500])\n",
    "        \n",
    "        #u[5000], the 5001st element, is the last in u_arr_train and the first in u_arr_test\n",
    "        self.u_arr_test = u_arr[:, ttsplit:]\n",
    "        #size 1001\n",
    "    \n",
    "#takes a reservoir object res along with initial conditions\n",
    "def getX(res, rk,x0 = 1,y0 = 1,z0 = 1, noise = False):\n",
    "    \n",
    "    if noise:\n",
    "        u_training = rk.u_arr_train_noise\n",
    "    else:\n",
    "        u_training = rk.u_arr_train\n",
    "    \n",
    "    #loops through every timestep\n",
    "    for i in range(0, u_training[0].size):\n",
    "        u = np.append(1, u_training[:,i]).reshape(4,1)\n",
    "        \n",
    "        x = res.X[:,i].reshape(res.rsvr_size,1)\n",
    "        x_update = np.tanh(np.add(res.Win.dot(u), res.W.dot(x)))\n",
    "        \n",
    "        res.X[:,i+1] = x_update.reshape(1,res.rsvr_size)    \n",
    "    \n",
    "    return res.X\n",
    "\n",
    "def get_states(res, rk, skip = 150):\n",
    "    Y_train = rk.u_arr_train_noise[:, skip+1:]\n",
    "    X = getX(res, rk, noise = True)[:, skip+1:(res.X[0].size - 1)]\n",
    "    X_train = np.concatenate((np.ones((1, rk.u_arr_train[0].size-(skip+1))), X, rk.u_arr_train_noise[:, skip:-1]), axis = 0)\n",
    "    res.data_trstates = np.matmul(Y_train, np.transpose(X_train))\n",
    "    res.states_trstates = np.matmul(X_train,np.transpose(X_train))\n",
    "\n",
    "    return \n",
    "    \n",
    "def trainRRM(res, rk, skip = 150, alpha = 10**-4):\n",
    "    print(\"Training... \")\n",
    "\n",
    "    alph = alpha\n",
    "    #rrm = Ridge(alpha = alph, solver = 'cholesky')\n",
    "    \n",
    "    Y_train = rk.u_arr_train_noise[:, skip+1:]\n",
    "\n",
    "    \n",
    "    X = getX(res, rk, noise = True)[:, skip+1:(res.X[0].size - 1)]\n",
    "    X_train = np.concatenate((np.ones((1, rk.u_arr_train[0].size-(skip+1))), X, rk.u_arr_train_noise[:, skip:-1]), axis = 0) \n",
    "    #X_train = np.copy(X)\n",
    "    \n",
    "    idenmat = np.identity(res.rsvr_size+4)*alph\n",
    "    data_trstates = np.matmul(Y_train, np.transpose(X_train))\n",
    "    states_trstates = np.matmul(X_train,np.transpose(X_train))\n",
    "    res.Wout = np.transpose(solve(np.transpose(states_trstates + idenmat),np.transpose(data_trstates)))\n",
    "    \n",
    "    #optimization function needs perc. of stable res. \n",
    "    #scipy.optimize.minimize\n",
    "    #https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize\n",
    "    \n",
    "    #function which takes log of alpha, give perc. of stable reservoirs\n",
    "\n",
    "    #split up train function to find matrices first, second one which computed Wout\n",
    "    #https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.fminbound.html \n",
    "    #allows to set range of alpha\n",
    "\n",
    "    print(\"Training complete \")\n",
    "    #Y_train = Y_train.transpose()\n",
    "    #X_train = X.transpose()\n",
    "    \n",
    "    #tweak regression param? use 10^-4, 10^-6\n",
    "    #test Ridge() in simpler context\n",
    "    #rrm.fit(X_train,Y_train)\n",
    "    #res.Wout = rrm.coef_\n",
    "    return res.Wout\n",
    "\n",
    "def repeatTraining(res, T = 300, ttsplit = int(300/0.1), repeat_times = 10, skip = 150, noise_scaling = 0.1):\n",
    "    ic = np.random.rand(3)*2-1\n",
    "    rk = RungeKutta(x0 = ic[0], y0 = ic[1], z0 = 30*ic[2], T = T, ttsplit = ttsplit, noise_scaling = noise_scaling)\n",
    "    \n",
    "    print(\"Training... \")\n",
    "\n",
    "    alph = 10**-6\n",
    "    #rrm = Ridge(alpha = alph, solver = 'cholesky')\n",
    "    \n",
    "    #train on 10 small training sets with different noise - minimize error over all\n",
    "    #save the state of the reservoir for noisy datasets\n",
    "    #also try - train on signal^2 or other function (get more info than just 3 vars) - no noise\n",
    "    \n",
    "    Y_train = rk.u_arr_train[:, skip+1:] \n",
    "    oneTime = rk.u_arr_train[:, skip+1:]\n",
    "    \n",
    "    X = getX(res, rk, noise = True)[:, skip+1:-1]\n",
    "    \n",
    "    Y_inputs = rk.u_arr_train_noise[:, skip:(rk.u_arr_train_noise[0].size - 1)]\n",
    "    for i in range(repeat_times-1):\n",
    "        Y_train = np.concatenate((Y_train, oneTime), axis = 1)\n",
    "        noise = np.random.randn(rk.u_arr_train[:,0].size, rk.u_arr_train[0,:].size)*noise_scaling\n",
    "        rk.u_arr_train_noise = rk.u_arr_train + noise \n",
    "        X = np.concatenate((X, getX(res, rk, noise = True)[:, skip+1:-1]), axis = 1)\n",
    "        Y_inputs = np.concatenate((Y_inputs, rk.u_arr_train_noise[:, skip:(rk.u_arr_train_noise[0].size - 1)]), axis = 1) \n",
    "        \n",
    "    X_train = np.concatenate((np.ones((1, repeat_times*(rk.u_arr_train[0].size-(skip+1)))), X, Y_inputs), axis = 0) \n",
    "    #X_train = np.copy(X)\n",
    "    \n",
    "    idenmat = np.identity(res.rsvr_size+4)*alph\n",
    "    data_trstates = np.matmul(Y_train, np.transpose(X_train))\n",
    "    states_trstates = np.matmul(X_train,np.transpose(X_train))\n",
    "    res.Wout = np.transpose(solve(np.transpose(states_trstates + idenmat),np.transpose(data_trstates)))\n",
    "    \n",
    "    print(\"Training complete \")\n",
    "    #Y_train = Y_train.transpose()\n",
    "    #X_train = X.transpose()\n",
    "    \n",
    "    #tweak regression param? use 10^-4, 10^-6\n",
    "    #test Ridge() in simpler context\n",
    "    #rrm.fit(X_train,Y_train)\n",
    "    #res.Wout = rrm.coef_\n",
    "    return res.Wout \n",
    "\n",
    "def repeatTrainingAvg(res, T = 100, ttsplit = 400, repeat_times = 10, noise_scaling = 0.01): \n",
    "    rk = RungeKutta(T = T,ttsplit = ttsplit) \n",
    "    Wout_final = np.zeros((3,res.rsvr_size+4))\n",
    "    \n",
    "    for i in range(repeat_times):\n",
    "        noise = np.random.randn(rk.u_arr_train[:,0].size, rk.u_arr_train[0,:].size)*noise_scaling \n",
    "        rk.u_arr_train_noise = rk.u_arr_train + noise\n",
    "        Wout_final = np.add(Wout_final, trainRRM(res, rk, skip = 100))\n",
    "    \n",
    "    res.Wout = Wout_final/repeat_times\n",
    "    \n",
    "#CONCATENATE ALL THE DATA BEFORE RUNNING REGRESSION\n",
    "    \n",
    "def predict(res, x0 = 0, y0 = 0, z0 = 0, steps = 1000):\n",
    "    Y = np.empty((3, steps + 1))\n",
    "    X = np.empty((res.rsvr_size, steps + 1))\n",
    "    \n",
    "    Y[:,0] = np.array([x0,y0,z0]).reshape(1,3) \n",
    "    X[:,0] = res.X[:,-2]\n",
    "\n",
    "    \n",
    "    for i in range(0, steps):\n",
    "        y_in = np.append(1, Y[:,i]).reshape(4,1)\n",
    "        x_prev = X[:,i].reshape(res.rsvr_size,1)\n",
    "        \n",
    "        x_current = np.tanh(np.add(res.Win.dot(y_in), res.W.dot(x_prev)))\n",
    "        X[:,i+1] = x_current.reshape(1,res.rsvr_size)\n",
    "        #X = np.concatenate((X, x_current), axis = 1)\n",
    "        \n",
    "        y_out = np.matmul(res.Wout, np.concatenate((np.array([[1]]), x_current, Y[:,i].reshape(3,1)), axis = 0))\n",
    "        #y_out = np.matmul(res.Wout, x_current)\n",
    "        Y[:,i+1] = y_out.reshape(1, 3)\n",
    "        \n",
    "\n",
    "    return Y\n",
    "\n",
    "def test(res, num_tests = 10, rkTime = 1000, split = 3000, showMapError = True, showTrajectories = True, showHist = True):\n",
    "\n",
    "    stable_count = 0\n",
    "    valid_time = np.array([])\n",
    "    max_sum_square = np.array([])\n",
    "    mean_sum_square = np.array([]) \n",
    "    means = np.zeros(num_tests)\n",
    "    variances = np.zeros(num_tests)\n",
    "    for i in range(num_tests):\n",
    "        \n",
    "        vtchange = 0\n",
    "        \n",
    "    \n",
    "        ic = np.random.rand(3)*2-1\n",
    "        rktest = RungeKutta(x0 = ic[0], y0 = ic[1], z0 = 30*ic[2], T = rkTime, ttsplit = split)\n",
    "        res.X = (np.zeros((res.rsvr_size, split+2))*2 - 1)\n",
    "        \n",
    "        #sets res.X\n",
    "        getX(res, rktest)\n",
    "        \n",
    "        pred = predict(res, x0 = rktest.u_arr_test[0,0], \\\n",
    "                       y0 = rktest.u_arr_test[1,0], \\\n",
    "                       z0 = rktest.u_arr_test[2,0], steps = (int(rkTime/0.1)-split))\n",
    "        x2y2z2 = np.zeros(pred[0].size-1)\n",
    "        lorenz_map_x = np.zeros(pred[0].size)\n",
    "        lorenz_map_x[0] = pred[0][0]\n",
    "        \n",
    "        check_vt = True\n",
    "        for j in range(0, pred[0].size):\n",
    "            if (j > 0):\n",
    "                wtchange = vtchange + np.sum((rktest.u_arr_test[:,j]-rktest.u_arr_test[:,j-1])**2)\n",
    "                #vtchange = vtchange + (rktest.u_arr_test[0, j] - rktest.u_arr_test[0, j-1])**2\\\n",
    "                #+ (rktest.u_arr_test[1, j] - rktest.u_arr_test[1, j-1])**2 + \\\n",
    "                #(rktest.u_arr_test[2, j] - rktest.u_arr_test[2, j-1])**2\n",
    "                rkmap = RungeKutta(pred[0][j-1]*7.929788629895004, \\\n",
    "                                   pred[1][j-1]*8.9932616136662, \\\n",
    "                                   pred[2][j-1]*8.575917849311919+23.596294463016896, h=0.01, T=0.1)\n",
    "                lorenz_map_x[j] = rkmap.u_arr_train[0][1] \n",
    "                \n",
    "                #EXAMINE!!!\n",
    "                # x2error = (pred[0][j]-rkmap.u_arr_train[0][1])**2\n",
    "                # y2error = (pred[1][j]-rkmap.u_arr_train[1][1])**2\n",
    "                # z2error = (pred[2][j]-rkmap.u_arr_train[2][1])**2\n",
    "                # x2y2z2 = np.append(x2y2z2, (x2error+y2error+z2error)) \n",
    "                x2y2z2[j-1] = np.sum((pred[:,j]-rkmap.u_arr_train[:,1])**2) \n",
    "                \n",
    "            if (np.abs(pred[0, j] - rktest.u_arr_test[0, j]) > 1.5) and check_vt:\n",
    "                valid_time = np.append(valid_time, j)\n",
    "                \n",
    "                # print(\"Test \" + str(i) + \" valid time: \" + str(j))\n",
    "                check_vt = False\n",
    "        \n",
    "        x2y2z2 = x2y2z2/1.45\n",
    "        #print(vtchange/(pred[0].size-1)) \n",
    "        #print(\"Mean: \" + str(np.mean(pred[0])))\n",
    "        #print(\"Variance: \" + str(np.var(pred[0])))\n",
    "        \n",
    "        if showHist:\n",
    "            plt.figure() \n",
    "            plt.hist(pred[0], bins = 11, label = \"Predictions\", alpha = 0.75)\n",
    "            plt.hist(rktest.u_arr_test[0], bins = 11, label = \"Truth\", alpha = 0.75)\n",
    "            plt.legend(loc=\"upper right\")\n",
    "        \n",
    "        if showMapError:\n",
    "            #plt.figure()\n",
    "            #plt.plot(vector_field, label = \"Vector Field Stability Metric\")\n",
    "            #plt.legend(loc=\"upper right\") \n",
    "\n",
    "            plt.figure() \n",
    "            plt.plot(x2y2z2, label = \"x + y + z square error\")\n",
    "            plt.legend(loc=\"upper right\")\n",
    "            \n",
    "        if showTrajectories:\n",
    "            plt.figure() \n",
    "            #plt.plot(lorenz_map_x, label = \"Map Trajectory\", color = \"green\") \n",
    "            plt.plot(pred[0], label = \"Predictions\")\n",
    "            plt.plot(rktest.u_arr_test[0], label = \"Truth\") \n",
    "            plt.legend(loc=\"upper right\") \n",
    "        \n",
    "        \"\"\"\n",
    "        print(\"Variance of lorenz data x dim: \" + str(np.var(rktest.u_arr_test[0])))\n",
    "        print(\"Variance of predictions: \" + str(np.var(pred[0]))) \n",
    "        print(\"Max of total square error: \" + str(max(x2y2z2)))\n",
    "        print(\"Mean of total error: \" + str(np.mean(x2y2z2)))\n",
    "        print(\"Wasserstein distance: \" + str(wasserstein_distance(pred[0], rktest.u_arr_test[0])))\n",
    "        print()\n",
    "        \"\"\"\n",
    "        max_sum_square = np.append(max_sum_square, max(x2y2z2))\n",
    "        mean_sum_square = np.append(mean_sum_square, np.mean(x2y2z2)) \n",
    "        \n",
    "        means[i] = np.mean(pred[0])\n",
    "        variances[i] = np.var(pred[0])\n",
    "        \n",
    "        if np.mean(x2y2z2) < 0.01 and 0.98 < np.var(pred[0]) and np.var(pred[0]) < 1.01:\n",
    "            stable_count += 1\n",
    "            \"\"\"\n",
    "            print(\"stable\")\n",
    "            print()\n",
    "            \"\"\"\n",
    "        else:\n",
    "            \"\"\"\n",
    "            print(\"unstable\")\n",
    "            print() \n",
    "            \"\"\"\n",
    "    \n",
    "    \n",
    "    if showMapError or showTrajectories or showHist:\n",
    "        plt.show()\n",
    "    \n",
    "    #print(\"Variance of total square error: \" + str(np.var(x2y2z2)))\n",
    "    \"\"\"\n",
    "    print(\"Avg. max sum square: \" + str(np.mean(max_sum_square)))\n",
    "    print(\"Avg. mean sum square: \" + str(np.mean(mean_sum_square))) \n",
    "    print(\"Avg. of x dim: \" + str(np.mean(means)))\n",
    "    print(\"Var. of x dim: \" + str(np.mean(variances)))\n",
    "    print()\n",
    "    \"\"\"\n",
    "    \n",
    "    return stable_count/num_tests\n",
    "\n",
    "def generate_res(num_res, rk, res_size):\n",
    "\n",
    "    reservoirs = []\n",
    "    with tqdm(total = num_res) as pbar:\n",
    "        while len(reservoirs) < num_res:\n",
    "            try:\n",
    "                reservoirs.append(Reservoir(rk, rsvr_size = res_size, spectral_radius = 0.5, input_weight = 1.0))\n",
    "                get_states(reservoirs[-1], rk, skip = 150)\n",
    "                pbar.update(1)\n",
    "            except:\n",
    "                print(\"eigenvalue error occured.\")\n",
    "    return reservoirs\n",
    "\n",
    "def optim_func(reservoirs, alpha):\n",
    "\n",
    "    results = np.array([])\n",
    "    with tqdm(total = len(reservoirs)) as pbar:\n",
    "        for res in reservoirs: \n",
    "            try:\n",
    "                idenmat = np.identity(res.rsvr_size+4)*alpha\n",
    "                res.Wout = np.transpose(solve(np.transpose(res.states_trstates + idenmat),np.transpose(res.data_trstates))) \n",
    "\n",
    "                results = np.append(results, test(res, 1, rkTime = 400, \\\n",
    "                      split = 2000, showMapError = False, showTrajectories = False, showHist = False))\n",
    "                pbar.update(1)\n",
    "            except:\n",
    "                print(\"eigenvalue error occured.\")\n",
    "    print(np.mean(results))\n",
    "    return -1*np.mean(results)\n",
    "\n",
    "def trainAndTest(alph):\n",
    "\n",
    "    results = np.array([])\n",
    "    num_res = 10\n",
    "\n",
    "    for i in range(num_res):\n",
    "        try:\n",
    "            ic = np.random.rand(3)*2-1\n",
    "            rk = RungeKutta(x0 = ic[0], y0 = ic[1], z0 = 30*ic[2], T = 500, ttsplit = int(500/0.1), noise_scaling = 0.01)\n",
    "            res = Reservoir(rk, rsvr_size = 100, spectral_radius = 0.5, input_weight = 1.0)\n",
    "            \n",
    "            trainRRM(res, rk, skip = 150, alpha = alph)\n",
    "            \n",
    "            results = np.append(results, test(res, 1, rkTime = 400, split = 2000, showMapError = False, showTrajectories = False, showHist = False))\n",
    "        except:\n",
    "            print(\"eigenvalue error occured.\")\n",
    "    return -1*np.mean(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:07<00:00,  6.84it/s]\n",
      " 74%|████████████████████████████████████████████████████████████▋                     | 37/50 [00:07<00:02,  5.21it/s]c:\\users\\alexander\\anaconda3\\envs\\reservoir-rls\\lib\\site-packages\\numpy\\core\\_methods.py:205: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:09<00:00,  5.07it/s]\n",
      "  2%|█▋                                                                                 | 1/50 [00:00<00:09,  5.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|██████████████████████████▏                                                       | 16/50 [00:03<00:06,  5.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eigenvalue error occured.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|████████████████████████████████████████████████████████████████████████████████▎ | 49/50 [00:09<00:00,  5.17it/s]\n",
      "  0%|                                                                                           | 0/50 [00:00<?, ?it/s]c:\\users\\alexander\\anaconda3\\envs\\reservoir-rls\\lib\\site-packages\\ipykernel_launcher.py:193: RuntimeWarning: overflow encountered in matmul\n",
      "c:\\users\\alexander\\anaconda3\\envs\\reservoir-rls\\lib\\site-packages\\ipykernel_launcher.py:193: RuntimeWarning: invalid value encountered in matmul\n",
      "c:\\users\\alexander\\anaconda3\\envs\\reservoir-rls\\lib\\site-packages\\ipykernel_launcher.py:235: RuntimeWarning: overflow encountered in double_scalars\n",
      "c:\\users\\alexander\\anaconda3\\envs\\reservoir-rls\\lib\\site-packages\\ipykernel_launcher.py:236: RuntimeWarning: overflow encountered in double_scalars\n",
      "c:\\users\\alexander\\anaconda3\\envs\\reservoir-rls\\lib\\site-packages\\ipykernel_launcher.py:234: RuntimeWarning: overflow encountered in double_scalars\n",
      "  2%|█▋                                                                                 | 1/50 [00:00<00:09,  5.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4897959183673469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|██████████████████████████████████████████▋                                       | 26/50 [00:05<00:04,  5.10it/s]c:\\users\\alexander\\anaconda3\\envs\\reservoir-rls\\lib\\site-packages\\numpy\\core\\_methods.py:202: RuntimeWarning: invalid value encountered in subtract\n",
      "  x = asanyarray(arr - arrmean)\n",
      " 56%|█████████████████████████████████████████████▉                                    | 28/50 [00:05<00:04,  5.12it/s]"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "np.random.seed(0)\n",
    "\n",
    "train_time = 500\n",
    "res_size = 100\n",
    "res_per_test = 50\n",
    "noise_values = np.logspace(-3.666666666666, 0, num = 12, base = 10) \n",
    "\n",
    "#rk = RungeKutta(x0 = 1, y0 = 1, z0 = 30, T = train_time, ttsplit = int(train_time/0.1), noise_scaling = 0.01)\n",
    "#reservoirs = generate_res(res_per_test, rk, res_size = res_size)\n",
    "ic = np.random.rand(3)*2-1\n",
    "rk = RungeKutta(x0 = ic[0], y0 = ic[1], z0 = 30*ic[2], T = train_time, ttsplit = int(train_time/0.1), noise_scaling = 0)\n",
    "for noise_scaling in noise_values:\n",
    "    rk_test = rk\n",
    "    noise = np.random.randn(rk_test.u_arr_train[:,0].size, rk_test.u_arr_train[0,:].size)*noise_scaling \n",
    "    rk_test.u_arr_train_noise = rk_test.u_arr_train + noise\n",
    "\n",
    "    reservoirs = generate_res(res_per_test, rk, res_size = res_size)\n",
    "    for r in reservoirs:\n",
    "        # r.data_trstates = 0\n",
    "        # r.states_trstates = 0 \n",
    "        get_states(r, rk, skip = 150)\n",
    "\n",
    "    min_optim_func = lambda alpha: optim_func(reservoirs, alpha)\n",
    "    result = minimize(min_optim_func, 10**-3)\n",
    "    f = open(\"noise varying data\", \"a\")\n",
    "    now = datetime.now()\n",
    "    currenttime = now.strftime(\"%H:%M:%S\")\n",
    "    f.write(currenttime)\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"noise level: \" + str(noise_scaling))\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"res size: \" + str(res_size))\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"train time: \" + str(train_time))\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"max fraction of stable reservoirs: \" + str(-1*result.fun))\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"optimal alpha: \" + str(result.x))\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
