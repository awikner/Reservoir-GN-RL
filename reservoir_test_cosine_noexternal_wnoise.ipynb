{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reservoir_rls_multires import *\n",
    "import matplotlib.pyplot as plt\n",
    "from lorenz63 import *\n",
    "from scipy.signal import welch, periodogram\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import cma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AdaptSigma': 'True  # or False or any CMAAdaptSigmaBase class e.g. CMAAdaptSigmaTPA, CMAAdaptSigmaCSA', 'CMA_active': 'True  # negative update, conducted after the original update', 'CMA_cmean': '1  # learning rate for the mean value', 'CMA_const_trace': 'False  # normalize trace, 1, True, \"arithm\", \"geom\", \"aeig\", \"geig\" are valid', 'CMA_diagonal': '0*100*N/popsize**0.5  # nb of iterations with diagonal covariance matrix, True for always', 'CMA_eigenmethod': 'np.linalg.eigh  # or cma.utilities.math.eig or pygsl.eigen.eigenvectors', 'CMA_elitist': 'False  #v or \"initial\" or True, elitism likely impairs global search performance', 'CMA_injections_threshold_keep_len': '1  #v keep length if Mahalanobis length is below the given relative threshold', 'CMA_mirrors': 'popsize < 6  # values <0.5 are interpreted as fraction, values >1 as numbers (rounded), otherwise about 0.16 is used', 'CMA_mirrormethod': '2  # 0=unconditional, 1=selective, 2=selective with delay', 'CMA_mu': 'None  # parents selection parameter, default is popsize // 2', 'CMA_on': '1  # multiplier for all covariance matrix updates', 'CMA_sampler': 'None  # a class or instance that implements the interface of `cma.interfaces.StatisticalModelSamplerWithZeroMeanBaseClass`', 'CMA_sampler_options': '{}  # options passed to `CMA_sampler` class init as keyword arguments', 'CMA_rankmu': '1.0  # multiplier for rank-mu update learning rate of covariance matrix', 'CMA_rankone': '1.0  # multiplier for rank-one update learning rate of covariance matrix', 'CMA_recombination_weights': 'None  # a list, see class RecombinationWeights, overwrites CMA_mu and popsize options', 'CMA_dampsvec_fac': 'np.Inf  # tentative and subject to changes, 0.5 would be a \"default\" damping for sigma vector update', 'CMA_dampsvec_fade': '0.1  # tentative fading out parameter for sigma vector update', 'CMA_teststds': 'None  # factors for non-isotropic initial distr. of C, mainly for test purpose, see CMA_stds for production', 'CMA_stds': 'None  # multipliers for sigma0 in each coordinate, not represented in C, makes scaling_of_variables obsolete', 'CSA_dampfac': '1  #v positive multiplier for step-size damping, 0.3 is close to optimal on the sphere', 'CSA_damp_mueff_exponent': '0.5  # zero would mean no dependency of damping on mueff, useful with CSA_disregard_length option', 'CSA_disregard_length': 'False  #v True is untested, also changes respective parameters', 'CSA_clip_length_value': 'None  #v poorly tested, [0, 0] means const length N**0.5, [-1, 1] allows a variation of +- N/(N+2), etc.', 'CSA_squared': 'False  #v use squared length for sigma-adaptation ', 'BoundaryHandler': 'BoundTransform  # or BoundPenalty, unused when ``bounds in (None, [None, None])``', 'bounds': '[None, None]  # lower (=bounds[0]) and upper domain boundaries, each a scalar or a list/vector', 'conditioncov_alleviate': '[1e8, 1e12]  # when to alleviate the condition in the coordinates and in main axes', 'eval_final_mean': 'True  # evaluate the final mean, which is a favorite return candidate', 'fixed_variables': 'None  # dictionary with index-value pairs like {0:1.1, 2:0.1} that are not optimized', 'ftarget': '-inf  #v target function value, minimization', 'integer_variables': '[]  # index list, invokes basic integer handling: prevent std dev to become too small in the given variables', 'is_feasible': 'is_feasible  #v a function that computes feasibility, by default lambda x, f: f not in (None, np.NaN)', 'maxfevals': 'inf  #v maximum number of function evaluations', 'maxiter': '100 + 150 * (N+3)**2 // popsize**0.5  #v maximum number of iterations', 'mean_shift_line_samples': 'False #v sample two new solutions colinear to previous mean shift', 'mindx': '0  #v minimal std in any arbitrary direction, cave interference with tol*', 'minstd': '0  #v minimal std (scalar or vector) in any coordinate direction, cave interference with tol*', 'maxstd': 'inf  #v maximal std in any coordinate direction', 'pc_line_samples': 'False #v one line sample along the evolution path pc', 'popsize': '4+int(3*np.log(N))  # population size, AKA lambda, number of new solution per iteration', 'randn': 'np.random.randn  #v randn(lam, N) must return an np.array of shape (lam, N), see also cma.utilities.math.randhss', 'scaling_of_variables': 'None  # deprecated, rather use fitness_transformations.ScaleCoordinates instead (or possibly CMA_stds).\\n            Scale for each variable in that effective_sigma0 = sigma0*scaling. Internally the variables are divided by\\n            scaling_of_variables and sigma is unchanged, default is `np.ones(N)`', 'seed': 'time  # random number seed for `numpy.random`; `None` and `0` equate to `time`, `np.nan` means \"do nothing\", see also option \"randn\"', 'signals_filename': 'cma_signals.in  # read versatile options from this file (use `None` or `\"\"` for no file) which contains a single options dict, e.g. ``{\"timeout\": 0}`` to stop, string-values are evaluated, e.g. \"np.inf\" is valid', 'termination_callback': '[]  #v a function or list of functions returning True for termination, called in `stop` with `self` as argument, could be abused for side effects', 'timeout': 'inf  #v stop if timeout seconds are exceeded, the string \"2.5 * 60**2\" evaluates to 2 hours and 30 minutes', 'tolconditioncov': '1e14  #v stop if the condition of the covariance matrix is above `tolconditioncov`', 'tolfacupx': '1e3  #v termination when step-size increases by tolfacupx (diverges). That is, the initial step-size was chosen far too small and better solutions were found far away from the initial solution x0', 'tolupsigma': '1e20  #v sigma/sigma0 > tolupsigma * max(eivenvals(C)**0.5) indicates \"creeping behavior\" with usually minor improvements', 'tolflatfitness': '1  #v iterations tolerated with flat fitness before termination', 'tolfun': '1e-11  #v termination criterion: tolerance in function value, quite useful', 'tolfunhist': '1e-12  #v termination criterion: tolerance in function value history', 'tolfunrel': '0  #v termination criterion: relative tolerance in function value: Delta f current < tolfunrel * (median0 - median_min)', 'tolstagnation': 'int(100 + 100 * N**1.5 / popsize)  #v termination if no improvement over tolstagnation iterations', 'tolx': '1e-11  #v termination criterion: tolerance in x-changes', 'transformation': 'None  # depreciated, use cma.fitness_transformations.FitnessTransformation instead.\\n            [t0, t1] are two mappings, t0 transforms solutions from CMA-representation to f-representation (tf_pheno),\\n            t1 is the (optional) back transformation, see class GenoPheno', 'typical_x': 'None  # used with scaling_of_variables', 'updatecovwait': 'None  #v number of iterations without distribution update, name is subject to future changes', 'verbose': '3  #v verbosity e.g. of initial/final message, -1 is very quiet, -9 maximally quiet, may not be fully implemented', 'verb_append': '0  # initial evaluation counter, if append, do not overwrite output files', 'verb_disp': '100  #v verbosity: display console output every verb_disp iteration', 'verb_filenameprefix': 'outcmaes\\\\  # output path and filenames prefix', 'verb_log': '1  #v verbosity: write data to files every verb_log iteration, writing can be time critical on fast to evaluate functions', 'verb_log_expensive': 'N * (N <= 50)  # allow to execute eigendecomposition for logging every verb_log_expensive iteration, 0 or False for never', 'verb_plot': '0  #v in fmin(): plot() is called every verb_plot iteration', 'verb_time': 'True  #v output timings on console', 'vv': '{}  #? versatile set or dictionary for hacking purposes, value found in self.opts[\"vv\"]'}\n"
     ]
    }
   ],
   "source": [
    "print(cma.CMAOptions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [00:22<00:00,  8.96it/s]\n"
     ]
    }
   ],
   "source": [
    "get_data = False\n",
    "data_length = 1000000\n",
    "step = 0.05\n",
    "f_s = 1/step\n",
    "scale = 0.01\n",
    "slow_var = 48/28\n",
    "r_t = lambda x: r_t_cosine(x)\n",
    "dx_dt = lambda x, time, r_t: dxdt_lorenz(x, time, r_t)\n",
    "if get_data:\n",
    "    lorenz_data_cosine = getLorenzData(data_length, r_t, dx_dt, sample_tau = step)\n",
    "    # np.savetxt('lorenz_data_cosine_step%0.2f.csv' %(step), lorenz_data_cosine, delimiter = ',')\n",
    "else:\n",
    "    lorenz_data_cosine = np.loadtxt('lorenz_data_cosine_step%0.2f.csv' %(step), delimiter = ',')\n",
    "times = np.arange(lorenz_data_cosine.shape[0])*step\n",
    "external_data = r_t(times)\n",
    "scaled_data = lorenz_data_cosine\n",
    "scaled_data = np.ascontiguousarray(scaled_data)\n",
    "num_nodes = 360\n",
    "train_length = 3000\n",
    "num_tests = 200\n",
    "sync_length = 200\n",
    "pred_length = 500\n",
    "res_seed = 1\n",
    "base_res = reservoir(3,num_nodes,input_weight = 1, spectral_radius = 1, seed = res_seed) #Generate a reservoir\n",
    "mask = ['input_weight', 'regularization', 'leakage', 'forget']\n",
    "x0 = np.array([4.636771438402045, 4.6364128276072565, 5.673582356077067, 9.196194509537818])\n",
    "min_func_base = lambda x: vt_min_function_norm(np.ascontiguousarray(lorenz_data_cosine), x, mask,\\\n",
    "    base_res.Win, base_res.A, num_nodes, num_tests, sync_length, train_length, pred_length, \\\n",
    "    noise_scale = 0.2, noise_realizations = 1, evenspace = True, returnall = True)\n",
    "results = min_func_base(x0)\n",
    "    # np.savetxt('cosine_noexternal_results.csv', results_data, delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.0\n"
     ]
    }
   ],
   "source": [
    "print(np.median(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phase_min_func(delay, truth, filtered):\n",
    "    delay = round(delay)\n",
    "    truth_delayed = truth[:truth.shape[0]-delay]\n",
    "    filtered_delayed = filtered[delay:]\n",
    "    val = -np.mean(truth_delayed * filtered_delayed)\n",
    "    return val\n",
    "def min_func_wphase(x, mask, base_data, f_s, true_external_data,\\\n",
    "    base_res, num_tests, num_nodes, pred_length, train_length, scale = True, \n",
    "    external_output = True):\n",
    "    init_delay = 20000\n",
    "    max_freq = 0.15\n",
    "    min_freq = 0.001\n",
    "    Wn_xy = x[0]/10*(max_freq-min_freq)+min_freq\n",
    "    Wn_z = Wn_xy\n",
    "    data_split = separate_lorenz_2scale(base_data, f_s, Wn_xy, Wn_z, filter_order = 10)\n",
    "    base_external_data = data_split[init_delay:,-1]\n",
    "    num_delays = 10000\n",
    "    z_centered = base_external_data - np.mean(base_external_data)\n",
    "    min_func   = lambda delay: phase_min_func(delay, true_external_data[init_delay:], z_centered)\n",
    "    func_vals = np.zeros(num_delays)\n",
    "    for i in range(num_delays):\n",
    "        func_vals[i] = min_func(i)\n",
    "    min_delay = np.argmin(func_vals)\n",
    "    data = base_data[init_delay:base_data.shape[0]-min_delay]\n",
    "    external_data = base_external_data[min_delay:]\n",
    "    if scale:\n",
    "        SS = StandardScaler()\n",
    "        external_data = SS.fit_transform(external_data.reshape(-1,1))\n",
    "    funval = vt_min_function_norm_external(data,external_data, x[1:], mask, base_res.Win, base_res.A, \\\n",
    "        num_tests = num_tests,  num_nodes = num_nodes, pred_length = pred_length, train_length = train_length,\\\n",
    "        external_output = external_output)\n",
    "    return funval\n",
    "def min_func_wtruth(x, mask, base_data, f_s, true_external_data,\\\n",
    "    base_res, num_tests, num_nodes, pred_length, train_length, scale = True, \n",
    "    external_output = True):\n",
    "    init_delay = 0\n",
    "    data = base_data[init_delay:]\n",
    "    external_data = true_external_data[init_delay:]\n",
    "    if scale:\n",
    "        SS = StandardScaler()\n",
    "        external_data = SS.fit_transform(external_data.reshape(-1,1))\n",
    "    funval = vt_min_function_norm_external(data,external_data, x, mask, base_res.Win, base_res.A, \\\n",
    "        num_tests = num_tests,  num_nodes = num_nodes, pred_length = pred_length, train_length = train_length,\\\n",
    "        external_output = external_output)\n",
    "    return funval\n",
    "num_nodes = 360\n",
    "num_tests = 200\n",
    "train_length = 3000\n",
    "sync_length = 200\n",
    "pred_length = 500\n",
    "res_seed = 1\n",
    "base_res = reservoir(3,num_nodes,input_weight = 1, spectral_radius = 1, seed = res_seed) #Generate a reservoir\n",
    "mask = ['input_weight', 'regularization', 'leakage', 'forget']\n",
    "x0 = np.array([6,4,0,9])\n",
    "min_func_base = lambda x: vt_min_function_norm(np.ascontiguousarray(lorenz_data_cosine), x, mask,\\\n",
    "    base_res.Win, base_res.A, num_nodes, num_tests, sync_length, train_length, pred_length)\n",
    "sigma = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'AdaptSigma': 'True  # or False or any CMAAdaptSigmaBase class e.g. CMAAdaptSigmaTPA, CMAAdaptSigmaCSA', 'CMA_active': 'True  # negative update, conducted after the original update', 'CMA_cmean': '1  # learning rate for the mean value', 'CMA_const_trace': 'False  # normalize trace, 1, True, \"arithm\", \"geom\", \"aeig\", \"geig\" are valid', 'CMA_diagonal': '0*100*N/popsize**0.5  # nb of iterations with diagonal covariance matrix, True for always', 'CMA_eigenmethod': 'np.linalg.eigh  # or cma.utilities.math.eig or pygsl.eigen.eigenvectors', 'CMA_elitist': 'False  #v or \"initial\" or True, elitism likely impairs global search performance', 'CMA_injections_threshold_keep_len': '1  #v keep length if Mahalanobis length is below the given relative threshold', 'CMA_mirrors': 'popsize < 6  # values <0.5 are interpreted as fraction, values >1 as numbers (rounded), otherwise about 0.16 is used', 'CMA_mirrormethod': '2  # 0=unconditional, 1=selective, 2=selective with delay', 'CMA_mu': 'None  # parents selection parameter, default is popsize // 2', 'CMA_on': '1  # multiplier for all covariance matrix updates', 'CMA_sampler': 'None  # a class or instance that implements the interface of `cma.interfaces.StatisticalModelSamplerWithZeroMeanBaseClass`', 'CMA_sampler_options': '{}  # options passed to `CMA_sampler` class init as keyword arguments', 'CMA_rankmu': '1.0  # multiplier for rank-mu update learning rate of covariance matrix', 'CMA_rankone': '1.0  # multiplier for rank-one update learning rate of covariance matrix', 'CMA_recombination_weights': 'None  # a list, see class RecombinationWeights, overwrites CMA_mu and popsize options', 'CMA_dampsvec_fac': 'np.Inf  # tentative and subject to changes, 0.5 would be a \"default\" damping for sigma vector update', 'CMA_dampsvec_fade': '0.1  # tentative fading out parameter for sigma vector update', 'CMA_teststds': 'None  # factors for non-isotropic initial distr. of C, mainly for test purpose, see CMA_stds for production', 'CMA_stds': 'None  # multipliers for sigma0 in each coordinate, not represented in C, makes scaling_of_variables obsolete', 'CSA_dampfac': '1  #v positive multiplier for step-size damping, 0.3 is close to optimal on the sphere', 'CSA_damp_mueff_exponent': '0.5  # zero would mean no dependency of damping on mueff, useful with CSA_disregard_length option', 'CSA_disregard_length': 'False  #v True is untested, also changes respective parameters', 'CSA_clip_length_value': 'None  #v poorly tested, [0, 0] means const length N**0.5, [-1, 1] allows a variation of +- N/(N+2), etc.', 'CSA_squared': 'False  #v use squared length for sigma-adaptation ', 'BoundaryHandler': 'BoundTransform  # or BoundPenalty, unused when ``bounds in (None, [None, None])``', 'bounds': '[None, None]  # lower (=bounds[0]) and upper domain boundaries, each a scalar or a list/vector', 'conditioncov_alleviate': '[1e8, 1e12]  # when to alleviate the condition in the coordinates and in main axes', 'eval_final_mean': 'True  # evaluate the final mean, which is a favorite return candidate', 'fixed_variables': 'None  # dictionary with index-value pairs like {0:1.1, 2:0.1} that are not optimized', 'ftarget': '-inf  #v target function value, minimization', 'integer_variables': '[]  # index list, invokes basic integer handling: prevent std dev to become too small in the given variables', 'is_feasible': 'is_feasible  #v a function that computes feasibility, by default lambda x, f: f not in (None, np.NaN)', 'maxfevals': 'inf  #v maximum number of function evaluations', 'maxiter': '100 + 150 * (N+3)**2 // popsize**0.5  #v maximum number of iterations', 'mean_shift_line_samples': 'False #v sample two new solutions colinear to previous mean shift', 'mindx': '0  #v minimal std in any arbitrary direction, cave interference with tol*', 'minstd': '0  #v minimal std (scalar or vector) in any coordinate direction, cave interference with tol*', 'maxstd': 'inf  #v maximal std in any coordinate direction', 'pc_line_samples': 'False #v one line sample along the evolution path pc', 'popsize': '4+int(3*np.log(N))  # population size, AKA lambda, number of new solution per iteration', 'randn': 'np.random.randn  #v randn(lam, N) must return an np.array of shape (lam, N), see also cma.utilities.math.randhss', 'scaling_of_variables': 'None  # deprecated, rather use fitness_transformations.ScaleCoordinates instead (or possibly CMA_stds).\\n            Scale for each variable in that effective_sigma0 = sigma0*scaling. Internally the variables are divided by\\n            scaling_of_variables and sigma is unchanged, default is `np.ones(N)`', 'seed': 'time  # random number seed for `numpy.random`; `None` and `0` equate to `time`, `np.nan` means \"do nothing\", see also option \"randn\"', 'signals_filename': 'cma_signals.in  # read versatile options from this file (use `None` or `\"\"` for no file) which contains a single options dict, e.g. ``{\"timeout\": 0}`` to stop, string-values are evaluated, e.g. \"np.inf\" is valid', 'termination_callback': '[]  #v a function or list of functions returning True for termination, called in `stop` with `self` as argument, could be abused for side effects', 'timeout': 'inf  #v stop if timeout seconds are exceeded, the string \"2.5 * 60**2\" evaluates to 2 hours and 30 minutes', 'tolconditioncov': '1e14  #v stop if the condition of the covariance matrix is above `tolconditioncov`', 'tolfacupx': '1e3  #v termination when step-size increases by tolfacupx (diverges). That is, the initial step-size was chosen far too small and better solutions were found far away from the initial solution x0', 'tolupsigma': '1e20  #v sigma/sigma0 > tolupsigma * max(eivenvals(C)**0.5) indicates \"creeping behavior\" with usually minor improvements', 'tolflatfitness': '1  #v iterations tolerated with flat fitness before termination', 'tolfun': '1e-11  #v termination criterion: tolerance in function value, quite useful', 'tolfunhist': '1e-12  #v termination criterion: tolerance in function value history', 'tolfunrel': '0  #v termination criterion: relative tolerance in function value: Delta f current < tolfunrel * (median0 - median_min)', 'tolstagnation': 'int(100 + 100 * N**1.5 / popsize)  #v termination if no improvement over tolstagnation iterations', 'tolx': '1e-11  #v termination criterion: tolerance in x-changes', 'transformation': 'None  # depreciated, use cma.fitness_transformations.FitnessTransformation instead.\\n            [t0, t1] are two mappings, t0 transforms solutions from CMA-representation to f-representation (tf_pheno),\\n            t1 is the (optional) back transformation, see class GenoPheno', 'typical_x': 'None  # used with scaling_of_variables', 'updatecovwait': 'None  #v number of iterations without distribution update, name is subject to future changes', 'verbose': '3  #v verbosity e.g. of initial/final message, -1 is very quiet, -9 maximally quiet, may not be fully implemented', 'verb_append': '0  # initial evaluation counter, if append, do not overwrite output files', 'verb_disp': '100  #v verbosity: display console output every verb_disp iteration', 'verb_filenameprefix': 'outcmaes\\\\  # output path and filenames prefix', 'verb_log': '1  #v verbosity: write data to files every verb_log iteration, writing can be time critical on fast to evaluate functions', 'verb_log_expensive': 'N * (N <= 50)  # allow to execute eigendecomposition for logging every verb_log_expensive iteration, 0 or False for never', 'verb_plot': '0  #v in fmin(): plot() is called every verb_plot iteration', 'verb_time': 'True  #v output timings on console', 'vv': '{}  #? versatile set or dictionary for hacking purposes, value found in self.opts[\"vv\"]'}\n"
     ]
    }
   ],
   "source": [
    "opts = cma.CMAOptions()\n",
    "print(opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20_w,40)-aCMA-ES (mu_w=11.3,w_1=16%) in dimension 4 (seed=5, Tue Jan 26 11:33:23 2021)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-8a2d3195e808>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mopts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'verb_filenameprefix'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfoldername\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_func_base\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopts\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Run the algorithm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\alexander\\dropbox\\alexanderwikner_1\\umd grad school\\reservoir-gn-rl-new\\pycma-awikner-patch-1\\cma\\evolution_strategy.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(objective_function, x0, sigma0, options, args, gradf, restarts, restart_from_best, incpopsize, eval_initial_x, parallel_objective, noise_handler, noise_change_sigma_exponent, noise_kappa_exponent, bipop, callback)\u001b[0m\n\u001b[0;32m   4387\u001b[0m                                              \u001b[0mevaluations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnoisehandler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4388\u001b[0m                                              \u001b[0maggregation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4389\u001b[1;33m                                              parallel_mode=parallel_objective)  # treats NaN with resampling if not parallel_mode\n\u001b[0m\u001b[0;32m   4390\u001b[0m                     \u001b[1;31m# TODO: check args and in case use args=(noisehandler.evaluations, )\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alexander\\dropbox\\alexanderwikner_1\\umd grad school\\reservoir-gn-rl-new\\pycma-awikner-patch-1\\cma\\evolution_strategy.py\u001b[0m in \u001b[0;36mask_and_eval\u001b[1;34m(self, func, args, gradf, number, xmean, sigma_fac, evaluations, aggregation, kappa, parallel_mode)\u001b[0m\n\u001b[0;32m   2412\u001b[0m                     \u001b[1;31m# self.more_to_write += [length_normalizer * 1e-3, length_normalizer * self.mahalanobis_norm(x - xmean) * 1e2]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2414\u001b[1;33m                 \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mkappa\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2415\u001b[0m                     func(xmean + kappa * length_normalizer * (x - xmean),\n\u001b[0;32m   2416\u001b[0m                          *args)\n",
      "\u001b[1;32m<ipython-input-3-14a36dfb3ee2>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[0mx0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m min_func_base = lambda x: vt_min_function_norm(np.ascontiguousarray(lorenz_data_cosine), x, mask,\\\n\u001b[1;32m---> 56\u001b[1;33m     base_res.Win, base_res.A, num_nodes, num_tests, sync_length, train_length, pred_length)\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[0msigma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Dropbox\\AlexanderWikner_1\\UMD Grad School\\Reservoir-GN-RL-new\\reservoir_rls_multires.py\u001b[0m in \u001b[0;36mvt_min_function_norm\u001b[1;34m(data, hyperparams, mask, base_Win, base_A, num_nodes, num_tests, sync_length, train_length, pred_length, separated)\u001b[0m\n\u001b[0;32m    602\u001b[0m         valid_times = cross_validation_performance_resync(data, res, num_tests, sync_length, \\\n\u001b[0;32m    603\u001b[0m                                                    \u001b[0mtrain_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 604\u001b[1;33m                                                    train_method = 'Normal')\n\u001b[0m\u001b[0;32m    605\u001b[0m     \u001b[1;31m# print('Input Weight: %e, Reg: %e' % (input_weight, regularization))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_times\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Dropbox\\AlexanderWikner_1\\UMD Grad School\\Reservoir-GN-RL-new\\reservoir_rls_multires.py\u001b[0m in \u001b[0;36mcross_validation_performance_resync\u001b[1;34m(data, reservoir, num_tests, sync_length, train_length, pred_length, seed, errormax, train_method, progress, plot)\u001b[0m\n\u001b[0;32m    780\u001b[0m                 \u001b[0mreservoir\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainWoutRLS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msync_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 782\u001b[1;33m                 \u001b[0mreservoir\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainWout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msync_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    783\u001b[0m             \u001b[1;31m# Evaluate the prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    784\u001b[0m             \u001b[0mreservoir\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msynchronize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresync_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Dropbox\\AlexanderWikner_1\\UMD Grad School\\Reservoir-GN-RL-new\\reservoir_rls_multires.py\u001b[0m in \u001b[0;36mtrainWout\u001b[1;34m(self, train_data, sync_length, pass_data, external_input, external_output)\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;31m# Then, begin training over all remaining data points\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msync_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m             \u001b[0maug_r\u001b[0m               \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m             \u001b[0maug_r\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m          \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maug_r\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Square every other node\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Dropbox\\AlexanderWikner_1\\UMD Grad School\\Reservoir-GN-RL-new\\reservoir_rls_multires.py\u001b[0m in \u001b[0;36madvance\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;31m# Update the reservoir state using the tanh activation function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdateRes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleakage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdateRes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleakage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Dropbox\\AlexanderWikner_1\\UMD Grad School\\Reservoir-GN-RL-new\\reservoir_rls_multires.py\u001b[0m in \u001b[0;36mupdateRes\u001b[1;34m(r, leakage, A, Win, input)\u001b[0m\n\u001b[0;32m   1066\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mupdateRes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleakage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1067\u001b[0m     \u001b[0mnewr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mleakage\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mr\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mleakage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1068\u001b[1;33m             \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1069\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnewr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1070\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alexander\\anaconda3\\envs\\reservoir-rls\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36mdot\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m         \"\"\"\n\u001b[1;32m--> 359\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alexander\\anaconda3\\envs\\reservoir-rls\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__mul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    465\u001b[0m             \u001b[1;31m# Fast path for the most common case\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 467\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mul_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    468\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    469\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mul_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alexander\\anaconda3\\envs\\reservoir-rls\\lib\\site-packages\\scipy\\sparse\\coo.py\u001b[0m in \u001b[0;36m_mul_vector\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    581\u001b[0m         result = np.zeros(self.shape[0], dtype=upcast_char(self.dtype.char,\n\u001b[0;32m    582\u001b[0m                                                             other.dtype.char))\n\u001b[1;32m--> 583\u001b[1;33m         \u001b[0mcoo_matvec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnnz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    584\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "opts = cma.CMAOptions()\n",
    "opts.set('popsize',10*x0.size) # Set number of samples per generation\n",
    "\"\"\"\n",
    "Set bounds on parameters. IMPORTANT: The mean returned by cma-es is\n",
    "the mean BEFORE the boundary function is applied, so the mean may not\n",
    "lie in the domain set by bounds. To obtain the true sample mean requires \n",
    "downloading the cma-es package from github and editing one of the \n",
    "functions. Ask me if you need to do this.\n",
    "\"\"\"\n",
    "opts.set('bounds', [0,10]) \n",
    "opts.set('seed', 5) # Seed for the initial samples\n",
    "\"\"\"\n",
    "File where results are saved. IMPORTANT: Full covariance matrix is \n",
    "NOT saved, nor are the exact samples. If these need to be saved, one\n",
    "will also have to download from github and make some edits. Again,\n",
    "ask me.\n",
    "\"\"\"\n",
    "foldername = 'cmaes_lorenz_cosine_noextern_res%d\\\\' % res_seed\n",
    "import os\n",
    "if not os.path.exists(foldername):\n",
    "    os.makedirs(foldername)\n",
    "else:\n",
    "    for root, dirs, files in os.walk(foldername):\n",
    "        for file in files:\n",
    "            os.remove(os.path.join(root, file))\n",
    "opts.set('verb_filenameprefix',foldername)\n",
    "results = cma.fmin(min_func_base, x0, sigma, options = opts) # Run the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_length = 100000\n",
    "step = 0.05\n",
    "f_s = 1/step\n",
    "scale = 0.01\n",
    "slow_var = 48/28\n",
    "r_t = lambda x: r_t_const(x)\n",
    "dx_dt = lambda x, time, r_t: dxdt_lorenz(x, time, r_t)\n",
    "lorenz_data = getLorenzData(data_length, r_t, dx_dt, sample_tau = step)\n",
    "scaled_data = np.ascontiguousarray(lorenz_data)\n",
    "plt.plot(lorenz_data[:1000,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [00:21<00:00,  9.42it/s]\n",
      "  0%|▍                                                                                 | 1/200 [00:00<00:22,  8.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 21.  44.  29.  37.  32.  11.   2.  67.   5.  25.  61.  40.   9.   5.\n",
      "  22.   8.  32.  47.   7.  21.  19. 158.  40.  41.  29.  51.  25.   5.\n",
      "  77.   7.  36.  39.  57.   6.  18.  64.   7.  34.  33.  56.  23.  31.\n",
      "  64.  44.  68.  14.  47.  43.  24.  13.  13.  25.  54.  74.  23.  53.\n",
      "   8.   6.  18.   6.  25.  16.   3.  14.  10.  10.   5.  15.  22.  24.\n",
      "  10.  20.   9.   6.  42.  29.   9.  38.   4.  17.  33.  32.   8.  16.\n",
      "  13.  24.  54.   8.   8.  30.  63.  18.  22.  10.  34.  33.   9.   6.\n",
      "   1.   3.   2.  16.   4.   2.  87.  15.  22.  50.  18.  26.  19.  31.\n",
      "  18.   5.   7.  35.  82. 108.  15.   7.  42.   7.  51.  39.  63.   9.\n",
      "  12.  23.  13.  27.   6.  42.  45.  13.  37.   7.  13. 117.  15.  35.\n",
      "  78.  20.  19.  88.  97.  14.   5.  11.   8.  25.  58.  13.  20.  37.\n",
      "   8.  46.   3.   6.  29.  17.  21.  11.  21.  24.  49.  33.  17.   5.\n",
      "  18.  17.  19.  10.   5.  69.  38.   5.  17.  15.  62.  72.   6.  10.\n",
      "   9.  36.  22.  75.  74.  20. 143.  74.  48.  61.   7.  95.  33.   6.\n",
      "  26.  26.   6.  37.]\n",
      "21.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [00:22<00:00,  9.02it/s]\n",
      "  0%|▍                                                                                 | 1/200 [00:00<00:21,  9.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 21.  12.  29.  35.  21.  11.   2.  67.   5.  24.  63.  39.   9.   5.\n",
      "  22.   8.  33.  47.   7.  20.  17. 114.  41.  41.  29.  50.  26.   5.\n",
      "  76.   6.  56.  50.  58.   6.  18.  75.   7.  33.  33.  58.  23.  31.\n",
      "  53.  44.  41.  15.  46.  44.  33.  11.  12.  25.  54.  74.  22.  38.\n",
      "   8.   6.  18.   6.  24.  16.   3.  14.   9.  10.   5.  40.  22.  25.\n",
      "  10.  21.   8.   6.  40.  29.   9.  28.   4.  17.  32.  32.   8.  16.\n",
      "  13.  24.  29.   8.   8.  29.  63.  18.  21.  11.  21.  33.   9.   6.\n",
      "   1.   3.   2.  15.   4.   2.  65.  14.  22.  50.  19.  28.  19.  18.\n",
      "  18.   5.   7.  38.  81. 109.  17.   7.  44.   7.  50.  39.  64.   9.\n",
      "  13.  23.  11.  27.   6.  41.  45.  13.  36.   7.  13. 118.  14.  36.\n",
      "  78.  20.  22.  88.  53.  14.   5.  11.   8.  25.  57.  13.  20.  22.\n",
      "   7.  45.   3.   6.  29.  17.  21.  11.  22.  49.  49.  33.  25.   5.\n",
      "  18.  17.  10.   9.   5.  69.  38.   5.  17.  26.  62.  83.   6.   9.\n",
      "   9.  36.  22.  76.  45.  20. 146.  73.  44.  61.   7.  53.  30.   6.\n",
      "  27.  25.   6.  37.]\n",
      "21.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [00:21<00:00,  9.26it/s]\n",
      "  0%|▍                                                                                 | 1/200 [00:00<00:24,  8.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 24.  10.  27.  22.  34.   7.   3.  65.  17.   5. 127.  25.  18.   5.\n",
      "  69.   7.  33.  60.  20.  20.  38.  70.  38.  40.  65.  49.  26.   7.\n",
      "  26.   6.  34.  53.  57.   6.  33.  17.   9.  10.  30.  44.  50. 112.\n",
      "  53.  43.  41.  11.   7.  71.  12.  11.  24.  66.  57.  64.  36.  56.\n",
      "  10.   6.   7.  33.  22.  16.   3.  14.   6.  10.   9.  12.  23.  22.\n",
      "   9.  22.  22.   5.  27.  15.  13.  66.   4.  21.  61.  10.  20.  18.\n",
      "  36.  10.  16.   3.  38.  47.  64.  18.   9.  24.  21.  35.   9.  21.\n",
      "   5.   4.   5.  16.   4.   3.  28.  14.  44.  52.  32.  29.  51.  30.\n",
      "  23.  13.   8.  51. 108. 122.  17.   5.  48.   7.  67.  40.  22.  10.\n",
      "  12.  23.  22.  38.   6.  41.  17.  65.  38.   8.  15.  79.  14.  31.\n",
      " 103.  21.  18. 101.  52.  12.   6.  15.   8.  26. 112.  27.  19.  10.\n",
      "   4.  22.   3.   5.  15.  17.   8.  32.  60.  23.  92.  32.  15.   4.\n",
      "  10.  31.  10.  21.   8.  23.  40.   7.  15.  21.  62.  38.   6.  12.\n",
      "   9.  36.  13.  39.  58.  18.  74.  72.  98.  58.  19.  53.  18.   7.\n",
      "  38.  27.  11.   8.]\n",
      "22.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [00:22<00:00,  8.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 23.  10.  27.  21.  35.   8.   6.  67.  17.   4. 103.  25.  19.   5.\n",
      "  24.   8.  75.  92.  20.  22.  18.  70.  38.  32.  65.  49.  25.   7.\n",
      "  26.   6.  34.  54.  57.   5.  33.  17.   3.  10.  30.  44.  54.  33.\n",
      "  52.  43.  41.  11.   6.  70.  12.  10.  35.  66.  57.  65.  36.  92.\n",
      "  10.   5.   7.  44.  23.  16.   2.  14.   7.  10.   6.  13.  23.  22.\n",
      "   9.  23.  23.   5.  27.  15.  14.  69.   3.  21.  34.  21.  29.  15.\n",
      "  37.  10.  15.   3.  51.  48.  64.  18.  20.  24.  21.  35.   9.  21.\n",
      "   2.   4.   1.  17.   4.   6.  30.  13.  44.  52.  44.  29.  42.  30.\n",
      "  20.  13.   7.  92. 109. 122.  17.   6.  46.   7. 122.  42.  22.  10.\n",
      "  15.  23.  16.  37.   7.  41.  17.  64.  38.   7.   4.  79.  16.  31.\n",
      " 103.  22.  20. 100.  51.  11.   8.  14.   7.  25. 112.   6.  19.  22.\n",
      "   4.  22.   2.   5.  16.  17.   8.  34.  60.  23. 102.  32.  14.   3.\n",
      "  10.  31.  11.  33.   9.  57.  40.   5.  15.  22.  62.  37.   6.  11.\n",
      "  18.  36.  13.  39.  59.  18. 116.  72.  46.  58.  13.  53.  19.   7.\n",
      "  38.  36.   5.  29.]\n",
      "22.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import expit\n",
    "res_rossler = reservoir(4, 360, input_weight = 0.01, leakage =  0, \\\n",
    "                        regularization = 1e-7, forget = 1, seed = 1)\n",
    "train_length = 3000\n",
    "sync_length = 500\n",
    "pred_length = 500\n",
    "num_tests = 200\n",
    "# results = cross_validation_performance_resync_wextern(scaled_data, scaled_data_external, res_rossler, num_tests, sync_length, train_length, pred_length, \\\n",
    "#          seed = 10, errormax = 3.2, train_method = 'Normal', progress = True, plot = False)\n",
    "results = cross_validation_performance_resync_wextern(new_scaled_data, new_scaled_data_external, \\\n",
    "         res_rossler, num_tests, sync_length, train_length, pred_length, \\\n",
    "         seed = 10, errormax = 3.2, train_method = 'Normal', progress = True, external_output = False)\n",
    "print(results)\n",
    "print(np.median(results))\n",
    "results = cross_validation_performance_resync_wextern(new_scaled_data, new_scaled_data_external, \\\n",
    "         res_rossler, num_tests, sync_length, train_length, pred_length, \\\n",
    "         seed = 10, errormax = 3.2, train_method = 'Normal', progress = True, external_output = True)\n",
    "print(results)\n",
    "print(np.median(results))\n",
    "results = cross_validation_performance_resync_wextern(new_scaled_data, new_data_external, res_rossler, num_tests, sync_length, train_length, pred_length, \\\n",
    "         seed = 10, errormax = 3.2, train_method = 'Normal', progress = True, external_output = False)\n",
    "print(results)\n",
    "print(np.median(results))\n",
    "results = cross_validation_performance_resync_wextern(new_scaled_data, new_data_external, res_rossler, num_tests, sync_length, train_length, pred_length, \\\n",
    "         seed = 10, errormax = 3.2, train_method = 'Normal', progress = True, external_output = True)\n",
    "print(results)\n",
    "print(np.median(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:21<00:00,  9.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 20.   8.  10.   7.  16.   9.  10.  25.  18.  24.   8.   2.   9.   8.\n",
      " 122.  12.  19.   6.  10.   3.  24.   9.  17.  28.  17.   5.   4.   5.\n",
      "  13.   9.  11.   8.  15.  19.  13.  21.  12.  11.  17.  39.  19.  13.\n",
      "  10.   4.   8.  20.   6.  26.  21.   9.  16.   9.   3.  16.   2.  16.\n",
      "  10.  10.  37.   5.   5.  14.  12.  15.   7.   7.   6.   5.  12.  12.\n",
      "  11.   9.  24.  22.  17.   5.  47.   4.  12.  14.  15.  89.  27.  27.\n",
      "  14.   9.   9.  18.  17.   6.   4.   8.   6.   4.   4.   9.  10.   5.\n",
      "  14.   9.  69.   4.   8.  13.   8.   8.  17.   2.   5.   9.   5.   8.\n",
      "   7.  39.   5.   5.  31.  20.  15.   3.  15.  19.   4.  19.   9.   6.\n",
      "   6.  13.  12.  15.  19.   8.   5.  22.   9.   8.   7.   3.  45.  11.\n",
      "   5.   6.  27.  19.  23.  12.   8.  21.   8.   4.  16.  15.   8.   8.\n",
      "   7.  27.   8.   7.   3.  10.   5.  18.   8.  13.   4.  10.  74.  13.\n",
      "  14.  12.   1.  10.  24.   9.  20.  30.   6.  25.  46.  15.   5.  15.\n",
      "  18.  19.  21.  10.   6.   7.  17.  16.   5.   8.   9.  11.  25.   7.\n",
      "  22.   4.   8.  13.]\n",
      "10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "res_rossler = reservoir(3, 360, input_weight = 0.01, leakage =  0, \\\n",
    "                        regularization = 1e-7, forget = 1, seed = 1)\n",
    "train_length = 3000\n",
    "sync_length = 500\n",
    "pred_length = 500\n",
    "num_tests = 200\n",
    "# results = cross_validation_performance_resync_wextern(scaled_data, scaled_data_external, res_rossler, num_tests, sync_length, train_length, pred_length, \\\n",
    "#          seed = 10, errormax = 3.2, train_method = 'Normal', progress = True, plot = False)\n",
    "results = cross_validation_performance_resync(scaled_data, res_rossler, num_tests, sync_length, train_length, pred_length, \\\n",
    "         seed = 10, errormax = 3.2, train_method = 'Normal', progress = True)\n",
    "print(results)\n",
    "print(np.median(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([[1,2,3,4],[5,6,7,8]]).T/np.array([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data = True\n",
    "data_length = 2500000\n",
    "step = 0.05\n",
    "f_s = 1/step\n",
    "scale = 1\n",
    "r_t = lambda x: r_t_const(x)\n",
    "dx_dt = lambda x, time, r_t: dxdt_rossler(x, time, r_t, scale = scale)\n",
    "if get_data:\n",
    "    rossler_data = getLorenzData(data_length, r_t, dx_dt, sample_tau = step)\n",
    "    np.savetxt('rossler_data_step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 100\n",
    "num_tests = 100\n",
    "train_length = 10000\n",
    "sync_length = 500\n",
    "pred_length = 2000\n",
    "res_seed = 1\n",
    "base_res = reservoir(1,num_nodes,input_weight = 1, spectral_radius = 1, seed = res_seed) #Generate a reservoir\n",
    "mask = ['input_weight', 'regularization', 'leakage']\n",
    "x0 = np.array([6,6,6])\n",
    "# Set the minimization function. This function takes num_tests training\n",
    "# and validation data sets and trains the reservoir to predict each validation set\n",
    "# after being trained on the corresponding training set. The negative median valid\n",
    "# time is returned to be minimized.\n",
    "min_func = lambda x: vt_min_function_norm(rossler_data[:,1], x, mask, base_res.Win, base_res.A, \\\n",
    "     num_tests = num_tests,  num_nodes = num_nodes, pred_length = pred_length, train_length = train_length)\n",
    "sigma = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = cma.CMAOptions()\n",
    "opts.set('popsize',10*x0.size) # Set number of samples per generation\n",
    "\"\"\"\n",
    "Set bounds on parameters. IMPORTANT: The mean returned by cma-es is\n",
    "the mean BEFORE the boundary function is applied, so the mean may not\n",
    "lie in the domain set by bounds. To obtain the true sample mean requires \n",
    "downloading the cma-es package from github and editing one of the \n",
    "functions. Ask me if you need to do this.\n",
    "\"\"\"\n",
    "opts.set('bounds', [0,10]) \n",
    "opts.set('seed', 5) # Seed for the initial samples\n",
    "\"\"\"\n",
    "File where results are saved. IMPORTANT: Full covariance matrix is \n",
    "NOT saved, nor are the exact samples. If these need to be saved, one\n",
    "will also have to download from github and make some edits. Again,\n",
    "ask me.\n",
    "\"\"\"\n",
    "opts.set('verb_filenameprefix','cmaes_rossler_y_norm_wleakage_res%d\\\\' % res_seed)\n",
    "results = cma.fmin(min_func, x0, sigma, options = opts) # Run the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "expit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_base = reservoir(4, 360, input_weight = 0.017, regularization = 1e-10, forget = 1)\n",
    "train_length = 3000\n",
    "sync_length = 300\n",
    "pred_length = 500\n",
    "num_tests = 100\n",
    "results = cross_validation_performance_resync(rossler_data_w_lowfreq, res_base, num_tests, sync_length, train_length, pred_length, \\\n",
    "         seed = 10, errormax = 3.2, train_method = 'Normal', progress = True)\n",
    "print(results)\n",
    "print(np.mean(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate((np.array([1,2]).reshape(-1,1),np.array([])), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_length = 100000\n",
    "step = 0.05\n",
    "r_t = lambda x: r_t_const(x)\n",
    "dx_dt = lambda x, time, r_t: dxdt_lorenz(x, time, r_t)\n",
    "lorenz_data_base = getLorenzData(data_length, r_t, dx_dt, sample_tau = step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(lorenz_data_base, axis = 0))\n",
    "print(np.std(lorenz_data_base, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_base = reservoir(3, 300, input_weight = -0.06, input_bias = 0.04, regularization = 1e-7, forget = 0.999)\n",
    "train_length = 1000\n",
    "sync_length = 500\n",
    "pred_length = 500\n",
    "num_tests = 100\n",
    "results = cross_validation_performance_resync(lorenz_data_rossler[:,:3], res_base, num_tests, sync_length, train_length, pred_length, \\\n",
    "         seed = 10, errormax = 3.2, train_method = 'Normal', progress = True, plot = False)\n",
    "print(results)\n",
    "print(np.mean(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_res = double_reservoir(6, 400, input_weight = [0.017,0.017], regularization = [1e-10,1e-10], forget = [1,0.99])\n",
    "train_length = 1000\n",
    "sync_length = 500\n",
    "pred_length = 500\n",
    "num_tests = 50\n",
    "data = np.append(lorenz_data_rossler[:,:3], lorenz_data_rossler[:,:3], axis = 1)\n",
    "target_data = lorenz_data_split\n",
    "results = cross_validation_performance_resync_decompose(data, target_data, d_res, num_tests, sync_length, train_length, pred_length, \\\n",
    "         seed = 5, errormax = 3.2, train_method = 'Normal', progress = True, plot = False)\n",
    "print(results)\n",
    "print(np.mean(results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
