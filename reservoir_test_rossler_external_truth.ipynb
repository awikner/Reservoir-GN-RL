{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reservoir_rls_multires import *\n",
    "import matplotlib.pyplot as plt\n",
    "from lorenz63 import *\n",
    "from scipy.signal import welch, periodogram\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import cma\n",
    "\n",
    "def phase_min_func(delay, truth, filtered):\n",
    "    delay = round(delay)\n",
    "    truth_delayed = truth[:truth.shape[0]-delay]\n",
    "    filtered_delayed = filtered[delay:]\n",
    "    val = -np.mean(truth_delayed * filtered_delayed)\n",
    "    return val\n",
    "def min_func_wphase(x, mask, base_data, f_s, true_external_data,\\\n",
    "    base_res, num_tests, num_nodes, pred_length, train_length, scale = True, \n",
    "    external_output = True, evenspace = False, returnall = False):\n",
    "    init_delay = 10000\n",
    "    max_freq = 0.15\n",
    "    min_freq = 0.001\n",
    "    Wn_xy = x[0]/10*(max_freq-min_freq)+min_freq\n",
    "    Wn_z = Wn_xy\n",
    "    data_split = separate_lorenz_2scale(base_data, f_s, Wn_xy, Wn_z, filter_order = 10)\n",
    "    base_external_data = data_split[init_delay:,-1]\n",
    "    num_delays = 2000\n",
    "    z_centered = base_external_data - np.mean(base_external_data)\n",
    "    min_func   = lambda delay: phase_min_func(delay, true_external_data[init_delay:], z_centered)\n",
    "    func_vals = np.zeros(num_delays)\n",
    "    for i in range(num_delays):\n",
    "        func_vals[i] = min_func(i)\n",
    "    min_delay = np.argmin(func_vals)\n",
    "    data = base_data[init_delay:base_data.shape[0]-min_delay]\n",
    "    external_data = base_external_data[min_delay:]\n",
    "    if scale:\n",
    "        SS = StandardScaler()\n",
    "        external_data = SS.fit_transform(external_data.reshape(-1,1))\n",
    "    funval = vt_min_function_norm_external(data,external_data, x[1:], mask, base_res.Win, base_res.A, \\\n",
    "        num_tests = num_tests,  num_nodes = num_nodes, pred_length = pred_length, train_length = train_length,\\\n",
    "        external_output = external_output, evenspace = evenspace, returnall = returnall)\n",
    "    return funval\n",
    "def min_func_wtruth(x, mask, base_data, f_s, true_external_data,\\\n",
    "    base_res, num_tests, num_nodes, pred_length, train_length, scale = True, \n",
    "    external_output = True, evenspace = False, returnall = False):\n",
    "    init_delay = 20000\n",
    "    data = base_data[init_delay:]\n",
    "    external_data = true_external_data[init_delay:]\n",
    "    if scale:\n",
    "        SS = StandardScaler()\n",
    "        external_data = SS.fit_transform(external_data.reshape(-1,1))\n",
    "    funval = vt_min_function_norm_external(data,external_data, x, mask, base_res.Win, base_res.A, \\\n",
    "        num_tests = num_tests,  num_nodes = num_nodes, pred_length = pred_length, train_length = train_length,\\\n",
    "        external_output = external_output, evenspace = evenspace, returnall = returnall)\n",
    "    return funval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "num_iters = 50\n",
    "num_tests = 200\n",
    "results_data = np.zeros((num_iters, num_tests))\n",
    "for i in range(num_iters):\n",
    "    get_data = True\n",
    "    data_length = 1000000\n",
    "    step = 0.05\n",
    "    f_s = 1/step\n",
    "    scale = 0.01\n",
    "    slow_var = 48/28\n",
    "    r_t = lambda x: r_t_const(x)\n",
    "    dx_dt = lambda x, time, r_t: dxdt_lorenz_rossler(x, time, r_t, scale = scale, slow_var = slow_var)\n",
    "    if get_data:\n",
    "        lorenz_data_rossler = getCoupledLorenzData(data_length, r_t, dx_dt, sample_tau = step, seed = i)\n",
    "        # np.savetxt('lorenz_data_rossler_step%0.2f_scale%0.2f.csv' %(step, scale), lorenz_data_rossler, delimiter = ',')\n",
    "    else:\n",
    "        lorenz_data_rossler = np.loadtxt('lorenz_data_rossler_step%0.2f_scale%0.2f.csv' %(step, scale), delimiter = ',')\n",
    "    init_delay = 10000\n",
    "    scaled_data = lorenz_data_rossler[init_delay:,:3]\n",
    "    scaled_data = np.ascontiguousarray(scaled_data)\n",
    "    SS = StandardScaler()\n",
    "    num_nodes = 360\n",
    "    train_length = 3000\n",
    "    sync_length = 200\n",
    "    pred_length = 500\n",
    "    res_seed = 1\n",
    "    base_res = reservoir(4,num_nodes,input_weight = 1, spectral_radius = 1, seed = res_seed) #Generate a reservoir\n",
    "    mask = ['input_weight', 'regularization', 'leakage', 'forget']\n",
    "    x0 = np.array([4.899076309767498, 4.887994175687722, 2.7757037861539144, 7.493174873050889])\n",
    "    min_func_base = lambda x: min_func_wtruth(x, mask, np.ascontiguousarray(lorenz_data_rossler[:,:3]), f_s, lorenz_data_rossler[:,4],\\\n",
    "        base_res, num_tests, num_nodes, pred_length, train_length, evenspace = True, returnall = True)\n",
    "    sigma = 2\n",
    "    results = min_func_base(x0)\n",
    "    results_data[i] = results\n",
    "    print(i)\n",
    "    np.savetxt('rossler_external_truth_results.csv', results_data, delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 360\n",
    "num_tests = 200\n",
    "train_length = 3000\n",
    "sync_length = 500\n",
    "pred_length = 500\n",
    "res_seed = 1\n",
    "base_res = reservoir(4,num_nodes,input_weight = 1, spectral_radius = 1, seed = res_seed) #Generate a reservoir\n",
    "mask = ['input_weight', 'regularization', 'leakage', 'forget']\n",
    "x0 = np.array([6,4,0,9])\n",
    "min_func_base = lambda x: min_func_wtruth(x, mask, np.ascontiguousarray(lorenz_data_rossler[:,:3]), f_s, lorenz_data_rossler[:,4],\\\n",
    "    base_res, num_tests, num_nodes, pred_length, train_length)\n",
    "sigma = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40_w,80)-aCMA-ES (mu_w=21.8,w_1=9%) in dimension 4 (seed=5, Mon Jan 25 16:10:42 2021)\n",
      "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      "    1     80 -6.250000000000000e+01 1.0e+00 2.06e+00  1e+00  2e+00 29:24.1\n",
      "    2    160 -4.800000000000000e+01 1.5e+00 2.30e+00  9e-01  2e+00 58:25.6\n",
      "    3    240 -5.700000000000000e+01 3.0e+00 2.29e+00  6e-01  2e+00 87:19.6\n",
      "    4    320 -6.450000000000000e+01 4.3e+00 2.20e+00  4e-01  2e+00 117:51.0\n",
      "    5    400 -6.450000000000000e+01 7.4e+00 2.37e+00  2e-01  3e+00 146:46.1\n",
      "    6    480 -6.750000000000000e+01 1.3e+01 2.57e+00  2e-01  2e+00 174:52.9\n",
      "    7    560 -6.900000000000000e+01 1.6e+01 2.65e+00  2e-01  3e+00 208:37.4\n",
      "    8    640 -6.400000000000000e+01 1.9e+01 2.47e+00  1e-01  2e+00 241:26.7\n",
      "    9    720 -6.450000000000000e+01 1.8e+01 2.66e+00  1e-01  2e+00 270:02.8\n",
      "   10    800 -6.650000000000000e+01 1.9e+01 2.58e+00  1e-01  2e+00 298:30.1\n",
      "   11    880 -6.750000000000000e+01 2.3e+01 2.85e+00  1e-01  2e+00 326:52.3\n",
      "   12    960 -6.400000000000000e+01 2.0e+01 2.62e+00  9e-02  2e+00 355:08.1\n",
      "   13   1040 -7.000000000000000e+01 2.1e+01 2.77e+00  1e-01  2e+00 383:13.1\n",
      "   14   1120 -6.500000000000000e+01 1.8e+01 3.05e+00  1e-01  2e+00 411:23.5\n",
      "   15   1200 -6.850000000000000e+01 1.7e+01 2.82e+00  9e-02  1e+00 439:38.8\n",
      "   16   1280 -6.400000000000000e+01 1.8e+01 3.43e+00  1e-01  2e+00 467:52.1\n"
     ]
    }
   ],
   "source": [
    "opts = cma.CMAOptions()\n",
    "opts.set('popsize',20*x0.size) # Set number of samples per generation\n",
    "\"\"\"\n",
    "Set bounds on parameters. IMPORTANT: The mean returned by cma-es is\n",
    "the mean BEFORE the boundary function is applied, so the mean may not\n",
    "lie in the domain set by bounds. To obtain the true sample mean requires \n",
    "downloading the cma-es package from github and editing one of the \n",
    "functions. Ask me if you need to do this.\n",
    "\"\"\"\n",
    "opts.set('bounds', [0,10]) \n",
    "opts.set('seed', 5) # Seed for the initial samples\n",
    "\"\"\"\n",
    "File where results are saved. IMPORTANT: Full covariance matrix is \n",
    "NOT saved, nor are the exact samples. If these need to be saved, one\n",
    "will also have to download from github and make some edits. Again,\n",
    "ask me.\n",
    "\"\"\"\n",
    "opts.set('verb_filenameprefix','cmaes_lorenz_rossler_wtruthout_scaled_res%d\\\\' % res_seed)\n",
    "results = cma.fmin(min_func_base, x0, sigma, options = opts) # Run the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_length = 100000\n",
    "step = 0.05\n",
    "f_s = 1/step\n",
    "scale = 0.01\n",
    "slow_var = 48/28\n",
    "r_t = lambda x: r_t_const(x)\n",
    "dx_dt = lambda x, time, r_t: dxdt_lorenz(x, time, r_t)\n",
    "lorenz_data = getLorenzData(data_length, r_t, dx_dt, sample_tau = step)\n",
    "scaled_data = np.ascontiguousarray(lorenz_data)\n",
    "plt.plot(lorenz_data[:1000,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [00:21<00:00,  9.42it/s]\n",
      "  0%|▍                                                                                 | 1/200 [00:00<00:22,  8.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 21.  44.  29.  37.  32.  11.   2.  67.   5.  25.  61.  40.   9.   5.\n",
      "  22.   8.  32.  47.   7.  21.  19. 158.  40.  41.  29.  51.  25.   5.\n",
      "  77.   7.  36.  39.  57.   6.  18.  64.   7.  34.  33.  56.  23.  31.\n",
      "  64.  44.  68.  14.  47.  43.  24.  13.  13.  25.  54.  74.  23.  53.\n",
      "   8.   6.  18.   6.  25.  16.   3.  14.  10.  10.   5.  15.  22.  24.\n",
      "  10.  20.   9.   6.  42.  29.   9.  38.   4.  17.  33.  32.   8.  16.\n",
      "  13.  24.  54.   8.   8.  30.  63.  18.  22.  10.  34.  33.   9.   6.\n",
      "   1.   3.   2.  16.   4.   2.  87.  15.  22.  50.  18.  26.  19.  31.\n",
      "  18.   5.   7.  35.  82. 108.  15.   7.  42.   7.  51.  39.  63.   9.\n",
      "  12.  23.  13.  27.   6.  42.  45.  13.  37.   7.  13. 117.  15.  35.\n",
      "  78.  20.  19.  88.  97.  14.   5.  11.   8.  25.  58.  13.  20.  37.\n",
      "   8.  46.   3.   6.  29.  17.  21.  11.  21.  24.  49.  33.  17.   5.\n",
      "  18.  17.  19.  10.   5.  69.  38.   5.  17.  15.  62.  72.   6.  10.\n",
      "   9.  36.  22.  75.  74.  20. 143.  74.  48.  61.   7.  95.  33.   6.\n",
      "  26.  26.   6.  37.]\n",
      "21.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [00:22<00:00,  9.02it/s]\n",
      "  0%|▍                                                                                 | 1/200 [00:00<00:21,  9.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 21.  12.  29.  35.  21.  11.   2.  67.   5.  24.  63.  39.   9.   5.\n",
      "  22.   8.  33.  47.   7.  20.  17. 114.  41.  41.  29.  50.  26.   5.\n",
      "  76.   6.  56.  50.  58.   6.  18.  75.   7.  33.  33.  58.  23.  31.\n",
      "  53.  44.  41.  15.  46.  44.  33.  11.  12.  25.  54.  74.  22.  38.\n",
      "   8.   6.  18.   6.  24.  16.   3.  14.   9.  10.   5.  40.  22.  25.\n",
      "  10.  21.   8.   6.  40.  29.   9.  28.   4.  17.  32.  32.   8.  16.\n",
      "  13.  24.  29.   8.   8.  29.  63.  18.  21.  11.  21.  33.   9.   6.\n",
      "   1.   3.   2.  15.   4.   2.  65.  14.  22.  50.  19.  28.  19.  18.\n",
      "  18.   5.   7.  38.  81. 109.  17.   7.  44.   7.  50.  39.  64.   9.\n",
      "  13.  23.  11.  27.   6.  41.  45.  13.  36.   7.  13. 118.  14.  36.\n",
      "  78.  20.  22.  88.  53.  14.   5.  11.   8.  25.  57.  13.  20.  22.\n",
      "   7.  45.   3.   6.  29.  17.  21.  11.  22.  49.  49.  33.  25.   5.\n",
      "  18.  17.  10.   9.   5.  69.  38.   5.  17.  26.  62.  83.   6.   9.\n",
      "   9.  36.  22.  76.  45.  20. 146.  73.  44.  61.   7.  53.  30.   6.\n",
      "  27.  25.   6.  37.]\n",
      "21.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [00:21<00:00,  9.26it/s]\n",
      "  0%|▍                                                                                 | 1/200 [00:00<00:24,  8.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 24.  10.  27.  22.  34.   7.   3.  65.  17.   5. 127.  25.  18.   5.\n",
      "  69.   7.  33.  60.  20.  20.  38.  70.  38.  40.  65.  49.  26.   7.\n",
      "  26.   6.  34.  53.  57.   6.  33.  17.   9.  10.  30.  44.  50. 112.\n",
      "  53.  43.  41.  11.   7.  71.  12.  11.  24.  66.  57.  64.  36.  56.\n",
      "  10.   6.   7.  33.  22.  16.   3.  14.   6.  10.   9.  12.  23.  22.\n",
      "   9.  22.  22.   5.  27.  15.  13.  66.   4.  21.  61.  10.  20.  18.\n",
      "  36.  10.  16.   3.  38.  47.  64.  18.   9.  24.  21.  35.   9.  21.\n",
      "   5.   4.   5.  16.   4.   3.  28.  14.  44.  52.  32.  29.  51.  30.\n",
      "  23.  13.   8.  51. 108. 122.  17.   5.  48.   7.  67.  40.  22.  10.\n",
      "  12.  23.  22.  38.   6.  41.  17.  65.  38.   8.  15.  79.  14.  31.\n",
      " 103.  21.  18. 101.  52.  12.   6.  15.   8.  26. 112.  27.  19.  10.\n",
      "   4.  22.   3.   5.  15.  17.   8.  32.  60.  23.  92.  32.  15.   4.\n",
      "  10.  31.  10.  21.   8.  23.  40.   7.  15.  21.  62.  38.   6.  12.\n",
      "   9.  36.  13.  39.  58.  18.  74.  72.  98.  58.  19.  53.  18.   7.\n",
      "  38.  27.  11.   8.]\n",
      "22.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [00:22<00:00,  8.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 23.  10.  27.  21.  35.   8.   6.  67.  17.   4. 103.  25.  19.   5.\n",
      "  24.   8.  75.  92.  20.  22.  18.  70.  38.  32.  65.  49.  25.   7.\n",
      "  26.   6.  34.  54.  57.   5.  33.  17.   3.  10.  30.  44.  54.  33.\n",
      "  52.  43.  41.  11.   6.  70.  12.  10.  35.  66.  57.  65.  36.  92.\n",
      "  10.   5.   7.  44.  23.  16.   2.  14.   7.  10.   6.  13.  23.  22.\n",
      "   9.  23.  23.   5.  27.  15.  14.  69.   3.  21.  34.  21.  29.  15.\n",
      "  37.  10.  15.   3.  51.  48.  64.  18.  20.  24.  21.  35.   9.  21.\n",
      "   2.   4.   1.  17.   4.   6.  30.  13.  44.  52.  44.  29.  42.  30.\n",
      "  20.  13.   7.  92. 109. 122.  17.   6.  46.   7. 122.  42.  22.  10.\n",
      "  15.  23.  16.  37.   7.  41.  17.  64.  38.   7.   4.  79.  16.  31.\n",
      " 103.  22.  20. 100.  51.  11.   8.  14.   7.  25. 112.   6.  19.  22.\n",
      "   4.  22.   2.   5.  16.  17.   8.  34.  60.  23. 102.  32.  14.   3.\n",
      "  10.  31.  11.  33.   9.  57.  40.   5.  15.  22.  62.  37.   6.  11.\n",
      "  18.  36.  13.  39.  59.  18. 116.  72.  46.  58.  13.  53.  19.   7.\n",
      "  38.  36.   5.  29.]\n",
      "22.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import expit\n",
    "res_rossler = reservoir(4, 360, input_weight = 0.01, leakage =  0, \\\n",
    "                        regularization = 1e-7, forget = 1, seed = 1)\n",
    "train_length = 3000\n",
    "sync_length = 500\n",
    "pred_length = 500\n",
    "num_tests = 200\n",
    "# results = cross_validation_performance_resync_wextern(scaled_data, scaled_data_external, res_rossler, num_tests, sync_length, train_length, pred_length, \\\n",
    "#          seed = 10, errormax = 3.2, train_method = 'Normal', progress = True, plot = False)\n",
    "results = cross_validation_performance_resync_wextern(new_scaled_data, new_scaled_data_external, \\\n",
    "         res_rossler, num_tests, sync_length, train_length, pred_length, \\\n",
    "         seed = 10, errormax = 3.2, train_method = 'Normal', progress = True, external_output = False)\n",
    "print(results)\n",
    "print(np.median(results))\n",
    "results = cross_validation_performance_resync_wextern(new_scaled_data, new_scaled_data_external, \\\n",
    "         res_rossler, num_tests, sync_length, train_length, pred_length, \\\n",
    "         seed = 10, errormax = 3.2, train_method = 'Normal', progress = True, external_output = True)\n",
    "print(results)\n",
    "print(np.median(results))\n",
    "results = cross_validation_performance_resync_wextern(new_scaled_data, new_data_external, res_rossler, num_tests, sync_length, train_length, pred_length, \\\n",
    "         seed = 10, errormax = 3.2, train_method = 'Normal', progress = True, external_output = False)\n",
    "print(results)\n",
    "print(np.median(results))\n",
    "results = cross_validation_performance_resync_wextern(new_scaled_data, new_data_external, res_rossler, num_tests, sync_length, train_length, pred_length, \\\n",
    "         seed = 10, errormax = 3.2, train_method = 'Normal', progress = True, external_output = True)\n",
    "print(results)\n",
    "print(np.median(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:21<00:00,  9.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 20.   8.  10.   7.  16.   9.  10.  25.  18.  24.   8.   2.   9.   8.\n",
      " 122.  12.  19.   6.  10.   3.  24.   9.  17.  28.  17.   5.   4.   5.\n",
      "  13.   9.  11.   8.  15.  19.  13.  21.  12.  11.  17.  39.  19.  13.\n",
      "  10.   4.   8.  20.   6.  26.  21.   9.  16.   9.   3.  16.   2.  16.\n",
      "  10.  10.  37.   5.   5.  14.  12.  15.   7.   7.   6.   5.  12.  12.\n",
      "  11.   9.  24.  22.  17.   5.  47.   4.  12.  14.  15.  89.  27.  27.\n",
      "  14.   9.   9.  18.  17.   6.   4.   8.   6.   4.   4.   9.  10.   5.\n",
      "  14.   9.  69.   4.   8.  13.   8.   8.  17.   2.   5.   9.   5.   8.\n",
      "   7.  39.   5.   5.  31.  20.  15.   3.  15.  19.   4.  19.   9.   6.\n",
      "   6.  13.  12.  15.  19.   8.   5.  22.   9.   8.   7.   3.  45.  11.\n",
      "   5.   6.  27.  19.  23.  12.   8.  21.   8.   4.  16.  15.   8.   8.\n",
      "   7.  27.   8.   7.   3.  10.   5.  18.   8.  13.   4.  10.  74.  13.\n",
      "  14.  12.   1.  10.  24.   9.  20.  30.   6.  25.  46.  15.   5.  15.\n",
      "  18.  19.  21.  10.   6.   7.  17.  16.   5.   8.   9.  11.  25.   7.\n",
      "  22.   4.   8.  13.]\n",
      "10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "res_rossler = reservoir(3, 360, input_weight = 0.01, leakage =  0, \\\n",
    "                        regularization = 1e-7, forget = 1, seed = 1)\n",
    "train_length = 3000\n",
    "sync_length = 500\n",
    "pred_length = 500\n",
    "num_tests = 200\n",
    "# results = cross_validation_performance_resync_wextern(scaled_data, scaled_data_external, res_rossler, num_tests, sync_length, train_length, pred_length, \\\n",
    "#          seed = 10, errormax = 3.2, train_method = 'Normal', progress = True, plot = False)\n",
    "results = cross_validation_performance_resync(scaled_data, res_rossler, num_tests, sync_length, train_length, pred_length, \\\n",
    "         seed = 10, errormax = 3.2, train_method = 'Normal', progress = True)\n",
    "print(results)\n",
    "print(np.median(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([[1,2,3,4],[5,6,7,8]]).T/np.array([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data = True\n",
    "data_length = 2500000\n",
    "step = 0.05\n",
    "f_s = 1/step\n",
    "scale = 1\n",
    "r_t = lambda x: r_t_const(x)\n",
    "dx_dt = lambda x, time, r_t: dxdt_rossler(x, time, r_t, scale = scale)\n",
    "if get_data:\n",
    "    rossler_data = getLorenzData(data_length, r_t, dx_dt, sample_tau = step)\n",
    "    np.savetxt('rossler_data_step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 100\n",
    "num_tests = 100\n",
    "train_length = 10000\n",
    "sync_length = 500\n",
    "pred_length = 2000\n",
    "res_seed = 1\n",
    "base_res = reservoir(1,num_nodes,input_weight = 1, spectral_radius = 1, seed = res_seed) #Generate a reservoir\n",
    "mask = ['input_weight', 'regularization', 'leakage']\n",
    "x0 = np.array([6,6,6])\n",
    "# Set the minimization function. This function takes num_tests training\n",
    "# and validation data sets and trains the reservoir to predict each validation set\n",
    "# after being trained on the corresponding training set. The negative median valid\n",
    "# time is returned to be minimized.\n",
    "min_func = lambda x: vt_min_function_norm(rossler_data[:,1], x, mask, base_res.Win, base_res.A, \\\n",
    "     num_tests = num_tests,  num_nodes = num_nodes, pred_length = pred_length, train_length = train_length)\n",
    "sigma = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = cma.CMAOptions()\n",
    "opts.set('popsize',10*x0.size) # Set number of samples per generation\n",
    "\"\"\"\n",
    "Set bounds on parameters. IMPORTANT: The mean returned by cma-es is\n",
    "the mean BEFORE the boundary function is applied, so the mean may not\n",
    "lie in the domain set by bounds. To obtain the true sample mean requires \n",
    "downloading the cma-es package from github and editing one of the \n",
    "functions. Ask me if you need to do this.\n",
    "\"\"\"\n",
    "opts.set('bounds', [0,10]) \n",
    "opts.set('seed', 5) # Seed for the initial samples\n",
    "\"\"\"\n",
    "File where results are saved. IMPORTANT: Full covariance matrix is \n",
    "NOT saved, nor are the exact samples. If these need to be saved, one\n",
    "will also have to download from github and make some edits. Again,\n",
    "ask me.\n",
    "\"\"\"\n",
    "opts.set('verb_filenameprefix','cmaes_rossler_y_norm_wleakage_res%d\\\\' % res_seed)\n",
    "results = cma.fmin(min_func, x0, sigma, options = opts) # Run the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "expit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_base = reservoir(4, 360, input_weight = 0.017, regularization = 1e-10, forget = 1)\n",
    "train_length = 3000\n",
    "sync_length = 300\n",
    "pred_length = 500\n",
    "num_tests = 100\n",
    "results = cross_validation_performance_resync(rossler_data_w_lowfreq, res_base, num_tests, sync_length, train_length, pred_length, \\\n",
    "         seed = 10, errormax = 3.2, train_method = 'Normal', progress = True)\n",
    "print(results)\n",
    "print(np.mean(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate((np.array([1,2]).reshape(-1,1),np.array([])), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_length = 100000\n",
    "step = 0.05\n",
    "r_t = lambda x: r_t_const(x)\n",
    "dx_dt = lambda x, time, r_t: dxdt_lorenz(x, time, r_t)\n",
    "lorenz_data_base = getLorenzData(data_length, r_t, dx_dt, sample_tau = step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(lorenz_data_base, axis = 0))\n",
    "print(np.std(lorenz_data_base, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_base = reservoir(3, 300, input_weight = -0.06, input_bias = 0.04, regularization = 1e-7, forget = 0.999)\n",
    "train_length = 1000\n",
    "sync_length = 500\n",
    "pred_length = 500\n",
    "num_tests = 100\n",
    "results = cross_validation_performance_resync(lorenz_data_rossler[:,:3], res_base, num_tests, sync_length, train_length, pred_length, \\\n",
    "         seed = 10, errormax = 3.2, train_method = 'Normal', progress = True, plot = False)\n",
    "print(results)\n",
    "print(np.mean(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_res = double_reservoir(6, 400, input_weight = [0.017,0.017], regularization = [1e-10,1e-10], forget = [1,0.99])\n",
    "train_length = 1000\n",
    "sync_length = 500\n",
    "pred_length = 500\n",
    "num_tests = 50\n",
    "data = np.append(lorenz_data_rossler[:,:3], lorenz_data_rossler[:,:3], axis = 1)\n",
    "target_data = lorenz_data_split\n",
    "results = cross_validation_performance_resync_decompose(data, target_data, d_res, num_tests, sync_length, train_length, pred_length, \\\n",
    "         seed = 5, errormax = 3.2, train_method = 'Normal', progress = True, plot = False)\n",
    "print(results)\n",
    "print(np.mean(results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
