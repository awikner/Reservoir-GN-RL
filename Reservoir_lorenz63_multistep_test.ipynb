{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test of Reservoir Computer prediction of Lorenz '63 System\n",
    "\n",
    "First, import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sparse\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.sparse import linalg\n",
    "from scipy.linalg import solve, pinv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define necessary  functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dxdt_lorenz(x,time,r_t, sigma = 10., beta = 8/3, rho = 28.):\n",
    "    # Evaluates derivative of Lorenz '63 system with a time-dependent\n",
    "    # rho value. For constant rho, input the r_t_const function.\n",
    "    return np.array([sigma*(- x[0] + x[1]),\\\n",
    "                     r_t(time)*rho*x[0] - x[1] - x[0]*x[2],\\\n",
    "                     x[0]*x[1]-beta*x[2]])\n",
    "    \n",
    "def rk4(x, time, tau, r_t, dxdt):\n",
    "    # Fourth order Runge-Kutta integrator\n",
    "    \n",
    "    k1 = dxdt(x, time, r_t)\n",
    "    k2 = dxdt(x + k1/2*tau, time + tau/2, r_t)\n",
    "    k3 = dxdt(x + k2/2*tau, time + tau/2, r_t)\n",
    "    k4 = dxdt(x + tau*k3, time + tau, r_t)\n",
    "    \n",
    "    xnext = x + 1/6*tau*(k1+2*k2+2*k3+k4)\n",
    "    return xnext\n",
    "\n",
    "def getLorenzData(data_length, r_t, dxdt_lorenz,transient_length = 1000, tau = 0.01,sample_tau = 0.05, seed = 5):\n",
    "    # Obtains time series of Lorenz '63 states after some initial transient time\n",
    "    sampling_rate = round(sample_tau/tau)\n",
    "    np.random.seed(seed)\n",
    "    x = np.random.rand(3)\n",
    "    time = -transient_length*tau\n",
    "    for i in range(0,transient_length):\n",
    "        x = rk4(x,time,tau,r_t,dxdt_lorenz)\n",
    "        time += tau\n",
    "    \n",
    "    data = np.zeros((3,data_length))\n",
    "    data[:,0] = x\n",
    "    for i in range(0,data_length-1):\n",
    "        data[:,i+1] = rk4(data[:,i],time,tau,r_t,dxdt_lorenz)\n",
    "        time += tau\n",
    "    \n",
    "    data = data[:,::sampling_rate]\n",
    "    return data\n",
    "\n",
    "def r_t_cosine(time, period = 500, max_height = 48/28):\n",
    "    # Function for oscillating rho value (not used here)\n",
    "    r = 1 + (max_height-1.)/2 - (max_height-1)/2*np.cos(2*np.pi/period*time)\n",
    "    return r\n",
    "\n",
    "def r_t_const(time, value = 1):\n",
    "    # Function for constant rho value\n",
    "    r = value\n",
    "    return r\n",
    "\n",
    "def advanceReservoir(win,A_mat,x,u,leakage):\n",
    "    # Equation for advancing reservoir state. Here, we do not use a bias factor.\n",
    "    x_next = leakage*x + (1-leakage)*np.tanh(A_mat.dot(x) + np.matmul(win,u))\n",
    "    return x_next\n",
    "\n",
    "def getPrediction(win, A_mat, wout, x, predict_length, leakage,timestep):\n",
    "    # Obtains a prediction of length predict_length given the trained reservoir parameters\n",
    "    prediction = np.zeros((wout.shape[0],predict_length))\n",
    "    aug_x = np.copy(x)\n",
    "    aug_x[::2] = np.power(aug_x[::2],2)\n",
    "    prediction[:,:timestep] = np.matmul(wout,aug_x)\n",
    "    x_feedback = x[:,-1]\n",
    "    \n",
    "    for pred_idx in range(0,predict_length - timestep):\n",
    "        x_feedback = advanceReservoir(win, A_mat, x_feedback, prediction[:,pred_idx], leakage)\n",
    "        aug_x = np.copy(x_feedback)\n",
    "        aug_x[::2] = np.power(aug_x[::2],2)\n",
    "        prediction[:,pred_idx + timestep] = np.matmul(wout,aug_x)\n",
    "        \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next, define reservoir hyperparameters and the length of and number of predictions to be made. Finally,  we obtain a training and testing data sequence from the Lorenz '63 system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_weight = 1e-2 #Input weight for reservoir\n",
    "regularization = 1e-5 #Tikhonov regularization term\n",
    "average_degree = 3 #Average in-degree for each reservoir node\n",
    "# forget = 1\n",
    "# inv_forget = 1/forget\n",
    "data_seed = 30  #Seed for initializing data\n",
    "timesteps = np.arange(1,21)\n",
    "leakage = 0 #Leakage parameter, unused\n",
    "spectral_radius = 0.9 #Spectral radius, maximum magnitude eigenvalue of reservoir adjacency matrix \n",
    "\n",
    "\n",
    "int_step = 0.005\n",
    "steps = np.arange(0.005,0.06,0.005) #Time step size for Lorenz system\n",
    "num_steps = len(steps)\n",
    "transient_length = 1000 #Length of initial transient input to reservoir before training begins\n",
    "data_length_base = int(5e4)\n",
    "data_length = data_length_base*steps/int_step #Length of full data set\n",
    "train_length = 5000 #Length of training data\n",
    "predict_length = 20  #Length of each prediction\n",
    "predict_gap_length = 100 #Length of time between subsequent predictions\n",
    "num_predictions = 3000  #Total number of predictions made\n",
    "\n",
    "approx_num_nodes = 300 #Approximate Number of nodes in the reservoir (rounded such that each input connects to the same number of nodes)\n",
    "np.random.seed(data_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomly generate reservoit adjacency and input matrices and initialize the reservoir node states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.28104585 0.26146857 0.1655575  0.08468628 0.52045049 0.22841742\n",
      " 0.14135072 0.46482451 0.37468858 0.47175555]\n"
     ]
    }
   ],
   "source": [
    "input_size = 3\n",
    "num_nodes = int(np.ceil(approx_num_nodes/input_size)*input_size); #Calculate number of nodes\n",
    "\n",
    "# Create the adjacency matrix and set the spectral radius\n",
    "A_mat = sparse.random(num_nodes,num_nodes, density = average_degree/num_nodes)\n",
    "eg = linalg.eigs(A_mat, k = 1, return_eigenvectors=False)\n",
    "A_mat = spectral_radius/np.abs(eg[0])*A_mat\n",
    "print(A_mat.data[:10])\n",
    "\n",
    "\n",
    "# Set the adjacency matrix such that all inputs go to the same number of nodes\n",
    "q = int(np.floor(num_nodes/(input_size)))\n",
    "win = np.zeros((num_nodes,input_size))\n",
    "for i in range(input_size):\n",
    "    np.random.seed(i)\n",
    "    ip = (-1 + 2*np.random.randn(q));\n",
    "    win[i*q:(i+1)*q,i] = input_weight*ip;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After an initial transient, record reservoir states and use them to calculate the output matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3129.22580583 -2521.32886021]\n",
      "1.3073920919247004e-05\n",
      "[-1907.64046264 -1309.19347872]\n",
      "1.2402994792524847e-05\n",
      "[-2152.78860193 -1680.55538394]\n",
      "1.4236714310434696e-05\n",
      "[-2140.44872363 -1697.6073515 ]\n",
      "1.7776833656582067e-05\n",
      "[-2099.65338931 -1688.15534117]\n",
      "2.1694106816420068e-05\n",
      "[-2366.43952081 -1956.99494011]\n",
      "2.4894103370057976e-05\n",
      "[-2407.62519806 -1998.83689358]\n",
      "3.07201939733896e-05\n",
      "[-2366.4214733 -1956.0737886]\n",
      "3.8313612641556576e-05\n",
      "[-2386.87159792 -1958.58302479]\n",
      "4.813664906204856e-05\n",
      "[-2569.63079315 -2132.27914883]\n",
      "5.875681524398331e-05\n",
      "[-2452.51359422 -2003.53678984]\n",
      "7.473320655471951e-05\n"
     ]
    }
   ],
   "source": [
    "wouts = np.zeros((input_size,num_nodes,num_steps,len(timesteps)))\n",
    "#Initialize reservoir state vector x and states array\n",
    "x = np.zeros((num_nodes,num_steps))\n",
    "states = np.zeros((num_nodes, train_length,num_steps))\n",
    "train_input_sequence = np.zeros((input_size,data_length_base,num_steps))\n",
    "training_nrms_error = np.zeros((num_steps, len(timesteps)))\n",
    "for i in range(num_steps):\n",
    "    train_input_sequence[:,:,i] = getLorenzData(round(data_length[i]),r_t_const,dxdt_lorenz,tau = int_step,sample_tau = steps[i])\n",
    "    # Advance reservoir state\n",
    "    for t in range(transient_length):\n",
    "        x[:,i] = advanceReservoir(win,A_mat,x[:,i],train_input_sequence[:,t,i],leakage)\n",
    "\n",
    "    #Begin recording states for training\n",
    "    states[:,0,i] = x[:,i];\n",
    "\n",
    "    for t in range(train_length-1):\n",
    "        states[:,t+1,i] = advanceReservoir(win,A_mat,states[:,t,i],train_input_sequence[:,t+transient_length,i],leakage)\n",
    "\n",
    "    x[:,i] = states[:,-1,i]\n",
    "\n",
    "    # We augment the reservoir states by squaring some of them to break the odd\n",
    "    # symmetry of the tanh function. We find experimentally that this improves\n",
    "    # performance for some systems.\n",
    "    aug_states = states[:,:,i]\n",
    "    aug_states[::2,:] = np.power(states[::2,:,i],2)\n",
    "    idenmat = regularization*sparse.identity(num_nodes)\n",
    "    states_trstates = np.matmul(aug_states,np.transpose(aug_states))\n",
    "    states_trstates_inv = pinv(states_trstates + idenmat)\n",
    "    norm_error = np.sqrt(np.mean(train_input_sequence[:,:,i]**2))\n",
    "    for k in range(len(timesteps)):\n",
    "        x_pred = states[:,-timesteps[k]:,i]\n",
    "        data_trstates = np.matmul(train_input_sequence[:,transient_length+timesteps[k]-1:transient_length+train_length+timesteps[k]-1,i],np.transpose(aug_states))\n",
    "        wouts[:,:,i,k] = np.matmul(data_trstates,states_trstates_inv)\n",
    "        training_error = (wouts[:,:,i,k] @ aug_states) - train_input_sequence[:,transient_length+timesteps[k]-1:transient_length+train_length+timesteps[k]-1,i]\n",
    "        training_nrms_error[i,k] = np.sqrt(np.mean(training_error**2))/norm_error\n",
    "        if k==0:\n",
    "            print(data_trstates[0:2,0])\n",
    "            print(training_nrms_error[i,k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_states = np.zeros((num_nodes, num_predictions, num_steps, len(timesteps)))\n",
    "pred_nrms_error = np.zeros((num_steps,len(timesteps)))\n",
    "for i in range(num_steps):\n",
    "    for k in range(len(timesteps)):\n",
    "        pred_states[:,0,i,k] = x[:,i]\n",
    "        for t in range(num_predictions - 1):\n",
    "            pred_states[:,t+1,i,k] = advanceReservoir(win,A_mat,pred_states[:,t,i,k],train_input_sequence[:,t+transient_length+train_length-1,i],leakage)\n",
    "        aug_pred_states = pred_states[:,:,i,k]\n",
    "        aug_pred_states[::2,:] = np.power(aug_pred_states[::2,:],2)\n",
    "        onestep_pred = wouts[:,:,i,k] @ aug_pred_states\n",
    "        norm_error = np.sqrt(np.mean(train_input_sequence[:,:,i]**2))\n",
    "        pred_start_idx = transient_length + train_length\n",
    "        pred_error = onestep_pred - train_input_sequence[:,pred_start_idx + timesteps[k] - 2:pred_start_idx + num_predictions + timesteps[k] - 2,i]\n",
    "        pred_nrms_error[i,k] = np.sqrt(np.mean(pred_error**2))/norm_error\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('Lorenz63Data/lorenz_mutltistep_trainerror.csv', pred_nrms_error, delimiter = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We evaluate the reservoir's performance over a set of prediction periods beginning right after training ends (this is not necessary, but is easiest). We then display the valid prediction times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data matrices\n",
    "error_cutoff = 1;\n",
    "predictions = np.zeros((input_size,predict_length,num_predictions))\n",
    "errors = np.zeros((predict_length,num_predictions))\n",
    "truths = np.zeros((input_size,predict_length,num_predictions))\n",
    "valid_times = np.zeros(num_predictions)\n",
    "\n",
    "\n",
    "for pred in range(num_predictions):\n",
    "    # Obtain the prediction\n",
    "    predictions[:,:,pred] = getPrediction(win,A_mat,wout,x_pred,predict_length,leakage,timestep)\n",
    "    start_pred_idx = transient_length + train_length + pred*predict_gap_length - 1\n",
    "    \n",
    "    # Compare prediction to true system and calculate valid prediction time given the normalized RMS error cutoff\n",
    "    truth = train_input_sequence[:,start_pred_idx:start_pred_idx + predict_length]\n",
    "    truths[:,:,pred] = truth\n",
    "    errors[:,pred] = np.linalg.norm(predictions[:,:,pred] - truth, axis = 0)/norm_error\n",
    "    for i in range(predict_length):\n",
    "        if errors[i,pred] > error_cutoff:\n",
    "            break\n",
    "        else:\n",
    "            valid_times[pred] += 1\n",
    "    \n",
    "    # Advance the reservoir node state to the next prediction\n",
    "    states_pred = np.zeros((num_nodes,predict_gap_length+1))\n",
    "    states_pred[:,0] = x\n",
    "    for i in range(predict_gap_length):\n",
    "        states_pred[:,i+1] = advanceReservoir(win,A_mat,states_pred[:,i],train_input_sequence[:,start_pred_idx + i],leakage)\n",
    "    x_pred = states_pred[:,-timestep:]\n",
    "    x = states_pred[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot an example prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = np.arange(0,step*predict_length,step)\n",
    "pred_idx = 10\n",
    "plt.plot(times, truths[0,:,pred_idx],label = 'Truth')\n",
    "plt.plot(times, predictions[0,:,pred_idx],label = 'Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('x(t)')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(times, truths[1,:,pred_idx],label = 'Truth')\n",
    "plt.plot(times, predictions[1,:,pred_idx],label = 'Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('y(t)')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(times, truths[2,:,pred_idx],label = 'Truth')\n",
    "plt.plot(times, predictions[2,:,pred_idx],label = 'Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('z(t)')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
