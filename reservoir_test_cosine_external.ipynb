{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reservoir_rls_multires import *\n",
    "import matplotlib.pyplot as plt\n",
    "from lorenz63 import *\n",
    "from scipy.signal import welch, periodogram\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import cma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nscaled_data_external = SS.fit_transform(lorenz_data_rossler[:,4].reshape(-1,1))\\ndata_external = lorenz_data_rossler[:,4]\\n\\nWn_xy = 0.0075\\nWn_z = Wn_xy\\nlorenz_data_split = separate_lorenz_2scale(lorenz_data_rossler[:,:3], f_s, Wn_xy, Wn_z, filter_order = 10)\\ndata_external = lorenz_data_split[init_delay:,5]\\nlorenz_data_rossler  = lorenz_data_rossler[init_delay:]\\nscaled_data_external = SS.fit_transform(data_external.reshape(-1,1))\\nplt.plot(lorenz_data_rossler[:,4])\\nplt.plot(data_external-np.mean(data_external))\\nplt.show()\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_data = True\n",
    "data_length = 1000000\n",
    "step = 0.05\n",
    "f_s = 1/step\n",
    "scale = 0.01\n",
    "slow_var = 48/28\n",
    "r_t = lambda x: r_t_cosine(x)\n",
    "dx_dt = lambda x, time, r_t: dxdt_lorenz(x, time, r_t)\n",
    "if get_data:\n",
    "    lorenz_data_cosine = getLorenzData(data_length, r_t, dx_dt, sample_tau = step)\n",
    "    np.savetxt('lorenz_data_cosine_step%0.2f.csv' %(step), lorenz_data_cosine, delimiter = ',')\n",
    "else:\n",
    "    lorenz_data_cosine = np.loadtxt('lorenz_data_cosine_step%0.2f.csv' %(step), delimiter = ',')\n",
    "times = np.arange(lorenz_data_cosine.shape[0])*step\n",
    "external_data = r_t(times)\n",
    "\"\"\"\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(111,projection = '3d')\n",
    "ax.plot3D(lorenz_data_rossler[:,0],lorenz_data_rossler[:,1],lorenz_data_rossler[:,2])\n",
    "plt.show()\n",
    "fig = plt.figure(figsize = (8,8))\n",
    "ax = fig.add_subplot(111,projection = '3d')\n",
    "ax.plot3D(lorenz_data_rossler[:,3],lorenz_data_rossler[:,4],lorenz_data_rossler[:,5])\n",
    "plt.show()\n",
    "\"\"\"\n",
    "scaled_data = lorenz_data_cosine\n",
    "scaled_data = np.ascontiguousarray(scaled_data)\n",
    "\"\"\"\n",
    "scaled_data_external = SS.fit_transform(lorenz_data_rossler[:,4].reshape(-1,1))\n",
    "data_external = lorenz_data_rossler[:,4]\n",
    "\n",
    "Wn_xy = 0.0075\n",
    "Wn_z = Wn_xy\n",
    "lorenz_data_split = separate_lorenz_2scale(lorenz_data_rossler[:,:3], f_s, Wn_xy, Wn_z, filter_order = 10)\n",
    "data_external = lorenz_data_split[init_delay:,5]\n",
    "lorenz_data_rossler  = lorenz_data_rossler[init_delay:]\n",
    "scaled_data_external = SS.fit_transform(data_external.reshape(-1,1))\n",
    "plt.plot(lorenz_data_rossler[:,4])\n",
    "plt.plot(data_external-np.mean(data_external))\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phase_min_func(delay, truth, filtered):\n",
    "    delay = round(delay)\n",
    "    truth_delayed = truth[:truth.shape[0]-delay]\n",
    "    filtered_delayed = filtered[delay:]\n",
    "    val = -np.mean(truth_delayed * filtered_delayed)\n",
    "    return val\n",
    "def min_func_wphase(x, mask, base_data, f_s, true_external_data,\\\n",
    "    base_res, num_tests, num_nodes, pred_length, train_length, scale = True, \n",
    "    external_output = True):\n",
    "    init_delay = 20000\n",
    "    max_freq = 0.15\n",
    "    min_freq = 0.001\n",
    "    Wn_xy = x[0]/10*(max_freq-min_freq)+min_freq\n",
    "    Wn_z = Wn_xy\n",
    "    data_split = separate_lorenz_2scale(base_data, f_s, Wn_xy, Wn_z, filter_order = 10)\n",
    "    base_external_data = data_split[init_delay:,-1]\n",
    "    num_delays = 10000\n",
    "    z_centered = base_external_data - np.mean(base_external_data)\n",
    "    min_func   = lambda delay: phase_min_func(delay, true_external_data[init_delay:], z_centered)\n",
    "    func_vals = np.zeros(num_delays)\n",
    "    for i in range(num_delays):\n",
    "        func_vals[i] = min_func(i)\n",
    "    min_delay = np.argmin(func_vals)\n",
    "    data = base_data[init_delay:base_data.shape[0]-min_delay]\n",
    "    external_data = base_external_data[min_delay:]\n",
    "    if scale:\n",
    "        SS = StandardScaler()\n",
    "        external_data = SS.fit_transform(external_data.reshape(-1,1))\n",
    "    funval = vt_min_function_norm_external(data,external_data, x[1:], mask, base_res.Win, base_res.A, \\\n",
    "        num_tests = num_tests,  num_nodes = num_nodes, pred_length = pred_length, train_length = train_length,\\\n",
    "        external_output = external_output)\n",
    "    return funval\n",
    "def min_func_wtruth(x, mask, base_data, f_s, true_external_data,\\\n",
    "    base_res, num_tests, num_nodes, pred_length, train_length, scale = True, \n",
    "    external_output = True):\n",
    "    init_delay = 0\n",
    "    data = base_data[init_delay:]\n",
    "    external_data = true_external_data[init_delay:]\n",
    "    if scale:\n",
    "        SS = StandardScaler()\n",
    "        external_data = SS.fit_transform(external_data.reshape(-1,1))\n",
    "    funval = vt_min_function_norm_external(data,external_data, x, mask, base_res.Win, base_res.A, \\\n",
    "        num_tests = num_tests,  num_nodes = num_nodes, pred_length = pred_length, train_length = train_length,\\\n",
    "        external_output = external_output)\n",
    "    return funval\n",
    "num_nodes = 360\n",
    "num_tests = 200\n",
    "train_length = 3000\n",
    "sync_length = 500\n",
    "pred_length = 500\n",
    "res_seed = 1\n",
    "base_res = reservoir(4,num_nodes,input_weight = 1, spectral_radius = 1, seed = res_seed) #Generate a reservoir\n",
    "mask = ['input_weight', 'regularization', 'leakage', 'forget']\n",
    "x0 = np.array([6,4,0,9])\n",
    "min_func_base = lambda x: min_func_wtruth(x, mask, scaled_data, f_s, external_data,\\\n",
    "    base_res, num_tests, num_nodes, pred_length, train_length)\n",
    "sigma = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20_w,40)-aCMA-ES (mu_w=11.3,w_1=16%) in dimension 4 (seed=5, Tue Jan 26 10:39:46 2021)\n",
      "Iterat #Fevals   function value  axis ratio  sigma  min&max std  t[m:s]\n",
      "    1     40 -5.900000000000000e+01 1.0e+00 1.95e+00  2e+00  2e+00 15:49.4\n",
      "    2     80 -6.000000000000000e+01 1.4e+00 1.81e+00  1e+00  2e+00 34:42.4\n",
      "    3    120 -6.100000000000000e+01 2.1e+00 1.55e+00  7e-01  1e+00 54:04.7\n",
      "    4    160 -5.850000000000000e+01 2.6e+00 1.30e+00  4e-01  1e+00 79:20.1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-e54ad375915c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \"\"\"\n\u001b[0;32m     18\u001b[0m \u001b[0mopts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'verb_filenameprefix'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'cmaes_lorenz_cosine_wtruthout_scaled_res%d\\\\'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mres_seed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_func_base\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopts\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Run the algorithm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\alexander\\dropbox\\alexanderwikner_1\\umd grad school\\reservoir-gn-rl-new\\pycma-awikner-patch-1\\cma\\evolution_strategy.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(objective_function, x0, sigma0, options, args, gradf, restarts, restart_from_best, incpopsize, eval_initial_x, parallel_objective, noise_handler, noise_change_sigma_exponent, noise_kappa_exponent, bipop, callback)\u001b[0m\n\u001b[0;32m   4387\u001b[0m                                              \u001b[0mevaluations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnoisehandler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluations\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4388\u001b[0m                                              \u001b[0maggregation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4389\u001b[1;33m                                              parallel_mode=parallel_objective)  # treats NaN with resampling if not parallel_mode\n\u001b[0m\u001b[0;32m   4390\u001b[0m                     \u001b[1;31m# TODO: check args and in case use args=(noisehandler.evaluations, )\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4391\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alexander\\dropbox\\alexanderwikner_1\\umd grad school\\reservoir-gn-rl-new\\pycma-awikner-patch-1\\cma\\evolution_strategy.py\u001b[0m in \u001b[0;36mask_and_eval\u001b[1;34m(self, func, args, gradf, number, xmean, sigma_fac, evaluations, aggregation, kappa, parallel_mode)\u001b[0m\n\u001b[0;32m   2412\u001b[0m                     \u001b[1;31m# self.more_to_write += [length_normalizer * 1e-3, length_normalizer * self.mahalanobis_norm(x - xmean) * 1e2]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2414\u001b[1;33m                 \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mkappa\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2415\u001b[0m                     func(xmean + kappa * length_normalizer * (x - xmean),\n\u001b[0;32m   2416\u001b[0m                          *args)\n",
      "\u001b[1;32m<ipython-input-4-a85d41a8eec2>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[0mx0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m min_func_base = lambda x: min_func_wtruth(x, mask, scaled_data, f_s, external_data,\\\n\u001b[1;32m---> 56\u001b[1;33m     base_res, num_tests, num_nodes, pred_length, train_length)\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[0msigma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-a85d41a8eec2>\u001b[0m in \u001b[0;36mmin_func_wtruth\u001b[1;34m(x, mask, base_data, f_s, true_external_data, base_res, num_tests, num_nodes, pred_length, train_length, scale, external_output)\u001b[0m\n\u001b[0;32m     42\u001b[0m     funval = vt_min_function_norm_external(data,external_data, x, mask, base_res.Win, base_res.A, \\\n\u001b[0;32m     43\u001b[0m         \u001b[0mnum_tests\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_tests\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mnum_nodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnum_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         external_output = external_output)\n\u001b[0m\u001b[0;32m     45\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfunval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[0mnum_nodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m360\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Dropbox\\AlexanderWikner_1\\UMD Grad School\\Reservoir-GN-RL-new\\reservoir_rls_multires.py\u001b[0m in \u001b[0;36mvt_min_function_norm_external\u001b[1;34m(data, external_data, hyperparams, mask, base_Win, base_A, num_nodes, num_tests, sync_length, train_length, pred_length, separated, external_output)\u001b[0m\n\u001b[0;32m    644\u001b[0m         valid_times = cross_validation_performance_resync_wextern(data, external_data, res, num_tests, sync_length, \\\n\u001b[0;32m    645\u001b[0m                                                    \u001b[0mtrain_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 646\u001b[1;33m                                                    train_method = 'Normal', external_output = external_output)\n\u001b[0m\u001b[0;32m    647\u001b[0m     \u001b[1;31m# print('Input Weight: %e, Reg: %e' % (input_weight, regularization))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_times\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Dropbox\\AlexanderWikner_1\\UMD Grad School\\Reservoir-GN-RL-new\\reservoir_rls_multires.py\u001b[0m in \u001b[0;36mcross_validation_performance_resync_wextern\u001b[1;34m(data, external_data, reservoir, num_tests, sync_length, train_length, pred_length, seed, errormax, train_method, external_input, external_output, progress, plot)\u001b[0m\n\u001b[0;32m    856\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m                 reservoir.trainWout(train_data, sync_length, external_data_train, external_input = external_input, \\\n\u001b[1;32m--> 858\u001b[1;33m                                       external_output = external_output)\n\u001b[0m\u001b[0;32m    859\u001b[0m             \u001b[1;31m# Evaluate the prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[0mreservoir\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msynchronize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresync_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Dropbox\\AlexanderWikner_1\\UMD Grad School\\Reservoir-GN-RL-new\\reservoir_rls_multires.py\u001b[0m in \u001b[0;36mtrainWout\u001b[1;34m(self, train_data, sync_length, pass_data, external_input, external_output)\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;31m# Then, begin training over all remaining data points\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msync_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madvance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m             \u001b[0maug_r\u001b[0m               \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m             \u001b[0maug_r\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m          \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maug_r\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Square every other node\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Dropbox\\AlexanderWikner_1\\UMD Grad School\\Reservoir-GN-RL-new\\reservoir_rls_multires.py\u001b[0m in \u001b[0;36madvance\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     68\u001b[0m         \u001b[1;31m# Update the reservoir state using the tanh activation function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdateRes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleakage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdateRes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleakage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mWin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Dropbox\\AlexanderWikner_1\\UMD Grad School\\Reservoir-GN-RL-new\\reservoir_rls_multires.py\u001b[0m in \u001b[0;36mupdateRes\u001b[1;34m(r, leakage, A, Win, input)\u001b[0m\n\u001b[0;32m   1066\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mupdateRes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleakage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mWin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1067\u001b[0m     \u001b[0mnewr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mleakage\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mr\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mleakage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1068\u001b[1;33m             \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1069\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnewr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1070\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "opts = cma.CMAOptions()\n",
    "opts.set('popsize',10*x0.size) # Set number of samples per generation\n",
    "\"\"\"\n",
    "Set bounds on parameters. IMPORTANT: The mean returned by cma-es is\n",
    "the mean BEFORE the boundary function is applied, so the mean may not\n",
    "lie in the domain set by bounds. To obtain the true sample mean requires \n",
    "downloading the cma-es package from github and editing one of the \n",
    "functions. Ask me if you need to do this.\n",
    "\"\"\"\n",
    "opts.set('bounds', [0,10]) \n",
    "opts.set('seed', 5) # Seed for the initial samples\n",
    "\"\"\"\n",
    "File where results are saved. IMPORTANT: Full covariance matrix is \n",
    "NOT saved, nor are the exact samples. If these need to be saved, one\n",
    "will also have to download from github and make some edits. Again,\n",
    "ask me.\n",
    "\"\"\"\n",
    "opts.set('verb_filenameprefix','cmaes_lorenz_cosine_wtruthout_scaled_res%d\\\\' % res_seed)\n",
    "results = cma.fmin(min_func_base, x0, sigma, options = opts) # Run the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_length = 100000\n",
    "step = 0.05\n",
    "f_s = 1/step\n",
    "scale = 0.01\n",
    "slow_var = 48/28\n",
    "r_t = lambda x: r_t_const(x)\n",
    "dx_dt = lambda x, time, r_t: dxdt_lorenz(x, time, r_t)\n",
    "lorenz_data = getLorenzData(data_length, r_t, dx_dt, sample_tau = step)\n",
    "scaled_data = np.ascontiguousarray(lorenz_data)\n",
    "plt.plot(lorenz_data[:1000,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [00:21<00:00,  9.42it/s]\n",
      "  0%|▍                                                                                 | 1/200 [00:00<00:22,  8.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 21.  44.  29.  37.  32.  11.   2.  67.   5.  25.  61.  40.   9.   5.\n",
      "  22.   8.  32.  47.   7.  21.  19. 158.  40.  41.  29.  51.  25.   5.\n",
      "  77.   7.  36.  39.  57.   6.  18.  64.   7.  34.  33.  56.  23.  31.\n",
      "  64.  44.  68.  14.  47.  43.  24.  13.  13.  25.  54.  74.  23.  53.\n",
      "   8.   6.  18.   6.  25.  16.   3.  14.  10.  10.   5.  15.  22.  24.\n",
      "  10.  20.   9.   6.  42.  29.   9.  38.   4.  17.  33.  32.   8.  16.\n",
      "  13.  24.  54.   8.   8.  30.  63.  18.  22.  10.  34.  33.   9.   6.\n",
      "   1.   3.   2.  16.   4.   2.  87.  15.  22.  50.  18.  26.  19.  31.\n",
      "  18.   5.   7.  35.  82. 108.  15.   7.  42.   7.  51.  39.  63.   9.\n",
      "  12.  23.  13.  27.   6.  42.  45.  13.  37.   7.  13. 117.  15.  35.\n",
      "  78.  20.  19.  88.  97.  14.   5.  11.   8.  25.  58.  13.  20.  37.\n",
      "   8.  46.   3.   6.  29.  17.  21.  11.  21.  24.  49.  33.  17.   5.\n",
      "  18.  17.  19.  10.   5.  69.  38.   5.  17.  15.  62.  72.   6.  10.\n",
      "   9.  36.  22.  75.  74.  20. 143.  74.  48.  61.   7.  95.  33.   6.\n",
      "  26.  26.   6.  37.]\n",
      "21.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [00:22<00:00,  9.02it/s]\n",
      "  0%|▍                                                                                 | 1/200 [00:00<00:21,  9.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 21.  12.  29.  35.  21.  11.   2.  67.   5.  24.  63.  39.   9.   5.\n",
      "  22.   8.  33.  47.   7.  20.  17. 114.  41.  41.  29.  50.  26.   5.\n",
      "  76.   6.  56.  50.  58.   6.  18.  75.   7.  33.  33.  58.  23.  31.\n",
      "  53.  44.  41.  15.  46.  44.  33.  11.  12.  25.  54.  74.  22.  38.\n",
      "   8.   6.  18.   6.  24.  16.   3.  14.   9.  10.   5.  40.  22.  25.\n",
      "  10.  21.   8.   6.  40.  29.   9.  28.   4.  17.  32.  32.   8.  16.\n",
      "  13.  24.  29.   8.   8.  29.  63.  18.  21.  11.  21.  33.   9.   6.\n",
      "   1.   3.   2.  15.   4.   2.  65.  14.  22.  50.  19.  28.  19.  18.\n",
      "  18.   5.   7.  38.  81. 109.  17.   7.  44.   7.  50.  39.  64.   9.\n",
      "  13.  23.  11.  27.   6.  41.  45.  13.  36.   7.  13. 118.  14.  36.\n",
      "  78.  20.  22.  88.  53.  14.   5.  11.   8.  25.  57.  13.  20.  22.\n",
      "   7.  45.   3.   6.  29.  17.  21.  11.  22.  49.  49.  33.  25.   5.\n",
      "  18.  17.  10.   9.   5.  69.  38.   5.  17.  26.  62.  83.   6.   9.\n",
      "   9.  36.  22.  76.  45.  20. 146.  73.  44.  61.   7.  53.  30.   6.\n",
      "  27.  25.   6.  37.]\n",
      "21.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [00:21<00:00,  9.26it/s]\n",
      "  0%|▍                                                                                 | 1/200 [00:00<00:24,  8.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 24.  10.  27.  22.  34.   7.   3.  65.  17.   5. 127.  25.  18.   5.\n",
      "  69.   7.  33.  60.  20.  20.  38.  70.  38.  40.  65.  49.  26.   7.\n",
      "  26.   6.  34.  53.  57.   6.  33.  17.   9.  10.  30.  44.  50. 112.\n",
      "  53.  43.  41.  11.   7.  71.  12.  11.  24.  66.  57.  64.  36.  56.\n",
      "  10.   6.   7.  33.  22.  16.   3.  14.   6.  10.   9.  12.  23.  22.\n",
      "   9.  22.  22.   5.  27.  15.  13.  66.   4.  21.  61.  10.  20.  18.\n",
      "  36.  10.  16.   3.  38.  47.  64.  18.   9.  24.  21.  35.   9.  21.\n",
      "   5.   4.   5.  16.   4.   3.  28.  14.  44.  52.  32.  29.  51.  30.\n",
      "  23.  13.   8.  51. 108. 122.  17.   5.  48.   7.  67.  40.  22.  10.\n",
      "  12.  23.  22.  38.   6.  41.  17.  65.  38.   8.  15.  79.  14.  31.\n",
      " 103.  21.  18. 101.  52.  12.   6.  15.   8.  26. 112.  27.  19.  10.\n",
      "   4.  22.   3.   5.  15.  17.   8.  32.  60.  23.  92.  32.  15.   4.\n",
      "  10.  31.  10.  21.   8.  23.  40.   7.  15.  21.  62.  38.   6.  12.\n",
      "   9.  36.  13.  39.  58.  18.  74.  72.  98.  58.  19.  53.  18.   7.\n",
      "  38.  27.  11.   8.]\n",
      "22.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [00:22<00:00,  8.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 23.  10.  27.  21.  35.   8.   6.  67.  17.   4. 103.  25.  19.   5.\n",
      "  24.   8.  75.  92.  20.  22.  18.  70.  38.  32.  65.  49.  25.   7.\n",
      "  26.   6.  34.  54.  57.   5.  33.  17.   3.  10.  30.  44.  54.  33.\n",
      "  52.  43.  41.  11.   6.  70.  12.  10.  35.  66.  57.  65.  36.  92.\n",
      "  10.   5.   7.  44.  23.  16.   2.  14.   7.  10.   6.  13.  23.  22.\n",
      "   9.  23.  23.   5.  27.  15.  14.  69.   3.  21.  34.  21.  29.  15.\n",
      "  37.  10.  15.   3.  51.  48.  64.  18.  20.  24.  21.  35.   9.  21.\n",
      "   2.   4.   1.  17.   4.   6.  30.  13.  44.  52.  44.  29.  42.  30.\n",
      "  20.  13.   7.  92. 109. 122.  17.   6.  46.   7. 122.  42.  22.  10.\n",
      "  15.  23.  16.  37.   7.  41.  17.  64.  38.   7.   4.  79.  16.  31.\n",
      " 103.  22.  20. 100.  51.  11.   8.  14.   7.  25. 112.   6.  19.  22.\n",
      "   4.  22.   2.   5.  16.  17.   8.  34.  60.  23. 102.  32.  14.   3.\n",
      "  10.  31.  11.  33.   9.  57.  40.   5.  15.  22.  62.  37.   6.  11.\n",
      "  18.  36.  13.  39.  59.  18. 116.  72.  46.  58.  13.  53.  19.   7.\n",
      "  38.  36.   5.  29.]\n",
      "22.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import expit\n",
    "res_rossler = reservoir(4, 360, input_weight = 0.01, leakage =  0, \\\n",
    "                        regularization = 1e-7, forget = 1, seed = 1)\n",
    "train_length = 3000\n",
    "sync_length = 500\n",
    "pred_length = 500\n",
    "num_tests = 200\n",
    "# results = cross_validation_performance_resync_wextern(scaled_data, scaled_data_external, res_rossler, num_tests, sync_length, train_length, pred_length, \\\n",
    "#          seed = 10, errormax = 3.2, train_method = 'Normal', progress = True, plot = False)\n",
    "results = cross_validation_performance_resync_wextern(new_scaled_data, new_scaled_data_external, \\\n",
    "         res_rossler, num_tests, sync_length, train_length, pred_length, \\\n",
    "         seed = 10, errormax = 3.2, train_method = 'Normal', progress = True, external_output = False)\n",
    "print(results)\n",
    "print(np.median(results))\n",
    "results = cross_validation_performance_resync_wextern(new_scaled_data, new_scaled_data_external, \\\n",
    "         res_rossler, num_tests, sync_length, train_length, pred_length, \\\n",
    "         seed = 10, errormax = 3.2, train_method = 'Normal', progress = True, external_output = True)\n",
    "print(results)\n",
    "print(np.median(results))\n",
    "results = cross_validation_performance_resync_wextern(new_scaled_data, new_data_external, res_rossler, num_tests, sync_length, train_length, pred_length, \\\n",
    "         seed = 10, errormax = 3.2, train_method = 'Normal', progress = True, external_output = False)\n",
    "print(results)\n",
    "print(np.median(results))\n",
    "results = cross_validation_performance_resync_wextern(new_scaled_data, new_data_external, res_rossler, num_tests, sync_length, train_length, pred_length, \\\n",
    "         seed = 10, errormax = 3.2, train_method = 'Normal', progress = True, external_output = True)\n",
    "print(results)\n",
    "print(np.median(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 200/200 [00:21<00:00,  9.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 20.   8.  10.   7.  16.   9.  10.  25.  18.  24.   8.   2.   9.   8.\n",
      " 122.  12.  19.   6.  10.   3.  24.   9.  17.  28.  17.   5.   4.   5.\n",
      "  13.   9.  11.   8.  15.  19.  13.  21.  12.  11.  17.  39.  19.  13.\n",
      "  10.   4.   8.  20.   6.  26.  21.   9.  16.   9.   3.  16.   2.  16.\n",
      "  10.  10.  37.   5.   5.  14.  12.  15.   7.   7.   6.   5.  12.  12.\n",
      "  11.   9.  24.  22.  17.   5.  47.   4.  12.  14.  15.  89.  27.  27.\n",
      "  14.   9.   9.  18.  17.   6.   4.   8.   6.   4.   4.   9.  10.   5.\n",
      "  14.   9.  69.   4.   8.  13.   8.   8.  17.   2.   5.   9.   5.   8.\n",
      "   7.  39.   5.   5.  31.  20.  15.   3.  15.  19.   4.  19.   9.   6.\n",
      "   6.  13.  12.  15.  19.   8.   5.  22.   9.   8.   7.   3.  45.  11.\n",
      "   5.   6.  27.  19.  23.  12.   8.  21.   8.   4.  16.  15.   8.   8.\n",
      "   7.  27.   8.   7.   3.  10.   5.  18.   8.  13.   4.  10.  74.  13.\n",
      "  14.  12.   1.  10.  24.   9.  20.  30.   6.  25.  46.  15.   5.  15.\n",
      "  18.  19.  21.  10.   6.   7.  17.  16.   5.   8.   9.  11.  25.   7.\n",
      "  22.   4.   8.  13.]\n",
      "10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "res_rossler = reservoir(3, 360, input_weight = 0.01, leakage =  0, \\\n",
    "                        regularization = 1e-7, forget = 1, seed = 1)\n",
    "train_length = 3000\n",
    "sync_length = 500\n",
    "pred_length = 500\n",
    "num_tests = 200\n",
    "# results = cross_validation_performance_resync_wextern(scaled_data, scaled_data_external, res_rossler, num_tests, sync_length, train_length, pred_length, \\\n",
    "#          seed = 10, errormax = 3.2, train_method = 'Normal', progress = True, plot = False)\n",
    "results = cross_validation_performance_resync(scaled_data, res_rossler, num_tests, sync_length, train_length, pred_length, \\\n",
    "         seed = 10, errormax = 3.2, train_method = 'Normal', progress = True)\n",
    "print(results)\n",
    "print(np.median(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([[1,2,3,4],[5,6,7,8]]).T/np.array([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_data = True\n",
    "data_length = 2500000\n",
    "step = 0.05\n",
    "f_s = 1/step\n",
    "scale = 1\n",
    "r_t = lambda x: r_t_const(x)\n",
    "dx_dt = lambda x, time, r_t: dxdt_rossler(x, time, r_t, scale = scale)\n",
    "if get_data:\n",
    "    rossler_data = getLorenzData(data_length, r_t, dx_dt, sample_tau = step)\n",
    "    np.savetxt('rossler_data_step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = 100\n",
    "num_tests = 100\n",
    "train_length = 10000\n",
    "sync_length = 500\n",
    "pred_length = 2000\n",
    "res_seed = 1\n",
    "base_res = reservoir(1,num_nodes,input_weight = 1, spectral_radius = 1, seed = res_seed) #Generate a reservoir\n",
    "mask = ['input_weight', 'regularization', 'leakage']\n",
    "x0 = np.array([6,6,6])\n",
    "# Set the minimization function. This function takes num_tests training\n",
    "# and validation data sets and trains the reservoir to predict each validation set\n",
    "# after being trained on the corresponding training set. The negative median valid\n",
    "# time is returned to be minimized.\n",
    "min_func = lambda x: vt_min_function_norm(rossler_data[:,1], x, mask, base_res.Win, base_res.A, \\\n",
    "     num_tests = num_tests,  num_nodes = num_nodes, pred_length = pred_length, train_length = train_length)\n",
    "sigma = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = cma.CMAOptions()\n",
    "opts.set('popsize',10*x0.size) # Set number of samples per generation\n",
    "\"\"\"\n",
    "Set bounds on parameters. IMPORTANT: The mean returned by cma-es is\n",
    "the mean BEFORE the boundary function is applied, so the mean may not\n",
    "lie in the domain set by bounds. To obtain the true sample mean requires \n",
    "downloading the cma-es package from github and editing one of the \n",
    "functions. Ask me if you need to do this.\n",
    "\"\"\"\n",
    "opts.set('bounds', [0,10]) \n",
    "opts.set('seed', 5) # Seed for the initial samples\n",
    "\"\"\"\n",
    "File where results are saved. IMPORTANT: Full covariance matrix is \n",
    "NOT saved, nor are the exact samples. If these need to be saved, one\n",
    "will also have to download from github and make some edits. Again,\n",
    "ask me.\n",
    "\"\"\"\n",
    "opts.set('verb_filenameprefix','cmaes_rossler_y_norm_wleakage_res%d\\\\' % res_seed)\n",
    "results = cma.fmin(min_func, x0, sigma, options = opts) # Run the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "expit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_base = reservoir(4, 360, input_weight = 0.017, regularization = 1e-10, forget = 1)\n",
    "train_length = 3000\n",
    "sync_length = 300\n",
    "pred_length = 500\n",
    "num_tests = 100\n",
    "results = cross_validation_performance_resync(rossler_data_w_lowfreq, res_base, num_tests, sync_length, train_length, pred_length, \\\n",
    "         seed = 10, errormax = 3.2, train_method = 'Normal', progress = True)\n",
    "print(results)\n",
    "print(np.mean(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate((np.array([1,2]).reshape(-1,1),np.array([])), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_length = 100000\n",
    "step = 0.05\n",
    "r_t = lambda x: r_t_const(x)\n",
    "dx_dt = lambda x, time, r_t: dxdt_lorenz(x, time, r_t)\n",
    "lorenz_data_base = getLorenzData(data_length, r_t, dx_dt, sample_tau = step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(lorenz_data_base, axis = 0))\n",
    "print(np.std(lorenz_data_base, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_base = reservoir(3, 300, input_weight = -0.06, input_bias = 0.04, regularization = 1e-7, forget = 0.999)\n",
    "train_length = 1000\n",
    "sync_length = 500\n",
    "pred_length = 500\n",
    "num_tests = 100\n",
    "results = cross_validation_performance_resync(lorenz_data_rossler[:,:3], res_base, num_tests, sync_length, train_length, pred_length, \\\n",
    "         seed = 10, errormax = 3.2, train_method = 'Normal', progress = True, plot = False)\n",
    "print(results)\n",
    "print(np.mean(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_res = double_reservoir(6, 400, input_weight = [0.017,0.017], regularization = [1e-10,1e-10], forget = [1,0.99])\n",
    "train_length = 1000\n",
    "sync_length = 500\n",
    "pred_length = 500\n",
    "num_tests = 50\n",
    "data = np.append(lorenz_data_rossler[:,:3], lorenz_data_rossler[:,:3], axis = 1)\n",
    "target_data = lorenz_data_split\n",
    "results = cross_validation_performance_resync_decompose(data, target_data, d_res, num_tests, sync_length, train_length, pred_length, \\\n",
    "         seed = 5, errormax = 3.2, train_method = 'Normal', progress = True, plot = False)\n",
    "print(results)\n",
    "print(np.mean(results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
